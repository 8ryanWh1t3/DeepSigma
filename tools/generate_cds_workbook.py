#!/usr/bin/env python3
"""Generate the Creative Director Suite CoherenceOps v2 workbook.

Reads the existing v1 workbook as structural reference, then produces
a new workbook with:
  - BOOT sheet with structured system prompt in A1
  - All original sheets from v1
  - New PATCH_LOG sheet
  - 7 named Excel tables with 25 sample rows each
  - CI_DASHBOARD with weighted Coherence Index dimensions

Usage:
    pip install openpyxl
    python tools/generate_cds_workbook.py

Output:
    templates/creative_director_suite/Creative_Director_Suite_CoherenceOps_v2.xlsx
"""

from __future__ import annotations

import datetime
from pathlib import Path

import openpyxl
from openpyxl.styles import Alignment, Font
from openpyxl.worksheet.table import Table, TableStyleInfo

REPO_ROOT = Path(__file__).resolve().parent.parent
V1_PATH = (
    Path.home()
    / "Library"
    / "Mobile Documents"
    / "com~apple~CloudDocs"
    / "Creative_Director_Suite_CoherenceOps_v1.xlsx"
)
OUTPUT = (
    REPO_ROOT
    / "templates"
    / "creative_director_suite"
    / "Creative_Director_Suite_CoherenceOps_v2.xlsx"
)

TODAY = datetime.date.today().isoformat()

BOOT_TEXT = f"""\
=== CREATIVE DIRECTOR SUITE — COHERENCE OPS WORKBOOK v2.0 ===

YOU ARE: Creative Ops Copilot (Coherence Ops: Truth · Reasoning · Memory)

OPENING MOVE:
1) Read this workbook's tables (tblTimeline, tblDeliverables, tblClaims, tblAssumptions, tblDLR, tblPatchLog, tblCanonGuardrails).
2) Then ask the user: "What Would You Like To Do Today?" and show the menu below.

MENU (reply with a number):
1) Build/Update Claims
2) Refresh Assumptions + Half-Life
3) Detect Drift + Root Cause
4) Propose Patch Options
5) Canon Audit
6) Weekly Exec Summary
7) Next 7 Days Asset Checklist

RULES:
- Use ONLY information found in this workbook. If data is missing, ask 1 clarifying question and list the missing fields.
- Do NOT invent sources, metrics, or brand rules.
- Enforce Canon Guardrails (tblCanonGuardrails) as hard constraints.
- Always reference: TableName + Row_ID(s) (e.g., tblTimeline Week=4, Decision_ID=DEC-004).
- Output in tables with these columns when applicable: ID | Recommendation | Risk | Expected Impact | Guardrail Check | Where to Write Back (Table/Columns).

DEFAULT OUTPUT FORMAT:
- Start with: "What Would You Like To Do Today?"
- After selection: produce (A) Findings, (B) Recommended Actions, (C) Write-back rows for Excel (ready to paste).

SHEET MANIFEST:
- BOOT: You are here. System prompt for LLM initialization.
- QUICK_START: 6-step guide to using this workbook.
- DATA_DICTIONARY: Lookup lists (Channels, Audiences, Status, Canon types).
- BRIEF_MATRIX: Initiative tracking with assumption half-life (tblTimeline, tblDeliverables).
- 6_LENS_PROMPTS: Multi-dimensional prompt generation (PRIME/EXEC/OPS/AI-TECH/HUMAN/ICON).
- DLR_CAPTURE: Decision Ledger Records — every decision sealed here (tblDLR).
- CANON_SYNC: Canonical statements — the truth registry (tblCanonGuardrails).
- ASSUMPTIONS: Assumption tracking with half-life decay (tblAssumptions).
- CLAIMS: Truth claims with confidence scoring (tblClaims).
- PATCH_LOG: Corrections triggered by drift detection (tblPatchLog).
- CI_DASHBOARD: Coherence Index — weighted governance scorecard.

NAMED TABLES:
tblTimeline, tblDeliverables, tblDLR, tblClaims, tblAssumptions, tblPatchLog, tblCanonGuardrails

PROVENANCE:
Generated by: DeepSigma v0.6.2 — tools/generate_cds_workbook.py
Framework: Σ OVERWATCH Coherence Ops
Date: {TODAY}
"""

# ---------------------------------------------------------------------------
# Sample data generators
# ---------------------------------------------------------------------------

CHARACTERS = [
    "Hello Kitty", "Kuromi", "My Melody", "Cinnamoroll", "Pompompurin",
    "Little Twin Stars", "Badtz-Maru", "Keroppi", "Pochacco", "Tuxedo Sam",
    "Gudetama", "Aggretsuko", "Chococat", "Hangyodon", "KIRIMIchan",
    "Cogimyun", "Wish Me Mell", "Corocorokuririn", "Marumofubiyori", "Retsuko",
    "Pekkle", "Monkichi", "Pandapple", "Sugarbunnies", "Jewelpet",
]

CHANNELS = ["YouTube", "TikTok", "Instagram", "CTV", "Retail", "Web", "App", "OOH"]
PHASES = ["Pre-Launch", "Launch", "Mid-Campaign", "Post-Launch", "Wrap-Up"]
STATUSES_DLR = ["DRAFT", "SEALED", "PATCHED", "RETIRED"]
SEVERITIES = ["LOW", "MEDIUM", "HIGH", "CRITICAL"]
TONES = ["Playful", "Warm", "Energetic", "Calm", "Bold"]
DIMENSIONS = ["Tone", "Visual", "Copy", "Behavior"]


def _date(offset_days: int) -> str:
    d = datetime.date(2026, 2, 16) + datetime.timedelta(days=offset_days)
    return d.isoformat()


def generate_timeline_rows(n: int = 25) -> list[list]:
    """Generate tblTimeline sample rows."""
    headers = [
        "Week", "Start_Date", "End_Date", "Phase", "Key_Deliverable",
        "Primary_Lens", "Decision_ID", "Assumption_Check", "Canon_Check",
        "KPI_Target", "Actual_KPI", "Drift_Flag", "CI_Week_Score",
        "CI_Week_Status", "Notes",
    ]
    rows = [headers]
    lenses = ["PRIME", "EXEC", "OPS", "AI/TECH", "HUMAN", "ICON"]
    for i in range(1, n + 1):
        phase = PHASES[i % len(PHASES)]
        lens = lenses[i % len(lenses)]
        drift = "GREEN" if i % 5 != 0 else ("YELLOW" if i % 10 != 0 else "RED")
        ci = max(60, 95 - (i * 2) % 30)
        ci_status = "ON_TRACK" if ci >= 85 else ("DRIFTING" if ci >= 70 else "CRITICAL")
        rows.append([
            i, _date((i - 1) * 7), _date(i * 7 - 1), phase,
            f"{CHARACTERS[i % len(CHARACTERS)]} {CHANNELS[i % len(CHANNELS)]} Drop",
            lens, f"DEC-{i:03d}", f"ASM-{i:03d}", f"GR-{i:03d}",
            f"VTR_{25 + i}%", f"VTR_{22 + i}%" if i % 3 == 0 else "",
            drift, ci, ci_status, "",
        ])
    return rows


def generate_deliverables_rows(n: int = 25) -> list[list]:
    """Generate tblDeliverables sample rows."""
    headers = [
        "Week", "Asset_ID", "Asset_Type", "Channel", "Owner", "Status",
        "Due_Date", "Dependency_Decision_ID", "Canon_Guardrail", "Notes",
    ]
    types = ["Video_6s", "Video_15s", "Poster", "Sticker_Pack", "AR_Filter",
             "Retail_Endcap", "Social_Carousel", "Brand_Anthem"]
    statuses = ["Draft", "In_Review", "Approved", "Published"]
    owners = ["Art_Director", "Motion_Lead", "Copywriter", "Producer", "Brand_Manager"]
    rows = [headers]
    for i in range(1, n + 1):
        rows.append([
            (i - 1) // 3 + 1, f"AS-{i:03d}",
            types[i % len(types)], CHANNELS[i % len(CHANNELS)],
            owners[i % len(owners)], statuses[i % len(statuses)],
            _date(i * 3), f"DEC-{i:03d}", f"GR-{i:03d}", "",
        ])
    return rows


def generate_dlr_rows(n: int = 25) -> list[list]:
    """Generate tblDLR sample rows."""
    headers = [
        "Decision_ID", "Initiative_ID", "Decision_Date", "Context",
        "Options_Considered", "Chosen_Option", "Rationale_Why",
        "Rejected_Alternatives_Why", "Assumptions_IDs", "Kill_Switch",
        "Review_Date", "Owner", "Status", "Seal_ID", "Patch_Version", "Notes",
    ]
    contexts = [
        "Platform selection for campaign launch",
        "Asset format decision for target demo",
        "Tone direction for brand character refresh",
        "Budget allocation across workstreams",
        "Timeline compression for retail deadline",
    ]
    rows = [headers]
    for i in range(1, n + 1):
        rows.append([
            f"DEC-{i:03d}", f"INIT-{(i - 1) // 5 + 1:03d}", _date(i * 2),
            contexts[i % len(contexts)],
            "A: option_a; B: option_b; C: option_c",
            "B", f"Best balance of reach and brand safety for {CHARACTERS[i % len(CHARACTERS)]}",
            "A: too narrow; C: production risk",
            f"ASM-{i:03d};ASM-{(i % 25) + 1:03d}",
            "If drift flagged OR assumptions expire",
            _date(i * 2 + 14), "Brand_Lead",
            STATUSES_DLR[i % len(STATUSES_DLR)],
            f"SEAL-{i:03d}" if i % 4 != 0 else "", i, "",
        ])
    return rows


def generate_claims_rows(n: int = 25) -> list[list]:
    """Generate tblClaims sample rows."""
    headers = [
        "Claim_ID", "Claim_Text", "Confidence_0_100", "Evidence_Summary",
        "Source_Ref", "Last_Validated_Date", "Owner", "Status", "Notes",
    ]
    claims = [
        "Target audience prefers short-form video over static imagery",
        "Character recognition drives higher engagement in JP market",
        "CTV placements outperform YouTube pre-roll for brand recall",
        "Kawaii aesthetic increases share rate by 2.3x among Gen Z",
        "Retail endcap motion lifts sell-through by 15% over static",
    ]
    statuses = ["ACTIVE", "ACTIVE", "ACTIVE", "EXPIRED", "CONTESTED"]
    rows = [headers]
    for i in range(1, n + 1):
        conf = max(40, 95 - (i * 3) % 50)
        rows.append([
            f"CLM-{i:03d}", claims[i % len(claims)], conf,
            f"Based on Q4 2025 campaign data for {CHARACTERS[i % len(CHARACTERS)]}",
            f"analytics_report_Q4_{2025 + i % 2}", _date(i),
            "Analytics_Lead", statuses[i % len(statuses)], "",
        ])
    return rows


def generate_assumptions_rows(n: int = 25) -> list[list]:
    """Generate tblAssumptions sample rows."""
    headers = [
        "Assumption_ID", "Related_Decision_ID", "Assumption_Text",
        "Confidence_Initial_0_1", "Half_Life_Days", "Date_Validated_Last",
        "Current_Confidence", "Expiry_Date", "Status", "Owner",
        "Action_If_Expired", "Notes",
    ]
    assumptions = [
        "Audience receptive to kawaii brand framing on this platform",
        "VTR benchmark holds above 30% for 6s format",
        "Retail partner will maintain endcap placement through Q1",
        "Character licensing terms allow derivative sticker packs",
        "Production timeline can absorb 1-week compression",
    ]
    rows = [headers]
    for i in range(1, n + 1):
        conf_init = round(0.6 + (i % 4) * 0.1, 2)
        half_life = 14 + (i % 5) * 7
        status = "ACTIVE" if i % 4 != 0 else ("EXPIRED" if i % 8 != 0 else "REFRESHED")
        rows.append([
            f"ASM-{i:03d}", f"DEC-{i:03d}",
            assumptions[i % len(assumptions)],
            conf_init, half_life, _date(i),
            round(conf_init * (0.5 ** (max(0, i - 10) / half_life)), 2),
            _date(i + half_life), status, "Strategy_Lead",
            "Revalidate with fresh data", "",
        ])
    return rows


def generate_patch_rows(n: int = 25) -> list[list]:
    """Generate tblPatchLog sample rows."""
    headers = [
        "Patch_ID", "Week_Triggered", "Decision_ID", "Drift_Source",
        "Severity", "Root_Cause", "Patch_Action", "Owner", "Status",
        "Date_Opened", "Date_Closed", "Impact_on_CI", "Notes",
    ]
    drift_sources = [
        "ASM expired", "KPI miss", "Canon conflict",
        "Timeline slip", "Audience shift",
    ]
    root_causes = [
        "Benchmark data stale", "Platform algorithm change",
        "Brand guideline update", "Resource reallocation",
        "Market trend shift",
    ]
    actions = [
        "Refresh assumption with Q1 actuals",
        "Swap platform allocation",
        "Update canon statement",
        "Compress timeline by 3 days",
        "Re-survey target audience",
    ]
    patch_statuses = ["OPEN", "IN_PROGRESS", "CLOSED"]
    rows = [headers]
    for i in range(1, n + 1):
        status = patch_statuses[i % len(patch_statuses)]
        rows.append([
            f"PAT-{i:03d}", (i - 1) // 3 + 1, f"DEC-{i:03d}",
            drift_sources[i % len(drift_sources)],
            SEVERITIES[i % len(SEVERITIES)],
            root_causes[i % len(root_causes)],
            actions[i % len(actions)],
            "Ops_Lead", status, _date(i * 2),
            _date(i * 2 + 5) if status == "CLOSED" else "",
            f"CI +{3 + i % 8} pts" if status == "CLOSED" else "",
            "",
        ])
    return rows


def generate_canon_rows(n: int = 25) -> list[list]:
    """Generate tblCanonGuardrails sample rows."""
    headers = [
        "Guardrail_ID", "Character", "Dimension", "Allowed", "Restricted",
        "Forbidden", "Severity", "Detection_Method", "Auto_Flag_If",
        "Owner", "Escalation_Path", "Notes",
    ]
    rows = [headers]
    for i in range(1, n + 1):
        char = CHARACTERS[i % len(CHARACTERS)]
        dim = DIMENSIONS[i % len(DIMENSIONS)]
        sev = "HARD" if i % 3 == 0 else ("CRITICAL" if i % 7 == 0 else "ADVISORY")
        rows.append([
            f"GR-{i:03d}", char, dim,
            f"{char} standard {dim.lower()} expression",
            f"Modified {dim.lower()} without brand team approval",
            f"{char} in violent or adult contexts",
            sev, "LLM content scan + manual review",
            f"Contains '{char}' + restricted keyword",
            "Brand_Manager", "VP Creative → Legal", "",
        ])
    return rows


# ---------------------------------------------------------------------------
# Workbook builder
# ---------------------------------------------------------------------------

def copy_sheet(src_wb, dst_wb, sheet_name: str) -> None:
    """Copy a sheet from src to dst workbook, values only."""
    if sheet_name not in src_wb.sheetnames:
        return
    src = src_wb[sheet_name]
    dst = dst_wb.create_sheet(sheet_name)
    for row in src.iter_rows(min_row=1, max_row=src.max_row,
                             max_col=src.max_column, values_only=False):
        for cell in row:
            new_cell = dst.cell(row=cell.row, column=cell.column,
                                value=cell.value)
            if cell.font:
                from copy import copy
                new_cell.font = copy(cell.font)
            if cell.fill and cell.fill.fgColor and cell.fill.fgColor.rgb:
                from copy import copy
                new_cell.fill = copy(cell.fill)
            if cell.alignment:
                from copy import copy
                new_cell.alignment = copy(cell.alignment)
    # Copy column widths
    for col_letter, dim in src.column_dimensions.items():
        dst.column_dimensions[col_letter].width = dim.width


def write_rows(ws, rows: list[list]) -> None:
    """Write rows starting at A1."""
    for r_idx, row in enumerate(rows, 1):
        for c_idx, val in enumerate(row, 1):
            ws.cell(row=r_idx, column=c_idx, value=val)


def add_named_table(ws, name: str, num_rows: int) -> None:
    """Add a named Excel table to a worksheet."""
    max_col = ws.max_column
    col_letter = openpyxl.utils.get_column_letter(max_col)
    ref = f"A1:{col_letter}{num_rows + 1}"  # +1 for header
    style = TableStyleInfo(
        name="TableStyleMedium9",
        showFirstColumn=False, showLastColumn=False,
        showRowStripes=True, showColumnStripes=False,
    )
    table = Table(displayName=name, ref=ref)
    table.tableStyleInfo = style
    ws.add_table(table)


def style_header_row(ws) -> None:
    """Bold the header row and auto-fit column widths."""
    bold = Font(bold=True)
    for cell in ws[1]:
        cell.font = bold
    # Approximate auto-fit
    for col in ws.columns:
        max_len = 0
        col_letter = openpyxl.utils.get_column_letter(col[0].column)
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len = max(max_len, len(val))
        ws.column_dimensions[col_letter].width = min(max_len + 4, 40)


def main() -> None:
    wb = openpyxl.Workbook()

    # Remove default sheet
    wb.remove(wb.active)

    # 1. BOOT sheet
    boot = wb.create_sheet("BOOT")
    boot["A1"] = BOOT_TEXT
    boot["A1"].alignment = Alignment(wrap_text=True, vertical="top")
    boot["A1"].font = Font(name="Consolas", size=11)
    boot.column_dimensions["A"].width = 120
    boot.row_dimensions[1].height = 800

    # 2. Copy utility sheets from v1 if available
    if V1_PATH.exists():
        v1 = openpyxl.load_workbook(str(V1_PATH), data_only=False)
        for name in ["QUICK_START", "DATA_DICTIONARY", "6_LENS_PROMPTS", "CI_DASHBOARD"]:
            copy_sheet(v1, wb, name)
    else:
        # Minimal stubs if v1 not available
        qs = wb.create_sheet("QUICK_START")
        write_rows(qs, [
            ["Step", "Do this", "Where", "Output", "Notes"],
            [1, "Read BOOT!A1", "BOOT", "Context loaded", "LLM reads this first"],
            [2, "Add initiative row", "BRIEF_MATRIX", "Initiative object", "Fill row 2"],
            [3, "Run 6-lens prompts", "6_LENS_PROMPTS", "Prompt blocks", "Copy into LLM"],
            [4, "Capture decision", "DLR_CAPTURE", "Sealed DLR", "Link assumptions"],
            [5, "Register assumptions", "ASSUMPTIONS", "Half-life tracking", "Set expiry"],
            [6, "Check CI dashboard", "CI_DASHBOARD", "Coherence Index", "Monitor drift"],
        ])

        dd = wb.create_sheet("DATA_DICTIONARY")
        write_rows(dd, [
            ["List_Name", "Value"],
            ["Channels", "YouTube"], ["Channels", "TikTok"],
            ["Channels", "Instagram"], ["Channels", "CTV"],
            ["Channels", "Retail"], ["Channels", "Web"],
            ["Audiences", "Gen Z"], ["Audiences", "Millennials"],
            ["Audiences", "Exec Leaders"], ["Audiences", "Families"],
            ["DLR_Status", "DRAFT"], ["DLR_Status", "SEALED"],
            ["DLR_Status", "PATCHED"], ["DLR_Status", "RETIRED"],
            ["Canon_Type", "FACT"], ["Canon_Type", "CONSTRAINT"],
            ["Canon_Type", "GUIDELINE"], ["Canon_Type", "PRECEDENT"],
        ])

        lp = wb.create_sheet("6_LENS_PROMPTS")
        write_rows(lp, [
            ["Lens", "IntelOps", "ReOps", "FranOps", "Generated_Prompt"],
            ["PRIME", "Truth standards?", "Governance invariants?", "Canon precedence?", ""],
            ["EXEC", "Top claims + blast radius?", "Decision gate + owner?", "Narrative risk?", ""],
            ["OPS", "Collection gaps?", "Daily loop plan?", "Continuity checks?", ""],
            ["AI/TECH", "Automation for drift?", "Drift triggers?", "Safe summary rules?", ""],
            ["HUMAN", "Bias risks?", "Adoption friction?", "Tone guardrails?", ""],
            ["ICON", "Truth status lights?", "Seal/patch markers?", "SEV banners?", ""],
        ])

        ci = wb.create_sheet("CI_DASHBOARD")
        write_rows(ci, [
            ["Dimension", "Weight", "Score (0-100)", "Weighted", "Notes", "Source"],
            ["Drift Velocity", 0.20, "", "", "Inverse of unresolved drift signals", "PATCH_LOG"],
            ["Assumption Freshness", 0.15, "", "", "% of assumptions within half-life", "ASSUMPTIONS"],
            ["Claim Confidence", 0.15, "", "", "Avg confidence across active claims", "CLAIMS"],
            ["DLR Completeness", 0.15, "", "", "% of decisions with full rationale", "DLR_CAPTURE"],
            ["Canon Compliance", 0.10, "", "", "% of outputs passing guardrail checks", "CANON_SYNC"],
            ["Deliverable On-Time", 0.10, "", "", "% of assets delivered by due date", "BRIEF_MATRIX"],
            ["Patch Resolution", 0.05, "", "", "% of patches closed within SLA", "PATCH_LOG"],
            ["Evidence Coverage", 0.05, "", "", "% of claims with evidence attached", "CLAIMS"],
            ["Owner Assignment", 0.03, "", "", "% of rows with an assigned owner", "ALL"],
            ["Review Cadence", 0.02, "", "", "% of DLRs reviewed within review date", "DLR_CAPTURE"],
        ])

    # 3. Governance sheets with 25 sample rows + named tables

    # BRIEF_MATRIX → tblTimeline
    bm = wb.create_sheet("BRIEF_MATRIX")
    timeline_rows = generate_timeline_rows(25)
    write_rows(bm, timeline_rows)
    style_header_row(bm)
    add_named_table(bm, "tblTimeline", 25)

    # We also define tblDeliverables on a separate sheet
    dl = wb.create_sheet("DELIVERABLES")
    deliv_rows = generate_deliverables_rows(25)
    write_rows(dl, deliv_rows)
    style_header_row(dl)
    add_named_table(dl, "tblDeliverables", 25)

    # DLR_CAPTURE → tblDLR
    dlr = wb.create_sheet("DLR_CAPTURE")
    dlr_rows = generate_dlr_rows(25)
    write_rows(dlr, dlr_rows)
    style_header_row(dlr)
    add_named_table(dlr, "tblDLR", 25)

    # CLAIMS → tblClaims
    cl = wb.create_sheet("CLAIMS")
    claims_rows = generate_claims_rows(25)
    write_rows(cl, claims_rows)
    style_header_row(cl)
    add_named_table(cl, "tblClaims", 25)

    # ASSUMPTIONS → tblAssumptions
    asm = wb.create_sheet("ASSUMPTIONS")
    asm_rows = generate_assumptions_rows(25)
    write_rows(asm, asm_rows)
    style_header_row(asm)
    add_named_table(asm, "tblAssumptions", 25)

    # PATCH_LOG → tblPatchLog (new sheet)
    pl = wb.create_sheet("PATCH_LOG")
    patch_rows = generate_patch_rows(25)
    write_rows(pl, patch_rows)
    style_header_row(pl)
    add_named_table(pl, "tblPatchLog", 25)

    # CANON_SYNC → tblCanonGuardrails
    cs = wb.create_sheet("CANON_SYNC")
    canon_rows = generate_canon_rows(25)
    write_rows(cs, canon_rows)
    style_header_row(cs)
    add_named_table(cs, "tblCanonGuardrails", 25)

    # 4. Reorder sheets: BOOT first, then utility, then governance, then dashboard
    desired_order = [
        "BOOT", "QUICK_START", "DATA_DICTIONARY", "BRIEF_MATRIX",
        "DELIVERABLES", "6_LENS_PROMPTS", "DLR_CAPTURE", "CANON_SYNC",
        "ASSUMPTIONS", "CLAIMS", "PATCH_LOG", "CI_DASHBOARD",
    ]
    current = wb.sheetnames
    new_order = []
    for name in desired_order:
        if name in current:
            new_order.append(current.index(name))
    # Append any remaining sheets not in desired_order
    for idx, name in enumerate(current):
        if idx not in new_order:
            new_order.append(idx)
    wb.move_sheet("BOOT", offset=-(len(current) - 1))  # Move BOOT to front

    # 5. Save
    OUTPUT.parent.mkdir(parents=True, exist_ok=True)
    wb.save(str(OUTPUT))
    print(f"Workbook saved to {OUTPUT}")
    print(f"  Sheets: {wb.sheetnames}")
    print("  Named tables: ", end="")
    for ws in wb.worksheets:
        for t in ws.tables.values():
            print(f"{t.displayName} ", end="")
    print()


if __name__ == "__main__":
    main()

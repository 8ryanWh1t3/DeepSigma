[{"additions":371,"body":"## Summary\\n- add machine-readable feature catalog JSON\\n- add catalog renderer script and generated docs page\\n- wire feature coverage into KPI PR comment output\\n- add top-level README links to feature catalog assets\\n\\n## Verification\\n- make feature-catalog\\n- python -m py_compile scripts/kpi_run.py scripts/render_feature_catalog.py","changedFiles":6,"createdAt":"2026-02-23T17:49:19Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T17:52:12Z","number":366,"title":"Build 90: add feature catalog artifacts and README links","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/366"},{"additions":510,"body":"## Build 89: Deterministic Governance Boundary + Cryptographic Proof\n\n### What this implements\n- Canonical runner: `scripts/run.py` routes through `scripts/pre_exec_gate.py` before execution.\n- Default deny posture in pre-exec gate:\n  - execution blocked unless authority contract has `allow_execution=true`.\n- Halt on ambiguity in pre-exec gate:\n  - conflicting authority claims fail hard.\n  - missing governance inputs fail hard.\n- Cryptographic proof bundle:\n  - `scripts/crypto_proof.py` generates `runs/proof_bundle.json` with\n    - `intent_hash`\n    - `input_snapshot_hash`\n    - `authority_contract_hash`\n    - `outputs_hash`\n  - optional Ed25519 verification transcript if key/signature files are present.\n- Audit-neutral proof export:\n  - `scripts/export_audit_neutral_pack.py` generates proof bundle and exports core artifacts + ambiguity policy.\n- Replay validation:\n  - `scripts/replay_run.py` requires and validates proof-chain fields.\n- Intent validation:\n  - `scripts/validate_intent_packet.py` enforces required fields + TTL validity.\n- Milestone gate updated:\n  - `scripts/validate_v2_1_0_milestone.py` now includes semantic checks for the Build 89 scripts.\n- Make targets:\n  - `make run`\n  - `make proof`\n\n### Validation\n- `python scripts/validate_intent_packet.py --self-check`\n- `python scripts/crypto_proof.py --self-check`\n- `python scripts/pre_exec_gate.py --self-check`\n- `python scripts/export_audit_neutral_pack.py --self-check`\n- `python scripts/replay_run.py --self-check`\n- `make milestone-gate`\n- `ruff check` on changed scripts\n","changedFiles":9,"createdAt":"2026-02-23T17:42:08Z","deletions":167,"labels":[],"mergedAt":"2026-02-23T17:44:29Z","number":365,"title":"Build 89: deterministic governance boundary + cryptographic proof","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/365"},{"additions":283,"body":"## What this adds\n- New schema: `schemas/core/decision_episode_chain.schema.json`\n- New validator: `scripts/validate_decision_episode_chain.py`\n- Milestone gate now requires and validates decision episode chain schema + validator self-check\n\n## Hardening upgrades\n- Strengthened self-check rigor with negative-path assertions:\n  - `scripts/pre_exec_gate.py`\n  - `scripts/verify_authority_signature.py`\n  - `scripts/replay_run.py`\n  - `scripts/export_audit_neutral_pack.py`\n- Audit pack now supports exporting a bound chain artifact (`decision_episode_chain.json`) with:\n  - `intent_hash`\n  - `authority_hash`\n  - `snapshot_hash`\n  - `outputs_hash`\n  - `chain_hash`\n\n## Validation run\n- `python scripts/validate_decision_episode_chain.py --self-check`\n- `python scripts/pre_exec_gate.py --self-check`\n- `python scripts/verify_authority_signature.py --self-check`\n- `python scripts/replay_run.py --self-check`\n- `python scripts/export_audit_neutral_pack.py --self-check`\n- `make milestone-gate`\n- `ruff check` on changed scripts\n","changedFiles":12,"createdAt":"2026-02-23T17:34:21Z","deletions":119,"labels":[],"mergedAt":"2026-02-23T17:46:15Z","number":364,"title":"Hardening: decision episode binding chain + validator + stricter self-checks","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/364"},{"additions":693,"body":"## Build 88: No-Theater Milestone Gate\n\n### What changed\n- Upgraded `scripts/validate_v2_1_0_milestone.py` from existence-only checks to semantic enforcement.\n- Validator now fails if proof scripts contain placeholder tokens (`TODO`, `stub`, etc.).\n- Validator now requires each proof script to:\n  - emit `PASS:`/`FAIL:` conventions\n  - pass `--self-check` with exit code 0\n- Added semantic checks for:\n  - `schemas/intent_packet.schema.json` required fields\n  - `governance/decision_invariants.md` core invariant content\n\n### Proof scripts upgraded from stubs to executable checks\n- `scripts/pre_exec_gate.py`\n- `scripts/validate_claim_evidence_authority.py`\n- `scripts/verify_authority_signature.py`\n- `scripts/idempotency_guard.py`\n- `scripts/capture_run_snapshot.py`\n- `scripts/replay_run.py`\n- `scripts/export_audit_neutral_pack.py`\n\n### Validation\n- `make milestone-gate` (PASS)\n- `ruff check` on all changed scripts (PASS)\n","changedFiles":8,"createdAt":"2026-02-23T17:15:43Z","deletions":30,"labels":[],"mergedAt":"2026-02-23T17:19:42Z","number":363,"title":"Build 88: no-theater milestone gate (semantic enforcement)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/363"},{"additions":1008,"body":"## What this adds\n- New audit script: `scripts/roadmap_audit.sh`\n- Generated outputs under `release_kpis/roadmap_audit/`:\n  - `ROADMAP_GROUPING.md`\n  - `REDUNDANCY_SUGGESTIONS.md` and `REDUNDANCY_SUGGESTIONS.json`\n  - `ROADMAP_DASHBOARD.md` and `ROADMAP_DASHBOARD.json`\n  - `MISALIGNMENTS.json`\n  - raw snapshots: `issues_all.json`, `prs_all.json`, `labels_existing.json`, `labels_missing.json`\n\n## Run mode\n- Executed in read-only mode (`APPLY_FIXES=false`)\n- No relabel/close operations performed\n\n## Quick results\n- Missing required labels: 0\n- Redundancy suggestions: 0\n- Misalignments: 22\n- Open issues by version: v2.0.7=9, v2.1.0=7, v2.1.1=3, UNVERSIONED=22\n","changedFiles":11,"createdAt":"2026-02-23T17:01:23Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T17:03:31Z","number":361,"title":"Build 87: roadmap alignment audit (A-D)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/361"},{"additions":314,"body":"## What this implements\n- Adds `scripts/validate_v2_1_0_milestone.py` and `make milestone-gate`\n- Enforces milestone gate in CI (`.github/workflows/ci.yml`) and KPI pipelines (`.github/workflows/kpi.yml`, `.github/workflows/kpi_gate.yml`)\n- Adds required v2.1.0 proof-point stubs (intent schema, pre-exec/accountability scripts, invariants doc)\n- Wires layer-to-KPI mapping into `scripts/kpi_run.py` and appends Layer Coverage to `release_kpis/PR_COMMENT.md`\n\n## Validation run\n- `make milestone-gate`\n- `make kpi`\n- `ruff check` on changed Python files\n\n## Notes\n- Stubs are intentionally minimal to make milestone criteria mechanically enforceable while implementation iterates.\n","changedFiles":23,"createdAt":"2026-02-23T16:54:25Z","deletions":144,"labels":[],"mergedAt":"2026-02-23T16:58:00Z","number":360,"title":"Build 87: enforce v2.1.0 milestone gate + layer coverage KPI wiring","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/360"},{"additions":136,"body":"## What this ships\n- Adds layered architecture spec for decision infrastructure (`specs/decision_infrastructure_model.md`)\n- Adds layer-to-KPI mapping artifact (`release_kpis/layer_kpi_mapping.json`)\n- Adds positioning manifesto + one-page executive briefing (`docs/positioning/positioning_manifesto.md`, `docs/positioning/executive_briefing_one_page.md`)\n- Updates README with explicit positioning shift and links to the new artifacts\n\n## External gate\n- Created milestone issue: #358\n\n## Why\nThis formalizes A+B+D from the hardening plan and implements C narrative framing without changing runtime behavior.\n","changedFiles":5,"createdAt":"2026-02-23T16:40:01Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T16:42:07Z","number":359,"title":"v2.1.0: decision infrastructure hardening framing (A+B+D+C)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/359"},{"additions":461,"body":"## Summary\\n- add formal KPI artifact eligibility rules ()\\n- apply tier caps in  so KPIs cannot exceed evidence-tier limits\\n- add  to emit confidence + bands artifacts\\n- wire confidence/bands into , Makefile, and KPI workflow uploads\\n- surface eligibility + confidence artifacts in README\\n\\n## Added artifacts\\n- release_kpis/kpi_confidence.json\\n- release_kpis/kpi_bands_v2.0.6.json\\n\\n## Verification\\n- make kpi\\n- ruff check . --select E,F,W --ignore E501\\n- python -m compileall scripts/kpi_merge.py scripts/kpi_confidence_bands.py scripts/kpi_run.py","changedFiles":19,"createdAt":"2026-02-23T16:32:40Z","deletions":144,"labels":[],"mergedAt":"2026-02-23T16:36:36Z","number":357,"title":"KPI hardening: artifact eligibility tiers + confidence bands","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/357"},{"additions":748,"body":"## Summary\\n- add nonlinear stability engine (Wrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/stability_v2.0.6.json\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/stability_simulation_v2.0.6.json\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/stability_adjusted_forecast.json\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/nonlinear_stability_report.md)\\n- define SSI math and instability gating thresholds\\n- add stability-adjusted roadmap forecast\\n- simulate instability scenarios on v2.0.6 baseline\\n- wire stability into python scripts/kpi_run.py\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/kpi_v2.0.6_merged.json\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/radar_v2.0.6.png\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/radar_v2.0.6.svg\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/badge_latest.svg\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/KPI_GATE_REPORT.md\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/kpi_trend.png\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/kpi_trend.svg\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/radar_composite_latest.png\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/radar_composite_latest.svg\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/radar_composite_latest.md\npython scripts/roadmap_forecast.py\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/roadmap_forecast.json\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/roadmap_forecast.md\npython scripts/render_roadmap_badge.py\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/roadmap_badge.svg\npython scripts/render_roadmap_timeline.py\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/roadmap_timeline.svg\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/roadmap_timeline.md\npython scripts/roadmap_scope_gate.py\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/ROADMAP_SCOPE_GATE_REPORT.md\npython scripts/nonlinear_stability.py\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/stability_v2.0.6.json\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/stability_simulation_v2.0.6.json\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/stability_adjusted_forecast.json\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/nonlinear_stability_report.md\nbash scripts/export_repo_telemetry.sh\npython scripts/tec_estimate.py\nWrote TEC artifacts to release_kpis/\nWrote: release_kpis/PR_COMMENT.md and artifact uploads\\n- surface stability artifacts in README\\n\\n## Verification\\n- make stability\\n- make kpi\\n- python -m compileall scripts/nonlinear_stability.py scripts/kpi_run.py","changedFiles":17,"createdAt":"2026-02-23T16:15:43Z","deletions":120,"labels":[],"mergedAt":"2026-02-23T16:26:30Z","number":341,"title":"Stability: SSI + drift acceleration + TEC sensitivity + v2.0.6 simulation","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/341"},{"additions":763,"body":"## Summary\\n- freeze v2.1.0 scope and stage v2.1.1 as dormant\\n- add machine-readable roadmap at roadmap/roadmap.json\\n- add roadmap KPI forecast artifacts + timeline + badge\\n- add roadmap scope drift gate script and CI workflow\\n- wire roadmap checks into KPI workflows and README\\n\\n## Verification\\n- make roadmap-refresh\\n- make kpi\\n- gh issues created for lock/epic/staging","changedFiles":26,"createdAt":"2026-02-23T15:50:13Z","deletions":158,"labels":[],"mergedAt":"2026-02-23T15:52:12Z","number":336,"title":"Roadmap discipline: v2.1.0 scope freeze + v2.1.1 staging + forecast/gate","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/336"},{"additions":117,"body":"## Summary\\n- add canonical wiki index page\\n- update Home and Sidebar navigation with release/evidence surfaces\\n- fix stale release link in Creative Director Suite\\n- refresh roadmap to current A-D tracks\\n- update wiki footer release pointer\\n\\n## Validation\\n- python src/tools/mermaid_audit.py (PASS)","changedFiles":7,"createdAt":"2026-02-23T15:34:39Z","deletions":14,"labels":[],"mergedAt":"2026-02-23T15:36:29Z","number":331,"title":"Docs: Wiki structure refresh and navigation cleanup","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/331"},{"additions":212,"body":"## Summary\\n- expand canonical Mermaid set to 9 diagrams\\n- add release preflight, KPI confidence bands, and DISR dual-mode architecture diagrams\\n- add Mermaid archive index and relink stale docs to archived diagrams\\n- update mermaid audit guardrail for canonical 9\\n\\n## Validation\\n- python src/tools/mermaid_audit.py (PASS)","changedFiles":23,"createdAt":"2026-02-23T15:28:36Z","deletions":36,"labels":[],"mergedAt":"2026-02-23T15:30:35Z","number":330,"title":"Docs: Mermaid canonical refresh + archive structure","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/330"},{"additions":73,"body":"## Summary\n- Adds a dedicated `release-preflight` CI job for tag builds\n- Enforces strict release checks before publish jobs start\n- Requires release tag commit to match `origin/main` HEAD\n\n## Details\n- `scripts/release_check.py`: adds `--require-main-head` / `RELEASE_CHECK_REQUIRE_MAIN_HEAD=1`\n- `Makefile`: adds `release-check-strict`\n- `.github/workflows/ci.yml`: adds `release-preflight` and makes `publish` + `release-artifacts` depend on it\n\n## Why\nPrevents stale/mis-pointed tags from reaching PyPI/GHCR publish steps.\n\n## Validation\n- `python scripts/release_check.py --tag v2.0.6 --require-main-head`\n- `python -m py_compile scripts/release_check.py`\n","changedFiles":3,"createdAt":"2026-02-23T15:09:04Z","deletions":3,"labels":[],"mergedAt":"2026-02-23T15:10:47Z","number":329,"title":"Harden release flow: strict tag preflight before publish","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/329"},{"additions":3,"body":"## Summary\n- Adds explicit least-privilege workflow permissions to \\.github/workflows/reencrypt_benchmark.yml\n- Resolves CodeQL alert for missing workflow permissions\n\n## Change\n- Added:\\n  permissions:\\n    contents: read\n\n## Validation\n- Workflow-only metadata change; no runtime logic modified.","changedFiles":1,"createdAt":"2026-02-23T14:52:11Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T14:58:45Z","number":328,"title":"Fix CodeQL: explicit permissions in benchmark workflow","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/328"},{"additions":2158,"body":"Implements v2.0.6 normalization:\\n\\n- Bump package + KPI version sources to 2.0.6 / v2.0.6\\n- Add changelog entry for 2.0.6\\n- Regenerate KPI/TEC artifacts for v2.0.6 (radar, badge, PR comment, history)\\n- Add version sync gate script and enforce in CI\\n- Extend release_check to validate release_kpis/VERSION.txt against tag\\n\\nThis resolves Build 82 audit mismatch where artifacts and metadata still reflected v2.0.5.","changedFiles":25,"createdAt":"2026-02-23T14:21:49Z","deletions":274,"labels":[],"mergedAt":"2026-02-23T14:23:44Z","number":310,"title":"Normalize v2.0.6 versioning and KPI artifacts","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/310"},{"additions":851,"body":"Replacement for closed-unmerged #308 after branch restoration.\\n\\nIncludes C-TEC v1.0, README/wiki updates, release notes v2.0.6, mermaid pipeline, and KPI workflow dependency fix.","changedFiles":27,"createdAt":"2026-02-23T14:09:05Z","deletions":80,"labels":[],"mergedAt":"2026-02-23T14:11:11Z","number":309,"title":"Add TEC/C-TEC pipeline + docs/wiki/mermaid updates","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/309"},{"additions":154,"body":"Reopens the closed-unmerged #305 content after branch restoration.\\n\\nCloses #289","changedFiles":4,"createdAt":"2026-02-23T13:45:20Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T13:46:56Z","number":306,"title":"DISR-210: benchmark suite for MTTR + throughput + CPU/RAM","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/306"},{"additions":153,"body":"## Summary\n- add explicit authority ledger load/export support (`json` and `ndjson`) to make sealed entries shareable\n- add `scripts/export_authority_ledger.py` and `make authority-ledger-export`\n- preserve/strengthen precedence enforcement (`DRI > APPROVER > SYSTEM`) for privileged actions\n- keep versioned ledger snapshots with chained hashes and provenance updates\n- add focused tests for snapshot version increments, precedence rejection, and exportability\n\n## Validation\n- `python -m pytest tests/test_disr_authority_ledger_v1.py tests/test_disr_security_ops.py tests/test_disr_security_pipeline.py -q`\n- `python -m ruff check src/deepsigma/security/authority_ledger.py src/deepsigma/security/__init__.py scripts/export_authority_ledger.py tests/test_disr_authority_ledger_v1.py`\n- `make authority-ledger-export`\n\nCloses #285\n","changedFiles":5,"createdAt":"2026-02-23T13:33:53Z","deletions":41,"labels":[],"mergedAt":"2026-02-23T13:36:43Z","number":304,"title":"DISR-210: authority ledger v1 export + snapshot/precedence hardening","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/304"},{"additions":205,"body":"## Summary\n- add `scripts/security_audit_pack.py` to generate a shareable `security_audit_pack/` bundle\n- export events, authority ledger, security/scalability metrics, policy/config artifacts, and security docs\n- emit `manifest.json` and `versions.json` for reconstructable audit evidence\n- wire `make security-audit-pack` target into `Makefile`\n- integrate audit pack into `scripts/pilot_pack.py` so `pilot_pack/security_audit_pack/` is included\n- add tests for audit pack generation and strict-mode behavior\n\n## Validation\n- `python -m pytest tests/test_security_audit_pack.py -q`\n- `python -m ruff check scripts/security_audit_pack.py scripts/pilot_pack.py tests/test_security_audit_pack.py`\n- `make security-audit-pack`\n\nCloses #291\n","changedFiles":5,"createdAt":"2026-02-23T13:29:35Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T13:31:40Z","number":303,"title":"DISR-210: add one-command Security Audit Pack export","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/303"},{"additions":103,"body":"## Summary\n- extend `scripts/crypto_misuse_scan.py` policy checks for provider drift and override violations\n- fail gate when `default_provider` is not in `allowed_providers`\n- emit HIGH finding when `DEEPSIGMA_CRYPTO_PROVIDER` is set to a blocked provider\n- emit MEDIUM provider drift finding when env override differs from policy default but remains allowed\n- add tests covering provider drift and blocked provider override detection\n\n## Validation\n- `python -m pytest tests/test_crypto_misuse_scan.py -q`\n- `python -m ruff check scripts/crypto_misuse_scan.py tests/test_crypto_misuse_scan.py`\n- `make security-gate`\n\nCloses #290\n","changedFiles":2,"createdAt":"2026-02-23T13:24:35Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T13:27:01Z","number":302,"title":"DISR-210: extend security gate with provider drift and override checks","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/302"},{"additions":245,"body":"## Summary\n- rework reencrypt pipeline to stream records in bounded batches instead of loading full files in memory\n- add batch checkpointing during execution so resume can continue from persisted `line_offset` per file\n- add idempotency key handling to prevent accidental mismatched resumes\n- add CLI flags for `--batch-size` and `--idempotency-key`\n- keep dry-run + completed-checkpoint shortcuts intact\n\n## Validation\n- `python -m pytest tests/test_disr_security_ops.py tests/test_disr_security_pipeline.py tests/test_cli_smoke.py -q`\n- `python -m ruff check src/deepsigma/security/reencrypt.py src/deepsigma/cli/security.py tests/test_disr_security_ops.py tests/test_cli_smoke.py`\n\nCloses #288\n","changedFiles":4,"createdAt":"2026-02-23T13:20:50Z","deletions":26,"labels":[],"mergedAt":"2026-02-23T13:22:38Z","number":301,"title":"DISR-210: streaming batched reencrypt with idempotent checkpoint/resume","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/301"},{"additions":517,"body":"## Summary\n- add runtime crypto policy loader/enforcer for provider, algorithm, TTL bounds, and envelope version support\n- add policy artifacts: `governance/security_crypto_policy.json` + `schemas/core/security_crypto_policy.schema.json`\n- enforce policy at runtime in provider resolution, key rotation TTL validation, and encrypted envelope writes\n- extend `scripts/crypto_misuse_scan.py` to fail CI on policy/config drift and envelope policy violations\n- add envelope migration plan docs (`docs/docs/security/ENVELOPE_VERSIONING.md`) and update DISR docs\n- add focused tests for policy, scanner policy violations, provider blocking, and TTL enforcement\n\n## Validation\n- `python -m pytest tests/test_disr_policy.py tests/test_disr_provider_registry.py tests/test_disr_security_ops.py tests/test_credibility_store_encryption.py tests/test_crypto_misuse_scan.py -q`\n- `make security-gate`\n\nCloses #287\n","changedFiles":14,"createdAt":"2026-02-23T13:16:02Z","deletions":4,"labels":[],"mergedAt":"2026-02-23T13:17:56Z","number":300,"title":"DISR-210: crypto policy engine + envelope version governance","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/300"},{"additions":398,"body":"## Summary\n- add canonical security event model + query helper with strict event-type allowlist\n- add security event schema: `schemas/core/security_event.schema.json`\n- emit `REENCRYPT_DONE` (with legacy compatibility retained), `KEY_ROTATED`, `PROVIDER_CHANGED`, and `NONCE_REUSE_DETECTED` into sealed security event log\n- add CLI support for querying events and emitting provider-change events\n- wire provider policy resolution to optionally emit provider-change telemetry\n- include security event logs in pilot pack outputs\n- update DISR demo docs for the event set\n\n## Validation\n- `python -m pytest tests/test_security_events.py tests/test_disr_provider_registry.py tests/test_cli_smoke.py tests/test_disr_security_ops.py tests/test_disr_security_pipeline.py -q`\n- `ruff check src/deepsigma/security/events.py src/deepsigma/security/providers/__init__.py src/deepsigma/security/rotate_keys.py src/deepsigma/security/reencrypt.py src/deepsigma/cli/security.py scripts/crypto_misuse_scan.py scripts/reencrypt_demo.py scripts/reencrypt_benchmark.py scripts/pilot_pack.py tests/test_security_events.py tests/test_disr_provider_registry.py tests/test_cli_smoke.py`\n\nCloses #286\n","changedFiles":15,"createdAt":"2026-02-23T13:04:17Z","deletions":30,"labels":[],"mergedAt":"2026-02-23T13:10:13Z","number":299,"title":"DISR-210: sealed security events coverage for telemetry lane","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/299"},{"additions":151,"body":"## Summary\n- regenerate DISR KPI artifacts after security demo + benchmark reset\n- refresh `kpi_v2.0.5_merged.json` and radar/badge/composite outputs\n- update PR comment notes to reflect Economic/Scalability auto-derivation with evidence gating\n- include current security gate reports in `release_kpis/`\n\n## Commands run\n- `make security-demo`\n- `make reencrypt-benchmark ARGS=\"--reset-dataset\"`\n- `make kpi`\n\n## Result\n- Economic + Scalability no longer stale/maxed in merged KPI\n- PR comment language now aligned with Build 81 scoring path\n","changedFiles":20,"createdAt":"2026-02-23T04:28:08Z","deletions":133,"labels":[],"mergedAt":"2026-02-23T04:31:13Z","number":298,"title":"Refresh v2.0.5 KPI artifacts and scoring notes","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/298"},{"additions":161,"body":"## Summary\\n- add Authority Ledger v1 schema/version metadata per entry\\n- enforce authority precedence (DRI > Approver > System) for privileged authorization\\n- emit versioned snapshot file with ledger hash + provenance on each append\\n- document snapshot + precedence behavior in key lifecycle docs\\n- add tests for snapshot/provenance and precedence enforcement\\n\\n## Validation\\n- ........................                                                 [100%]\n=============================== warnings summary ===============================\ntests/test_disr_security_ops.py::test_reencrypt_dry_run_writes_checkpoint\ntests/test_disr_security_pipeline.py::test_reencrypt_dry_run_then_resume_completed\ntests/test_cli_smoke.py::TestSecurityCLI::test_security_reencrypt_dry_run_json\n  /Users/bryanwhite/Documents/DeepSigma-v0.3.0/src/credibility_engine/store.py:103: RuntimeWarning: encrypt_at_rest=True but DEEPSIGMA_MASTER_KEY is unset; falling back to plaintext persistence\n    self._initialize_encryption()\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n24 passed, 3 warnings in 1.18s\\n- All checks passed!\\n\\nCloses #285","changedFiles":3,"createdAt":"2026-02-23T04:19:37Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T04:21:25Z","number":297,"title":"DISR-210: Authority Ledger v1 snapshots and precedence","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/297"},{"additions":541,"body":"## Summary\n- add `action_contract` module with signed authority contract creation/validation\n- add schema: `schemas/core/action_contract.schema.json`\n- enforce valid signed action contract for both rotate and reencrypt flows\n- write authority ledger entries for both action types (`AUTHORIZED_KEY_ROTATION`, `AUTHORIZED_REENCRYPT`)\n- extend security CLI with action-contract file support for both commands\n- update benchmark/demo scripts to pass authority contract context\n- add tests for contract validity/expiry/signature and updated security flows\n\n## Validation\n- `python -m pytest -q tests/test_disr_action_contract.py tests/test_disr_security_ops.py tests/test_disr_security_pipeline.py tests/test_cli_smoke.py tests/test_reencrypt_benchmark_metrics.py`\n- `python -m ruff check src/deepsigma/security/action_contract.py src/deepsigma/security/authority_ledger.py src/deepsigma/security/rotate_keys.py src/deepsigma/security/reencrypt.py src/deepsigma/cli/security.py scripts/reencrypt_benchmark.py scripts/reencrypt_demo.py tests/test_disr_action_contract.py tests/test_disr_security_ops.py tests/test_disr_security_pipeline.py tests/test_cli_smoke.py`\n\nCloses #284\n","changedFiles":15,"createdAt":"2026-02-23T04:07:38Z","deletions":75,"labels":[],"mergedAt":"2026-02-23T04:17:15Z","number":296,"title":"DISR-210: authority action contract enforcement for rotate/reencrypt","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/296"},{"additions":148,"body":"## Summary\n- add optional stub providers implementing `CryptoProvider`:\n  - `aws-kms`\n  - `gcp-kms`\n  - `azure-kv`\n- register stubs in provider registry without introducing cloud SDK dependencies\n- keep stubs fail-closed (`NotImplementedError`) until deployment adapters are implemented\n- export stub classes via `deepsigma.security`\n- document no-secrets/no-runtime-dependency guidance in DISR docs\n- add tests verifying registration and fail-closed behavior\n\n## Validation\n- `python -m pytest -q tests/test_disr_provider_registry.py tests/test_credibility_store_encryption.py tests/test_disr_security_ops.py`\n- `python -m ruff check src/deepsigma/security/providers src/deepsigma/security/__init__.py tests/test_disr_provider_registry.py`\n\nCloses #283\n","changedFiles":7,"createdAt":"2026-02-23T04:00:43Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T04:02:30Z","number":295,"title":"DISR-210: optional cloud KMS provider stubs (AWS/GCP/Azure)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/295"},{"additions":291,"body":"## Summary\n- add `LocalKeyStoreProvider` with deterministic keystore format (`schema_version`, `provider`, sorted `keys`)\n- keep `LocalKeyringProvider` as compatibility alias, while making `local-keystore` the default provider selection\n- wire `CredibilityStore` encryption to provider-managed key metadata\n- emit crypto envelope v1 fields on encrypted records: `key_id`, `key_version`, `provider`, `alg`, `nonce`, `aad`, `created_at`, `expires_at`\n- extend crypto envelope schema and DISR docs to reflect v1 field contract\n- add/adjust tests for provider registry defaults and encrypted envelope metadata\n\n## Validation\n- `python -m pytest -q tests/test_disr_provider_registry.py tests/test_credibility_store_encryption.py tests/test_disr_security_ops.py tests/test_disr_keyring.py`\n- `python -m pytest -q tests/test_crypto_misuse_scan.py`\n- `python -m ruff check src/deepsigma/security/providers src/credibility_engine/store.py tests/test_disr_provider_registry.py tests/test_credibility_store_encryption.py`\n\nCloses #282\n","changedFiles":9,"createdAt":"2026-02-23T03:57:15Z","deletions":52,"labels":[],"mergedAt":"2026-02-23T03:59:03Z","number":294,"title":"DISR-210: LocalKeyStoreProvider default + crypto envelope v1","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/294"},{"additions":306,"body":"## Summary\n- add `CryptoProvider` abstract interface for key lifecycle operations\n- add `LocalKeyringProvider` default implementation over existing JSON keyring\n- add provider registry with policy-based resolution (`resolve_provider_name`, `provider_from_policy`)\n- expose provider APIs via `deepsigma.security`\n- add tests for registry behavior, policy precedence, and local provider lifecycle\n\n## Validation\n- `python -m pytest -q tests/test_disr_provider_registry.py tests/test_disr_keyring.py tests/test_disr_security_ops.py`\n- `python -m ruff check src/deepsigma/security/providers src/deepsigma/security/__init__.py tests/test_disr_provider_registry.py`\n\nCloses #281\n","changedFiles":6,"createdAt":"2026-02-23T03:49:03Z","deletions":4,"labels":[],"mergedAt":"2026-02-23T03:53:16Z","number":293,"title":"DISR-210: CryptoProvider interface + provider registry","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/293"},{"additions":287,"body":"## Summary\n- add issue intake workflow for `v2.1.0 (DISR Architecture)`\n- auto-add issues to Project #2, set `Status=Todo`, and sync `Lane`\n- enforce exactly one `lane:*` label for v2.1.0 intake\n- document lane labels in label policy\n\n## Notes\n- Uses `PROJECT_AUTOMATION_TOKEN` if present, otherwise `GITHUB_TOKEN`.\n","changedFiles":3,"createdAt":"2026-02-23T03:41:52Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T03:43:24Z","number":292,"title":"Automate v2.1.0 project intake with lane enforcement","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/292"},{"additions":97,"body":"## Summary\n- mark default demo and benchmark metrics as `dry_run`/`simulated` with `kpi_eligible=false`\n- cap `economic_measurability` and `scalability` KPI scores at 4.0 unless evidence is real workload\n- add explicit signing placeholder disclosure to security demo metrics/docs\n- add test coverage for simulated score caps and real-workload eligibility paths\n\n## Validation\n- `ruff check src scripts tests`\n- `pytest -q tests/test_kpi_compute_security_metrics.py tests/test_reencrypt_benchmark_metrics.py`\n- `make security-demo && make reencrypt-benchmark && python scripts/kpi_compute.py`\n","changedFiles":8,"createdAt":"2026-02-23T03:29:52Z","deletions":4,"labels":[],"mergedAt":"2026-02-23T03:30:36Z","number":278,"title":"DISR: honesty hardening for demo metrics and KPI caps","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/278"},{"additions":2158,"body":"## Summary\n- bump package/governance/release metadata to `v2.0.5` / `GOV-2.0.5`\n- add release notes for v2.0.5 in both release-doc surfaces\n- update README and stability/pilot scorecard release pointers\n- advance KPI release pointer and regenerate v2.0.5 radar/composite artifacts\n- include DISR security + scalability metric artifacts for release evidence\n\n## Validation\n- `make kpi`\n- `make security-gate`\n\n","changedFiles":26,"createdAt":"2026-02-23T03:19:55Z","deletions":196,"labels":[],"mergedAt":"2026-02-23T03:20:53Z","number":277,"title":"Release v2.0.5: DISR completion and KPI evidence refresh","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/277"},{"additions":289,"body":"## Summary\n- add deterministic DISR benchmark script: `scripts/reencrypt_benchmark.py`\n- benchmark runs against a generated 100k-record fixture by default\n- log wall-clock, CPU, RSS peak, throughput, and dataset hash\n- write outputs to:\n  - `release_kpis/scalability_metrics.json`\n  - `artifacts/benchmarks/reencrypt/benchmark_summary.json`\n- wire benchmark command into `make reencrypt-benchmark`\n- include scalability metrics/artifacts in pilot pack when present\n- surface benchmark path in security demo docs and README\n- add tests for benchmark metrics + KPI parser support\n\n## Validation\n- `ruff check src scripts tests`\n- `pytest -q tests/test_reencrypt_benchmark_metrics.py tests/test_kpi_compute_security_metrics.py`\n- `make reencrypt-benchmark`\n- `make security-gate`\n\nCloses #255\n","changedFiles":7,"createdAt":"2026-02-23T03:15:42Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T03:16:25Z","number":276,"title":"DISR PR8: add reencrypt scalability benchmark telemetry","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/276"},{"additions":136,"body":"## Summary\n- extend `scripts/reencrypt_demo.py` to compute quantified security metrics:\n  - MTTR seconds\n  - reencrypt records/sec\n  - reencrypt MB/minute\n- write metrics to `release_kpis/security_metrics.json`\n- wire KPI telemetry parser to derive `economic_measurability` from the metrics file\n- document the metric outputs in `docs/docs/security/DEMO_10_MIN.md`\n- add tests for security-metrics KPI computation behavior\n\n## Validation\n- `ruff check src scripts tests`\n- `pytest -q tests/test_kpi_compute_security_metrics.py tests/test_disr_security_pipeline.py`\n- `make security-demo && python scripts/kpi_compute.py`\n\nCloses #256\n","changedFiles":4,"createdAt":"2026-02-23T03:10:10Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T03:12:07Z","number":275,"title":"DISR PR7: quantified security metrics and KPI parsing","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/275"},{"additions":108,"body":"## Summary\n- add dedicated DISR pipeline unit tests covering:\n  - keyring TTL expiry boundary behavior\n  - authority-gated rotation version increments + ledger chain linkage\n  - reencrypt dry-run -> completed checkpoint resume behavior\n\n## Validation\n- `ruff check src scripts tests`\n- `pytest -q tests/test_disr_keyring.py tests/test_disr_security_ops.py tests/test_disr_security_pipeline.py`\n\nCloses #266\n","changedFiles":1,"createdAt":"2026-02-23T03:07:46Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T03:08:29Z","number":274,"title":"DISR PR6: expand keyring/rotation/reencrypt unit coverage","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/274"},{"additions":154,"body":"## Summary\n- add DISR 10-minute demo doc with reproducible commands and expected outputs\n- add `scripts/reencrypt_demo.py` and `make security-demo` for rotation + reencrypt dry-run rehearsal\n- wire DISR docs and security artifacts into `pilot_pack`\n- add DISR drill references in README and pilot README\n\n## Validation\n- `ruff check src scripts tests`\n- `pytest -q tests/test_disr_security_ops.py tests/test_cli_smoke.py tests/test_security_events.py`\n- `make security-demo`\n- `make security-gate`\n- `make pilot-pack`\n\nCloses #259\nCloses #267\nCloses #268\n","changedFiles":8,"createdAt":"2026-02-23T03:05:38Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T03:06:26Z","number":273,"title":"DISR PR5: 10-minute security demo and pilot-pack evidence","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/273"},{"additions":209,"body":"## Summary\n- enforce authority approval context on `security rotate-keys`\n- emit signed `AUTHORIZED_KEY_ROTATION` security events\n- append chained entries to `data/security/authority_ledger.json`\n- add authority approval chain requirements to key lifecycle docs\n- include authority ledger artifact in pilot pack when present\n\n## Validation\n- `pytest -q tests/test_disr_security_ops.py tests/test_cli_smoke.py tests/test_security_events.py`\n- `ruff check src scripts tests`\n- `make security-gate`\n\nCloses #254\n","changedFiles":9,"createdAt":"2026-02-23T03:00:09Z","deletions":7,"labels":[],"mergedAt":"2026-02-23T03:02:08Z","number":272,"title":"DISR PR4: authority-gated key rotation approvals","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/272"},{"additions":472,"body":"## Summary\n- add sealed hash-chained security events (`KEY_ROTATED`, `REENCRYPT_COMPLETED`)\n- add deterministic crypto misuse scanner and `make security-gate`\n- add `security_gate.yml` workflow to block on HIGH findings and publish reports\n- add tests for event chain integrity and scanner findings\n\n## Validation\n- `pytest -q tests/test_crypto_misuse_scan.py tests/test_security_events.py`\n- `pytest -q tests/test_disr_security_ops.py tests/test_cli_smoke.py`\n- `make security-gate`\n- `ruff check src scripts tests`\n\nCloses #264\nCloses #258\nCloses #265\n","changedFiles":9,"createdAt":"2026-02-23T02:56:02Z","deletions":2,"labels":[],"mergedAt":"2026-02-23T02:56:48Z","number":271,"title":"DISR PR3: security gate + sealed security events","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/271"},{"additions":532,"body":"## Scope\nImplements DISR runtime primitives:\n- #262 Add rotate_keys command\n- #263 Add reencrypt job with checkpointing + rollback-oriented flow\n\n## Changes\n- Added runtime modules:\n  - src/deepsigma/security/rotate_keys.py\n  - src/deepsigma/security/reencrypt.py\n- Added CLI namespace:\n  - src/deepsigma/cli/security.py\n  - wired into src/deepsigma/cli/main.py\n- Added tests:\n  - tests/test_disr_security_ops.py\n  - extended tests/test_cli_smoke.py for security commands\n\n## Behavior\n- deepsigma security rotate-keys creates a new key version and emits KEY_ROTATED event + audit entry.\n- deepsigma security reencrypt supports --dry-run, --checkpoint, and --resume; actual run performs rekey and emits REENCRYPT_COMPLETED audit event.\n\n## Validation\n- pytest -q tests/test_disr_keyring.py tests/test_disr_security_ops.py tests/test_cli_smoke.py -k 'security or keyring'\n- ruff check src/deepsigma/security src/deepsigma/cli/security.py tests/test_disr_security_ops.py tests/test_cli_smoke.py\n","changedFiles":6,"createdAt":"2026-02-23T02:48:46Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T02:52:06Z","number":270,"title":"DISR PR2: rotate-keys + reencrypt runtime commands","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/270"},{"additions":413,"body":"## Scope\\nImplements the DISR foundation slice:\\n- #257 Security spec + key lifecycle docs\\n- #260 Canonical crypto envelope metadata schema\\n- #261 Keyring + TTL model\\n\\n## Changes\\n- Added docs:\\n  - docs/docs/security/DISR.md\\n  - docs/docs/security/KEY_LIFECYCLE.md\\n  - docs/docs/security/RECOVERY_RUNBOOK.md\\n- Added schema:\\n  - schemas/core/crypto_envelope.schema.json\\n- Added keyring module:\\n  - src/deepsigma/security/keyring.py\\n  - src/deepsigma/security/__init__.py\\n- Added tests:\\n  - tests/test_disr_keyring.py\\n- Linked DISR docs in README security section.\\n\\n## Validation\\n- pytest -q tests/test_disr_keyring.py tests/test_credibility_store_encryption.py\\n- ruff check src/deepsigma/security/keyring.py tests/test_disr_keyring.py\\n","changedFiles":8,"createdAt":"2026-02-23T02:44:12Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T02:46:12Z","number":269,"title":"DISR PR1: docs + envelope schema + keyring TTL model","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/269"},{"additions":1,"body":"Fix README GHCR badge click target that returned 404 by pointing to the account package listing for this repo.","changedFiles":1,"createdAt":"2026-02-23T02:13:58Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T02:15:39Z","number":253,"title":"Docs: fix GHCR badge link target","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/253"},{"additions":8,"body":"## Fix\n- switched KPI badge and radar links in README to repo-relative paths\n- badge click target now points to `release_kpis/radar_composite_latest.png`\n\nThis avoids intermittent 404/render issues from fully-qualified blob/raw URL variants and keeps the target on the latest radar graphic.\n","changedFiles":1,"createdAt":"2026-02-23T02:10:13Z","deletions":8,"labels":[],"mergedAt":"2026-02-23T02:12:01Z","number":252,"title":"Docs: fix README KPI badge and radar links","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/252"},{"additions":2098,"body":"## Release v2.0.4\\n\\n### Includes\\n- package/version bump to 2.0.4\\n- policy baseline bump to GOV-2.0.4\\n- new release notes for v2.0.4 (docs/release + docs/docs/release)\\n- README/STABILITY/PILOT_SCORECARD release pointers updated\\n- regenerated Repo Radar artifacts for v2.0.4 (radar, composite, trend, badge, gate report)\\n\\n### Validation\\n- make kpi-issues\\n- make kpi\\n- python scripts/release_check.py --tag v2.0.4\\n","changedFiles":24,"createdAt":"2026-02-23T02:06:33Z","deletions":160,"labels":[],"mergedAt":"2026-02-23T02:08:38Z","number":251,"title":"Release: v2.0.4","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/251"},{"additions":15,"body":"## Fix\n- replace hardcoded rollout target `deploy/deepsigma` with a label-based wait for all release deployments\n- chart creates component deployments (api/dashboard), so hardcoded deployment name does not exist\n\n## Why\n`kind-install-test` failed in the install step with:\n`Error from server (NotFound): deployments.apps \"deepsigma\" not found`\n\n## Validation\n- workflow syntax preserved\n- install step now waits for deployments labeled `app.kubernetes.io/instance=deepsigma`\n","changedFiles":1,"createdAt":"2026-02-23T01:54:57Z","deletions":2,"labels":[],"mergedAt":"2026-02-23T02:02:18Z","number":250,"title":"CI: fix kind-install-test chart install rollout check","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/250"},{"additions":15,"body":"## Summary\n- add explicit least-privilege permissions blocks to flagged workflows\n- redact persistence exception details from public health/readiness responses\n- keep degraded health semantics while removing stack-trace/exception leakage\n\n## Files\n- .github/workflows/mesh_wan_integration.yml\n- .github/workflows/openapi_sync.yml\n- .github/workflows/helm_chart_validate.yml\n- .github/workflows/scale_benchmark.yml\n- dashboard/api_server.py\n\n## Validation\n- pytest -q tests/test_api_health_degraded.py tests/test_openapi_docs.py\n- ruff check dashboard/api_server.py\n","changedFiles":5,"createdAt":"2026-02-23T01:46:42Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T01:49:43Z","number":249,"title":"Security: resolve 8 open code scanning alerts","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/249"},{"additions":143,"body":"Summary\n- add DNS SRV peer discovery support to `mesh.discovery.StaticRegistry`\n- keep static config discovery behavior and allow merging static + DNS discovered peers\n- add a mesh topology panel to dashboard overview using `/mesh/tenant-alpha/topology` with replication lag visibility\n- document discovery modes in mesh README\n- add tests for DNS SRV discovery behavior\n\nValidation\n- python -m pytest -q tests/test_mesh_transport.py tests/test_openapi_docs.py\n- cd dashboard && npm run build\n\nPart of #149\n","changedFiles":4,"createdAt":"2026-02-23T01:39:35Z","deletions":5,"labels":[],"mergedAt":"2026-02-23T01:42:27Z","number":248,"title":"feat(mesh): DNS SRV discovery + topology dashboard panel (part of #149)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/248"},{"additions":363,"body":"Summary\n- add 3-node WAN mesh Docker testbed (`docker/mesh/docker-compose.wan.yml`) and dedicated mesh image (`docker/Dockerfile.mesh`)\n- add deterministic partition drill script (`scripts/mesh_wan_partition.sh`) that induces failure and verifies recovery\n- add CI workflow (`.github/workflows/mesh_wan_integration.yml`) to run the WAN integration scenario on PRs\n- add mesh topology API visibility (`/mesh/{tenant_id}/topology`) with node state + replication lag fields\n- timestamp replication log events for lag calculation\n- add operator troubleshooting runbook (`docs/docs/pilot/MESH_WAN_TROUBLESHOOTING.md`)\n- regenerate OpenAPI docs and extend API coverage checks/tests for topology endpoint\n\nValidation\n- python -m pytest -q tests/test_mesh_transport.py tests/test_openapi_docs.py tests/test_mesh_anti_entropy.py\n- make no-dupes\n- make openapi-docs\n- local WAN drill execution blocked in this environment (`docker: command not found`), delegated to CI workflow\n\nCloses #194\n","changedFiles":11,"createdAt":"2026-02-23T01:33:45Z","deletions":14,"labels":[],"mergedAt":"2026-02-23T01:37:15Z","number":247,"title":"feat(mesh): WAN integration drill + topology visibility (#194)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/247"},{"additions":244,"body":"Summary\n- add deterministic anti-entropy protocol helpers in src/mesh/anti_entropy.py\n- implement digest exchange, cursor/id delta offers, replay-safe delta apply, and reconciliation reports\n- add reconciliation correctness and replay-safety tests in tests/test_mesh_anti_entropy.py\n- document selected anti-entropy protocol and bandwidth profile in src/mesh/README.md\n\nValidation\n- python -m pytest -q tests/test_mesh_anti_entropy.py\n- python -m pytest -q tests/test_mesh_transport.py\n\nCloses #193\n","changedFiles":3,"createdAt":"2026-02-23T01:26:55Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T01:28:30Z","number":246,"title":"feat(mesh): anti-entropy + delta sync with replay safety (#193)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/246"},{"additions":213,"body":"Summary\n- define a mesh node identity model via NodeIdentity with SPIFFE-style IDs\n- add mTLS policy controls to HTTPTransport (HTTPS enforcement, trust roots, client cert/key, rotation path)\n- add peer identity verification through expected certificate fingerprint matching\n- expose trust/identity configuration via health output and management methods\n- add tests covering mTLS enforcement, trust root/rotation config, and rejected untrusted peer behavior\n\nValidation\n- python -m pytest -q tests/test_mesh_transport.py\n\nCloses #191\n","changedFiles":3,"createdAt":"2026-02-23T01:23:20Z","deletions":2,"labels":[],"mergedAt":"2026-02-23T01:25:01Z","number":245,"title":"feat(mesh): peer identity and mTLS controls for replication links (#191)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/245"},{"additions":271,"body":"Summary\n- implement a peer state machine in HTTPTransport with ONLINE/SUSPECT/OFFLINE states\n- add configurable partition/retry controls: max_retries, backoff_base, suspect_after_failures, offline_after_failures, recovery_successes\n- add automatic recovery/rejoin transitions when peers become healthy again\n- emit partition and recovery events with health-level partition metrics\n- document partition detection and recovery behavior in src/mesh/README.md\n\nValidation\n- python -m pytest -q tests/test_mesh_transport.py\n\nCloses #192\n","changedFiles":3,"createdAt":"2026-02-23T01:20:40Z","deletions":9,"labels":[],"mergedAt":"2026-02-23T01:21:10Z","number":244,"title":"feat(mesh): peer partition detection and recovery state transitions (#192)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/244"},{"additions":186,"body":"Summary\n- add a complete OpenClaw custom policy example bundle under src/adapters/openclaw/examples/custom-policy\n- add helper module src/adapters/openclaw/examples/custom_policy.py for loading/evaluating policies via WASMRuntime\n- add coverage for whitelist allow/block behavior and decision-path handling in tests/test_openclaw_custom_policy_example.py\n- document usage in src/adapters/openclaw/README.md\n\nValidation\n- python -m pytest -q tests/test_openclaw_custom_policy_example.py tests/test_openclaw_runtime.py\n\nCloses #142\n","changedFiles":8,"createdAt":"2026-02-23T01:16:59Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T01:17:25Z","number":243,"title":"feat(openclaw): custom WASM policy example + tests (#142)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/243"},{"additions":61,"body":"## Summary\n- add .devcontainer/devcontainer.json for Python 3.12 + Node 20\n- add post-create bootstrap script using lockfile-constrained install\n- auto-install dashboard npm dependencies in container setup\n- preinstall VS Code extensions (Python, Ruff, Pylance, ESLint)\n- configure forwarded ports for API (8000) and dashboard (5173)\n- add README badge: Open in GitHub Codespaces\n\nCloses #141\n","changedFiles":3,"createdAt":"2026-02-23T01:13:00Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T01:13:26Z","number":242,"title":"feat(devcontainer): Codespaces config + one-click setup (#141)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/242"},{"additions":76,"body":"## Summary\n- add optional chart-managed PVC for JSONL data directories\n- add optional API/dashboard volume mounts for /app/src/data and /app/data\n- support existing claim via `dataPersistence.existingClaim`\n- document persistence toggle and multi-replica storage guidance\n\nProgresses #148\n","changedFiles":7,"createdAt":"2026-02-23T01:10:43Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T01:11:10Z","number":241,"title":"feat(helm): add JSONL PVC support to chart (#148)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/241"},{"additions":64,"body":"## Summary\n- add API HorizontalPodAutoscaler template (autoscaling/v2)\n- add `api.autoscaling` values in base and production overlays\n- document production resource defaults and replica strategy\n- clarify persistence-backed mode scaling guidance\n\nCloses #189\n","changedFiles":4,"createdAt":"2026-02-23T01:08:31Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T01:08:56Z","number":240,"title":"feat(helm): API HPA + production scaling overlay (#189)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/240"},{"additions":231,"body":"## Summary\\n- add optional Fuseki StatefulSet + Service templates\\n- add optional ConfigMap and Secret templates\\n- wire envFrom toggles for API/dashboard from chart-managed config/secret\\n- add optional ServiceMonitor template for Prometheus Operator\\n- document all toggle paths in chart README\\n\\nCloses #188\\n","changedFiles":11,"createdAt":"2026-02-23T01:06:37Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T01:07:03Z","number":239,"title":"feat(helm): optional Fuseki + ServiceMonitor + config templates (#188)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/239"},{"additions":263,"body":"## Summary\\n- split Helm chart into separate API and dashboard Deployments + Services\\n- add ingress template with path routing to api/dashboard services\\n- keep liveness/readiness probes configurable per workload\\n- add production overlay values and chart README\\n- update helm smoke test to validate both services\\n\\nCloses #187\\n","changedFiles":12,"createdAt":"2026-02-23T01:01:47Z","deletions":41,"labels":[],"mergedAt":"2026-02-23T01:03:58Z","number":238,"title":"feat(helm): core workloads + ingress split (#187)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/238"},{"additions":643,"body":"## Summary\\n- add `deepsigma compliance export` command\\n- export SOC2 evidence package artifacts (audit log JSON/CSV, seal chain, policy snapshots, scorecard history, tenant config)\\n- add redaction mode (`--redact`) for user identifiers\\n- generate compliance summary + connector data-flow diagram\\n- add CLI docs and tests\\n\\n## Validation\\n- pytest tests/test_compliance_export.py\\n- pytest tests/test_cli_smoke.py::TestCLIHelp::test_no_args_prints_help\\n- ruff check src/deepsigma/cli/compliance_export.py tests/test_compliance_export.py src/deepsigma/cli/main.py docs/CLI.md\\n","changedFiles":4,"createdAt":"2026-02-23T00:56:50Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T00:58:39Z","number":237,"title":"feat: SOC2 compliance evidence export CLI (#146)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/237"},{"additions":472,"body":"## Summary\n- add `/metrics` Prometheus exposition endpoint on dashboard API\n- add required DeepSigma series:\n  - `deepsigma_claims_total` (gauge by state)\n  - `deepsigma_drift_events_total` (counter by severity)\n  - `deepsigma_packet_seal_duration_seconds` (histogram)\n  - `deepsigma_iris_query_duration_seconds` (histogram)\n  - `deepsigma_api_requests_total` (counter by endpoint + status)\n  - `deepsigma_evidence_tier_count` (gauge by tier)\n- add Grafana dashboard template at `ops/grafana/deepsigma.json`\n- add local monitoring stack: `docker-compose.monitoring.yml` + Prometheus/Grafana provisioning\n- add README Monitoring section\n- refresh OpenAPI artifact for `/metrics`\n\n## Validation\n- `ruff check src/services/prom_metrics.py dashboard/api_server.py src/credibility_engine/api.py tests/test_metrics_endpoint.py`\n- `PYTHONPATH=src pytest -q tests/test_metrics_endpoint.py tests/test_openapi_docs.py`\n- `PYTHONPATH=src python - <<'PY' ... /metrics smoke check ... PY`\n- `make openapi-docs`\n\nCloses #143\n","changedFiles":11,"createdAt":"2026-02-23T00:50:36Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T00:52:16Z","number":236,"title":"Prometheus metrics + Grafana dashboard template","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/236"},{"additions":1533,"body":"## Summary\n- add deterministic OpenAPI export pipeline from FastAPI app to `docs/api/openapi.json`\n- add static Redoc site at `docs/api/index.html`\n- add OpenAPI validator script for required API families (credibility, mesh, tenant, policy, audit)\n- add CI workflow (`openapi_sync.yml`) to enforce spec/docs sync against code\n- add README API docs link\n\n## Validation\n- `make openapi-check`\n- `PYTHONPATH=src pytest -q tests/test_openapi_docs.py`\n\nCloses #139\n","changedFiles":11,"createdAt":"2026-02-23T00:36:34Z","deletions":2,"labels":[],"mergedAt":"2026-02-23T00:46:28Z","number":235,"title":"Auto-generated API reference from OpenAPI spec","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/235"},{"additions":359,"body":"## Summary\n- add `deepsigma init <name>` to scaffold a starter project with sample claims, drift scenario, IRIS query docs, and trust scorecard input\n- add `docs/QUICKSTART.md` with copy/paste flow: fresh venv -> install -> init -> make demo\n- add CLI docs + README references for the new quickstart path\n- add CLI smoke test coverage for `deepsigma init`\n\n## Validation\n- `ruff check src/deepsigma/cli/init_project.py src/deepsigma/cli/main.py tests/test_cli_smoke.py`\n- `PYTHONPATH=src pytest -q tests/test_cli_smoke.py -k \"init_project or new_connector or no_args_prints_help\"`\n- `PYTHONPATH=src python -m deepsigma.cli.main init my-project --out-dir <tmp>`\n- `make -C <tmp>/my-project demo`\n\nCloses #138\n","changedFiles":6,"createdAt":"2026-02-23T00:33:04Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T00:37:43Z","number":234,"title":"SDK quickstart: add deepsigma init starter scaffold","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/234"},{"additions":92,"body":"## Summary\n- add `docs/DATA_BOUNDARIES.md` as a one-page security/data-handling reference for enterprise review\n- cover data at rest, storage locations, retention, redaction, tenancy separation, connector data flow, secrets management, and network boundaries\n- add README links under a new \"Security And Data Handling\" section\n- update Connector SDK doc to reference `docs/DATA_BOUNDARIES.md`\n\n## Notes\n- No real secrets or endpoint URLs included\n- Document is under 500 lines\n\nCloses #136\n","changedFiles":3,"createdAt":"2026-02-23T00:30:10Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T00:33:16Z","number":233,"title":"Connector safety and data boundaries documentation","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/233"},{"additions":399,"body":"## Summary\n- add Connector SDK documentation and protocol expectations\n- add `deepsigma new-connector` scaffold command with templates\n- add reusable connector protocol test harness and tests\n- add community CSV connector example\n\n## Validation\n- `ruff check tests/test_cli_smoke.py src/deepsigma/cli/new_connector.py src/deepsigma/cli/main.py src/adapters/testing/harness.py src/adapters/community/csv_connector.py tests/test_connector_protocol_harness.py`\n- `PYTHONPATH=src pytest -q tests/test_cli_smoke.py -k \"new_connector or no_args_prints_help\"`\n- `PYTHONPATH=src pytest -q tests/test_connector_protocol_harness.py`\n- `PYTHONPATH=src python -m deepsigma.cli.main new-connector sample_api --out-dir <tmp>/adapters --tests-dir <tmp>/tests`\n\nCloses #140\n","changedFiles":14,"createdAt":"2026-02-23T00:27:45Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T00:29:14Z","number":232,"title":"Connector SDK + plugin scaffolder + protocol harness","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/232"},{"additions":299,"body":"## Summary\n- add new Helm chart at `charts/deepsigma` for dashboard/API deployment\n- add `helm test` smoke pod that checks `/healthz` and `/api/health`\n- add CI workflow for chart lint/template and kind install + helm test\n- document kind/minikube install paths and failure diagnostics runbook\n\n## Acceptance Mapping (#190)\n- [x] kind/minikube install path tested/documented\n- [x] `helm test` smoke checks implemented\n- [x] CI check for chart lint/template render\n- [x] failure diagnostics documented\n\n## Notes\n- Helm CLI is not installed in this local runtime, so lint/template execution is validated in CI workflow\n\nCloses #190\n","changedFiles":11,"createdAt":"2026-02-23T00:21:02Z","deletions":0,"labels":[],"mergedAt":"2026-02-23T00:22:47Z","number":231,"title":"feat(helm): chart install validation and helm test smoke checks (#190)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/231"},{"additions":211,"body":"## Summary\n- add persistence-aware health payload (`/api/health`) with degraded semantics\n- add explicit liveness (`/api/live`) and readiness (`/api/ready`) endpoints\n- track in-flight requests and reject new non-health requests while draining\n- add graceful shutdown drain loop with configurable timeout/poll\n- document readiness/liveness and drain env vars\n\n## Tests\n- `pytest -q tests/test_api_health_degraded.py`\n- `pytest -q tests/test_credibility_api_stateless.py`\n- `ruff check dashboard/api_server.py tests/test_api_health_degraded.py`\n\nCloses #196\n","changedFiles":3,"createdAt":"2026-02-23T00:15:11Z","deletions":8,"labels":[],"mergedAt":"2026-02-23T00:18:40Z","number":230,"title":"feat(api): health degradation + readiness/liveness + graceful shutdown (#196)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/230"},{"additions":427,"body":"## Summary\n- add a reproducible 3-replica benchmark harness behind reverse proxy (`docker/scale/*`)\n- add benchmark runner scripts for 100-concurrent requests with throughput/latency/error reporting\n- add scaling guide with replica sizing advice and acceptance mapping\n- add GitHub Actions workflow to execute benchmark and upload artifacts\n\n## Validation\n- `ruff check scripts/run_scale_benchmark.py`\n- `python -m compileall scripts/run_scale_benchmark.py`\n- `python scripts/run_scale_benchmark.py --help`\n\n## Notes\n- Local benchmark execution requires Docker (`make scale-benchmark`)\n- In this environment Docker is unavailable, so benchmark run is captured via workflow and reproducible on developer machines\n\nCloses #197\n","changedFiles":13,"createdAt":"2026-02-22T23:58:32Z","deletions":1,"labels":[],"mergedAt":"2026-02-23T00:05:30Z","number":229,"title":"feat(scale): add stateless API load benchmark + scaling guide (#197)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/229"},{"additions":465,"body":"## Summary\n- add `deepsigma retention sweep --tenant <id>` command\n- add tenant `retention_policy` defaults in policy files\n- implement lifecycle sweep with:\n  - tier sweep (hot->warm->cold)\n  - cold-tier purge by retention cutoff\n  - audit-log purge by retention cutoff\n  - JSONL compaction during sweep\n  - dry-run mode and JSON output\n- emit audit entries for purge actions\n- add docs discoverability in README and ops runbook\n\n## Acceptance Mapping (#145)\n- [x] `deepsigma retention sweep` CLI command\n- [x] configurable retention policy in tenant policy file\n- [x] sweep demotes hot->warm->cold and purges expired cold\n- [x] JSONL compaction runs during sweep\n- [x] dry-run mode (`--dry-run`) and clear output\n- [x] audit log entry for purge actions\n- [x] cron-friendly exit codes (0 success, non-zero on errors)\n- [x] integrated with evidence tiering manager\n\n## Validation\n- `ruff check src/deepsigma/cli/retention.py src/deepsigma/cli/main.py src/tenancy/policies.py tests/test_retention_sweep.py`\n- `pytest -q tests/test_retention_sweep.py tests/test_jsonl_compaction.py`\n- `PYTHONPATH=src python -m deepsigma.cli.main retention sweep --tenant tenant-alpha --dry-run --json`\n\nCloses #145\n","changedFiles":7,"createdAt":"2026-02-22T23:53:55Z","deletions":7,"labels":[],"mergedAt":"2026-02-23T00:10:49Z","number":228,"title":"feat: retention sweep CLI (TTL purge + compaction cron)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/228"},{"additions":89,"body":"## Summary\n- remove request-affecting global mutable engine cache from `credibility_engine.api`\n- build request-scoped engine instances through an injectable store factory\n- preserve persistence-backed state by loading from `CredibilityStore` every request\n- add regression tests proving replica-independence / stateless behavior\n\n## Acceptance Mapping (#195)\n- [x] No request-affecting global mutable state (removed `_engines` cache)\n- [x] Credibility state loaded via persistence abstraction (`_store_factory` -> `CredibilityStore`)\n- [x] Seal/audit-compatible writes still route through persistence-backed engine/store path\n- [x] Regression tests for replica-independence (`tests/test_credibility_api_stateless.py`)\n\n## Validation\n- `pytest -q tests/test_credibility_api_stateless.py`\n\nCloses #195\n","changedFiles":2,"createdAt":"2026-02-22T23:42:51Z","deletions":15,"labels":[],"mergedAt":"2026-02-22T23:49:41Z","number":227,"title":"feat: stateless API split for credibility runtime (issue #195)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/227"},{"additions":116,"body":"## Summary\n- add two local proof visuals under `docs/assets/` for README embedding\n- add README \"Golden-Path Proof Artifacts\" section with:\n  - dashboard proof images\n  - executable Golden Path + Trust Scorecard commands\n  - CLI transcript showing 7/7 PASS, drift->patch completion, and SLOs ALL PASS\n  - explicit WHY retrieval <= 60s evidence from scorecard metrics\n\n## Acceptance Mapping (#135)\n- [x] 2 proof visuals embedded in README\n- [x] CLI transcript with Golden Path + retrieval + drift->patch evidence\n- [x] Assets stored locally in `docs/assets/`\n- [x] README quick start references `make demo`\n- [x] Trust Scorecard output shown with `SLOs: ALL PASS`\n\nCloses #135\n","changedFiles":3,"createdAt":"2026-02-22T23:37:41Z","deletions":0,"labels":[],"mergedAt":"2026-02-22T23:40:23Z","number":226,"title":"docs: README golden-path proof artifacts (issue #135)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/226"},{"additions":38,"body":"## Summary\n- add `run_money_demo.sh` as one-command demo runner\n- add `make demo` target in `Makefile`\n- update docs to make `make demo` the recommended first-run entrypoint\n\n## Validation\n- `make demo`\n  - runs Drift->Patch cycle\n  - runs `tests/test_money_demo.py` contract\n  - prints artifact and evidence paths\n\nCloses #133\n","changedFiles":4,"createdAt":"2026-02-22T23:32:23Z","deletions":2,"labels":[],"mergedAt":"2026-02-22T23:33:56Z","number":225,"title":"feat: one-command money demo path (issue #133)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/225"},{"additions":54,"body":"## Summary\nAdds a canonical pilot results snapshot with hard evidence links and a final operator closeout checklist.\n\n### Added\n- `docs/docs/pilot/PILOT_RESULTS_2026-02-22.md`\n  - current CI state and deterministic drill results\n  - merge-block gate evidence links (failed CI runs)\n  - branch protection baseline\n  - explicit remaining tasks (WHY-60 with 2 new users + final go/no-go)\n  - validation log table template\n- `pilot/README.md` link to the results snapshot\n\nThis keeps issue #199 grounded in a single source-of-truth artifact and makes remaining manual closeout steps explicit.\n\nCloses #199\n","changedFiles":2,"createdAt":"2026-02-22T23:27:53Z","deletions":0,"labels":[],"mergedAt":"2026-02-22T23:29:41Z","number":224,"title":"Issue #199: add pilot results snapshot + closeout checklist","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/224"},{"additions":100,"body":"## Summary\nImplements automated Golden Path proof regeneration for tagged releases and attaches proof artifacts to the GitHub Release.\n\n### Added (tag `v*` only)\n- New CI job: `release-proof`\n- Executes full Golden Path end-to-end in fixture mode and captures transcript\n- Generates `trust_scorecard.json`\n- Gates release on Trust Scorecard SLO checks (hard fail if any SLO is false)\n- Captures dashboard screenshot via Playwright (headless Chromium)\n- Produces versioned proof artifacts (`vX.Y.Z` in filenames)\n- Uploads proof bundle as workflow artifact and attaches proof files to GitHub Release\n\n### Proof artifacts attached to release\n- `trust_scorecard_<tag>.json`\n- `golden_path_transcript_<tag>.txt`\n- `dashboard_screenshot_<tag>.png`\n- `golden_path_summary_<tag>.json`\n- `golden_path_output_<tag>.tar.gz`\n\n## Notes\n- This job runs only on tag pushes and after release artifacts + dashboard build jobs.\n- Existing PR CI behavior remains unchanged (proof job skipped on PR).\n\nCloses #144\n","changedFiles":1,"createdAt":"2026-02-22T23:24:16Z","deletions":0,"labels":[],"mergedAt":"2026-02-22T23:25:52Z","number":223,"title":"Issue #144: automate Golden Path release proof regeneration","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/223"},{"additions":320,"body":"## Summary\nImplements envelope-level encryption at rest for tenant-scoped credibility evidence, with key rotation support.\n\n### What changed\n- Added `encrypt_at_rest` support in `CredibilityStore` with graceful plaintext fallback if `DEEPSIGMA_MASTER_KEY` or `cryptography` is unavailable.\n- Added tenant-scoped key derivation from master key (`DEEPSIGMA_MASTER_KEY`) and AES-256-GCM envelope encryption for JSONL/JSON records.\n- Persisted encrypted records using `encrypted_payload` + `nonce` envelope fields.\n- Added transparent decrypt-on-read path for encrypted records.\n- Ensured packet artifacts (`packet_latest.json`) remain plaintext by design.\n- Added `CredibilityStore.rekey(previous_master_key=...)` to re-encrypt tenant records under the current key.\n- Added `deepsigma rekey --tenant <id>` CLI command to perform rotation using env-provided previous/current keys.\n- Added optional dependency extra `[encrypt]` in `pyproject.toml`.\n- Added/updated tests for config flag and encrypted store behavior.\n\n## Validation\n- `ruff check src/credibility_engine/store.py src/deepsigma/cli/rekey.py src/adapters/openclaw/runtime.py src/deepsigma/cli/main.py tests/test_credibility_store_encryption.py tests/test_openclaw_runtime.py`\n- `pytest -q tests/test_credibility_store_encryption.py tests/test_openclaw_runtime.py`\n\nCloses #147\n","changedFiles":7,"createdAt":"2026-02-22T23:20:46Z","deletions":21,"labels":[],"mergedAt":"2026-02-22T23:22:22Z","number":222,"title":"Issue #147: envelope-level encryption at rest + rekey CLI","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/222"},{"additions":257,"body":"## Summary\nImplements release supply-chain hardening and tagged publish behavior for both issues:\n\n- **#150 Signed releases + SBOM**\n  - signs wheel/sdist with Sigstore keyless (`python -m sigstore sign`)\n  - signs published GHCR image digest with Cosign keyless\n  - generates source + image SBOMs (`syft`) in CycloneDX/SPDX\n  - adds SLSA provenance attestations for dist artifacts and container image\n  - adds post-release verification job for Sigstore and Cosign checks\n  - documents verification commands in `SECURITY.md`\n\n- **#151 Publish to PyPI + GHCR on tag**\n  - keeps trusted publisher OIDC flow for PyPI\n  - hardens tagged GHCR path with **multi-arch** build (`linux/amd64,linux/arm64`)\n  - expands docker tag set to `vX.Y.Z`, `vX.Y`, `vX`, `latest`\n  - adds PyPI smoke job that retries install of tagged version and validates CLI\n  - validates optional extras install for `rdf,azure,snowflake`\n\nAlso updates release build lockfile to include `sigstore`.\n\n## Files\n- `.github/workflows/ci.yml`\n- `requirements/locks/release-build.in`\n- `requirements/locks/release-build.txt`\n- `SECURITY.md`\n- `README.md`\n\n## Validation\n- `python scripts/release_check.py --tag v2.0.3`\n- YAML parse sanity for `.github/workflows/ci.yml`\n\nCloses #150\nCloses #151\n","changedFiles":5,"createdAt":"2026-02-22T23:15:29Z","deletions":1,"labels":[],"mergedAt":"2026-02-22T23:17:02Z","number":221,"title":"Issues #150/#151: signed release supply chain + publish hardening","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/221"},{"additions":192,"body":"## Summary\n- add deterministic `release-check` script for tag/version/changelog coherence\n- add lockfile-backed release build deps (`requirements/locks/release-build.in/.txt`)\n- add `make build`, `make docker`, and `make release-check`\n- extend tag CI with release artifact upload to GitHub Release and GHCR push (`ghcr.io/8ryanwh1t3/deepsigma` with version + latest)\n- update PyPI publish job to use lockfile-constrained build + metadata check\n\n## Validation\n- python scripts/release_check.py --tag v2.0.3\n- python -m py_compile scripts/release_check.py\n- ruff check scripts/release_check.py\n- make build\n\nCloses #137\n","changedFiles":6,"createdAt":"2026-02-22T19:14:05Z","deletions":3,"labels":[],"mergedAt":"2026-02-22T19:15:39Z","number":220,"title":"Issue #137: CI release hygiene for tag artifacts","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/220"},{"additions":361,"body":"## Summary\nImplements the core of #134 by adding pinned lockfiles and making CI install via constraints instead of loose dependency resolution.\n\n## What changed\n- Added lockfiles under `requirements/locks/`:\n  - `base.txt`\n  - `dev-excel-local.txt`\n  - `rdf.txt`\n  - `azure.txt`\n  - `snowflake.txt`\n  - `openclaw.txt`\n  - `kpi.txt`\n- Added lock regeneration script: `scripts/update_locks.sh`\n- Added docs: `docs/docs/governance/DEPENDENCY_LOCKING.md`\n- Updated CI install steps to use lock constraints in:\n  - `.github/workflows/ci.yml`\n  - `.github/workflows/kpi.yml`\n  - `.github/workflows/kpi_gate.yml`\n- Added make target: `make lock-update`\n\n## Acceptance criteria mapping\n- [x] Lockfile committed (`requirements/locks/*.txt`)\n- [x] CI installs from lockfiles/constraints\n- [x] `pip install -e '.[dev,rdf]'` remains valid for contributors\n- [x] Optional extras have locked sub-deps (`rdf`, `azure`, `snowflake`, `openclaw`)\n- [x] Regeneration documented (`scripts/update_locks.sh` + docs)\n- [ ] Dependabot lockfile-specific tuning (existing Dependabot config already present; can be refined in follow-up)\n\nCloses #134\n","changedFiles":14,"createdAt":"2026-02-22T19:07:23Z","deletions":9,"labels":[],"mergedAt":"2026-02-22T19:10:47Z","number":219,"title":"Issue #134: deterministic dependency locks + CI constraints","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/219"},{"additions":169,"body":"## Summary\\n- add \\n- define 3 execution lanes for the 33 open issues\\n- include milestones, 7-day closure order, and KPI impact expectations\\n","changedFiles":1,"createdAt":"2026-02-22T18:56:44Z","deletions":0,"labels":[],"mergedAt":"2026-02-22T18:59:42Z","number":218,"title":"Add Issue War Plan for KPI execution","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/218"},{"additions":138,"body":"## Summary\\n- switch KPI links to explicit GitHub URLs for reliable rendering\\n- set Repo KPI badge click target to latest release radar graphic\\n- keep composite radar and delta links directly accessible\\n","changedFiles":6,"createdAt":"2026-02-22T18:36:34Z","deletions":29,"labels":[],"mergedAt":"2026-02-22T18:39:26Z","number":217,"title":"Fix README KPI and composite radar links","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/217"},{"additions":9,"body":"## Summary\\n- make release notes and KPI entries clickable links\\n- point Repo KPI badge to latest composite radar graphic\\n- replace shell expression path with concrete current release radar link\\n","changedFiles":1,"createdAt":"2026-02-22T18:31:53Z","deletions":9,"labels":[],"mergedAt":"2026-02-22T18:33:46Z","number":216,"title":"Fix README KPI links and badge target","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/216"},{"additions":2416,"body":"## Summary\\n- add make target \\n- add [issues-review] exporting open issues JSON\n[issues-review] wrote release_kpis/issues_open.json\n[issues-review] exporting closed issues (last 30d) JSON\n[issues-review] wrote release_kpis/issues_closed_30d.json\n[issues-review] generating KPI issue brief artifacts\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_kpi_matrix.csv\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_kill_list.md\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_portfolio_summary.md\n[issues-review] done for parse-safe issue export\\n- add Wrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_kpi_matrix.csv\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_kill_list.md\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_portfolio_summary.md to generate KPI issue matrix/kill list/portfolio summary\\n- commit latest issue review artifacts under \\n\\n## Validation\\n- bash scripts/issues_review.sh\n[issues-review] exporting open issues JSON\n[issues-review] wrote release_kpis/issues_open.json\n[issues-review] exporting closed issues (last 30d) JSON\n[issues-review] wrote release_kpis/issues_closed_30d.json\n[issues-review] generating KPI issue brief artifacts\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_kpi_matrix.csv\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_kill_list.md\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/issues_portfolio_summary.md\n[issues-review] done\npython scripts/issue_label_gate.py\nWrote: /Users/bryanwhite/Documents/DeepSigma-v0.3.0/release_kpis/ISSUE_LABEL_GATE_REPORT.md","changedFiles":16,"createdAt":"2026-02-22T18:21:36Z","deletions":17,"labels":[],"mergedAt":"2026-02-22T18:28:48Z","number":215,"title":"Add issues-review make target and KPI issue brief exports","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/215"},{"additions":1358,"body":"Implements Build 76 A-D:\\n\\n- Issue label gate enforcement and report\\n- README KPI block + KPI summary\\n- KPI historical trend rendering\\n- One-command pilot_pack bundle generation\\n- Workflow wiring for gate + trend + artifacts","changedFiles":19,"createdAt":"2026-02-22T18:09:55Z","deletions":41,"labels":[],"mergedAt":"2026-02-22T18:11:22Z","number":214,"title":"Build 76: label gate + KPI trend + pilot_pack","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/214"},{"additions":374,"body":"Adds 8 KPI portfolio issue templates and canonical label policy documentation to keep issue->radar labeling deterministic.","changedFiles":10,"createdAt":"2026-02-22T17:59:37Z","deletions":0,"labels":[],"mergedAt":"2026-02-22T18:01:13Z","number":213,"title":"Add KPI issue templates + canonical label policy","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/213"},{"additions":355,"body":" scoring + CI integration\r\n\r\n## Coherence Ops Patch Checklist\r\n\r\n- [ ] Links Drift Issue\r\n- [ ] Updates Decision DLR\r\n- [ ] Refreshes assumptions or extends expiry\r\n- [ ] Updates Patch record\r\n- [ ] `compute_ci` passes\r\n- [ ] Owner assigned\r\n- [ ] Seal updated (or explicitly \"pilot mode\")\r\n","changedFiles":10,"createdAt":"2026-02-22T17:28:46Z","deletions":32,"labels":[],"mergedAt":"2026-02-22T17:31:32Z","number":212,"title":"Repo Radar wired to Issues: KPI labels + issue deltas + deterministic","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/212"},{"additions":515,"body":" gate) + PR auto-comment + CI wiring\r\n\r\n## Coherence Ops Patch Checklist\r\n\r\n- [ ] Links Drift Issue\r\n- [ ] Updates Decision DLR\r\n- [ ] Refreshes assumptions or extends expiry\r\n- [ ] Updates Patch record\r\n- [ ] `compute_ci` passes\r\n- [ ] Owner assigned\r\n- [ ] Seal updated (or explicitly \"pilot mode\")\r\n","changedFiles":15,"createdAt":"2026-02-22T17:20:24Z","deletions":85,"labels":[],"mergedAt":"2026-02-22T17:22:49Z","number":211,"title":"Build 74: Repo Radar KPI (telemetry compute + merged KPIs + history +","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/211"},{"additions":1872,"body":"## Coherence Ops Patch Checklist\r\n\r\n- [ ] Links Drift Issue\r\n- [ ] Updates Decision DLR\r\n- [ ] Refreshes assumptions or extends expiry\r\n- [ ] Updates Patch record\r\n- [ ] `compute_ci` passes\r\n- [ ] Owner assigned\r\n- [ ] Seal updated (or explicitly \"pilot mode\")\r\n","changedFiles":21,"createdAt":"2026-02-22T16:59:09Z","deletions":17,"labels":[],"mergedAt":"2026-02-22T17:03:31Z","number":210,"title":"Codex/merge all","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/210"},{"additions":62,"body":"## Coherence Ops Patch Checklist\r\n\r\n- [ ] Links Drift Issue\r\n- [ ] Updates Decision DLR\r\n- [ ] Refreshes assumptions or extends expiry\r\n- [ ] Updates Patch record\r\n- [ ] `compute_ci` passes\r\n- [ ] Owner assigned\r\n- [ ] Seal updated (or explicitly \"pilot mode\")\r\n","changedFiles":7,"createdAt":"2026-02-22T16:44:58Z","deletions":19,"labels":[],"mergedAt":"2026-02-22T16:49:53Z","number":209,"title":"Codex/security burndown 22","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/209"},{"additions":73,"body":"IRIS flows\r\n\r\n## Coherence Ops Patch Checklist\r\n\r\n- [ ] Links Drift Issue\r\n- [ ] Updates Decision DLR\r\n- [ ] Refreshes assumptions or extends expiry\r\n- [ ] Updates Patch record\r\n- [ ] `compute_ci` passes\r\n- [ ] Owner assigned\r\n- [ ] Seal updated (or explicitly \"pilot mode\")\r\n","changedFiles":9,"createdAt":"2026-02-22T16:26:50Z","deletions":34,"labels":[],"mergedAt":"2026-02-22T16:39:48Z","number":208,"title":"Security: apply CodeQL in-source suppressions for validated path and ","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/208"},{"additions":101,"body":"## Summary\\n- Harden path containment checks using explicit  validation\\n- Route storage and mesh file operations through validated path helpers\\n- Ensure exhaust episode assembly uses validated \\n\\n## Validation\\n- Listing '/Users/bryanwhite/Documents/DeepSigma-v0.3.0'...\nListing '/opt/anaconda3/lib/python311.zip'...\nCan't list '/opt/anaconda3/lib/python311.zip'\nListing '/opt/anaconda3/lib/python3.11'...\nCompiling '/opt/anaconda3/lib/python3.11/_sysconfigdata_arm64_apple_darwin20_0_0.py'...\nListing '/opt/anaconda3/lib/python3.11/lib-dynload'...\nListing '/opt/anaconda3/lib/python3.11/site-packages'...\nListing '__editable__.deepsigma-2.0.0.finder.__path_hook__'...\nCan't list '__editable__.deepsigma-2.0.0.finder.__path_hook__'\nListing '/opt/anaconda3/lib/python3.11/site-packages/aeosa'... on modified files\\n- ...........                                                              [100%]\n11 passed in 1.05s\\n- .................s.................                                      [100%]\n=============================== warnings summary ===============================\ntests/test_mesh_transport.py::TestMeshServer::test_server_health_endpoint\ntests/test_mesh_transport.py::TestMeshServer::test_push_endpoint\ntests/test_mesh_transport.py::TestMeshServer::test_pull_endpoint\ntests/test_mesh_transport.py::TestMeshServer::test_status_endpoint\ntests/test_mesh_transport.py::TestHTTPIntegration::test_http_transport_with_test_server\n  /Users/bryanwhite/Documents/DeepSigma-v0.3.0/src/mesh/server.py:64: DeprecationWarning: \n          on_event is deprecated, use lifespan event handlers instead.\n  \n          Read more about it in the\n          [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n          \n    @app.on_event(\"shutdown\")\n\ntests/test_mesh_transport.py::TestMeshServer::test_server_health_endpoint\ntests/test_mesh_transport.py::TestMeshServer::test_push_endpoint\ntests/test_mesh_transport.py::TestMeshServer::test_pull_endpoint\ntests/test_mesh_transport.py::TestMeshServer::test_status_endpoint\ntests/test_mesh_transport.py::TestHTTPIntegration::test_http_transport_with_test_server\n  /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastapi/applications.py:4573: DeprecationWarning: \n          on_event is deprecated, use lifespan event handlers instead.\n  \n          Read more about it in the\n          [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n          \n    return self.router.on_event(event_type)\n\ntests/test_mesh_transport.py::TestHTTPIntegration::test_http_transport_with_test_server\n  /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/starlette/testclient.py:439: DeprecationWarning: You should not use the 'timeout' argument with the TestClient. See https://github.com/Kludex/starlette/issues/1108 for more information.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n34 passed, 1 skipped, 11 warnings in 2.76s\\n- .............................................                            [100%]\n45 passed in 0.63s","changedFiles":7,"createdAt":"2026-02-22T15:43:18Z","deletions":35,"labels":[],"mergedAt":"2026-02-22T15:49:04Z","number":207,"title":"Security: tighten path containment across storage and mesh modules","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/207"},{"additions":14,"body":"## Summary\n- sanitize IRIS API response payloads to remove traceback/stack/exception-style fields before returning to clients\n- keeps API behavior while preventing accidental leakage through engine response objects\n\n## Files\n- dashboard/server/api.py\n- dashboard/api_server.py\n\n## Validation\n- python -m ruff check dashboard/server/api.py dashboard/api_server.py\n- python -m pytest tests/test_api.py tests/test_dashboard_api_wiring.py -q\n","changedFiles":2,"createdAt":"2026-02-22T15:35:51Z","deletions":2,"labels":[],"mergedAt":"2026-02-22T15:37:39Z","number":206,"title":"Security: sanitize IRIS responses to prevent stack-trace leakage","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/206"},{"additions":2,"body":"## Summary\n- replace traceback logging (`logger.exception`) with non-traceback logging (`logger.error`) on IRIS API failure paths\n- keep stable error responses (`IRIS query failed`) for callers\n\n## Files\n- dashboard/server/api.py\n- dashboard/api_server.py\n\n## Validation\n- python -m ruff check dashboard/server/api.py dashboard/api_server.py\n- python -m pytest tests/test_api.py tests/test_dashboard_api_wiring.py -q\n","changedFiles":2,"createdAt":"2026-02-22T15:32:46Z","deletions":2,"labels":[],"mergedAt":"2026-02-22T15:34:47Z","number":205,"title":"Security: remove stack-trace exposure in dashboard APIs","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/205"},{"additions":187,"body":"## Summary\n- harden path handling for tenant, node, episode, and filename-derived file access\n- add explicit least-privilege permissions to flagged GitHub workflows\n- stop returning raw exception strings in dashboard IRIS endpoints\n- tighten Azure auth URL assertion test to structured URL checks\n\n## Files touched\n- src/mesh/logstore.py\n- src/mesh/transport.py\n- src/governance/audit.py\n- src/governance/telemetry.py\n- src/tenancy/policies.py\n- src/credibility_engine/store.py\n- dashboard/server/exhaust_api.py\n- dashboard/server/api.py\n- dashboard/api_server.py\n- .github/workflows/ci.yml\n- .github/workflows/publish-langchain.yml\n- .github/workflows/no_dupes.yml\n- .github/workflows/kpi_gate.yml\n- .github/workflows/validate-llm-data-model.yml\n- tests/test_azure_auth.py\n\n## Validation\n- python -m pytest tests/test_azure_auth.py tests/test_exhaust_api.py tests/test_mesh_transport.py -q\n- python -m pytest tests/test_azure_auth.py tests/test_mesh_transport.py tests/test_mesh_benchmarks.py tests/test_exhaust_api.py tests/test_api.py tests/test_dashboard_api_wiring.py tests/test_evidence_tiering.py -q\n- python -m ruff check src/governance/audit.py src/governance/telemetry.py src/tenancy/policies.py src/mesh/logstore.py src/mesh/transport.py src/credibility_engine/store.py dashboard/server/exhaust_api.py dashboard/server/api.py dashboard/api_server.py tests/test_azure_auth.py\n","changedFiles":15,"createdAt":"2026-02-22T15:21:52Z","deletions":37,"labels":[],"mergedAt":"2026-02-22T15:25:55Z","number":203,"title":"Security: remediate code scanning hotspots","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/203"},{"additions":2193,"body":"## Summary\nAdds Repo Radar KPI pipeline and updates pilot banner:\n- KPI spec (`governance/kpi_spec.yaml`)\n- deterministic KPI run/render scripts\n- generated radar PNG/SVG + badge + PR comment artifacts\n- optional KPI CI workflow (`kpi_gate.yml`)\n- Build 72 banner fix in `scripts/pilot_in_a_box.py`\n\n## Validation\n- `make kpi` generated:\n  - `release_kpis/radar_v2.0.2.png`\n  - `release_kpis/radar_v2.0.2.svg`\n  - `release_kpis/badge_latest.svg`\n  - `release_kpis/PR_COMMENT.md`\n","changedFiles":34,"createdAt":"2026-02-22T15:09:56Z","deletions":255,"labels":[],"mergedAt":"2026-02-22T15:13:58Z","number":202,"title":"Build 73: Repo Radar KPI + Build 72 banner fix","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/202"},{"additions":58,"body":"## Summary\nApplies only the Build 72 delta on top of current main:\n- deterministic PASSFAILPASS behavior in `scripts/pilot_in_a_box.py`\n- canonical clean `pilot/README.md`\n\n## Why\nPrevious local commit could not be pushed directly because main is protected.\nThis PR carries the same intended Build 72 outcomes through required checks.\n","changedFiles":2,"createdAt":"2026-02-22T14:55:20Z","deletions":90,"labels":[],"mergedAt":"2026-02-22T14:57:10Z","number":201,"title":"Build 72: deterministic drill cleanup","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/201"},{"additions":1231,"body":"## Summary\nPush latest pilot hardening commits to main:\n- Build 71 PASSFAILPASS drill + WHY-60s + docs/docs pilot pack\n- Duplicate filename guardrails (`no-dupes`)\n\n## Key commits\n- `561f532` Build 71: pilot teeth pack\n- `89fd573` guardrails: block duplicate-like filenames\n- `3994182` pilot hardening pack\n\n## Validation\n- `python scripts/pilot_in_a_box.py` -> baseline 100, fail 65, pass 100\n- `python scripts/compute_ci.py` -> 100\n- `python scripts/why_60s_challenge.py` -> pass\n","changedFiles":64,"createdAt":"2026-02-22T14:42:28Z","deletions":10,"labels":[],"mergedAt":"2026-02-22T14:43:15Z","number":200,"title":"Build 71: Pilot Teeth Pack + guardrails","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/200"},{"additions":877,"body":"## Summary\nImplements the v2.0.2 GitHub-native Coherence Ops pilot substrate with deterministic CI scoring, drift/patch artifacts, and workflow automation.\n\n## Included\n- Pilot structure + quickstart + scorecard docs\n- Canonical schemas/templates for DLR, assumption, drift, patch\n- Fictional sample decision/assumption/drift/patch records\n- Deterministic `scripts/compute_ci.py` + generated reports\n- `coherence_ci.yml` workflow with fail/warn/pass gate thresholds\n- Drift/decision issue forms + PR checklist\n- Coherence labels documented and created in GitHub\n\n## Validation\n- Local run: `python3 scripts/compute_ci.py`\n- Current sample CI score: `100`\n","changedFiles":23,"createdAt":"2026-02-22T14:07:46Z","deletions":37,"labels":[],"mergedAt":"2026-02-22T14:12:47Z","number":198,"title":"Pilot: GitHub-native DriftPatch loop (v2.0.2)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/198"},{"additions":2927,"body":"## Summary\n\n- **Authority Ledger**: Append-only, hash-chained NDJSON recording who held authority at the moment of commit. Supports append, revoke, verify-chain, and active-for-actor queries.\n- **Sealed Run Binding**: `authority_ledger_ref` embedded in sealed runs; replay verification checks entry existence, hash match, revocation, temporal validity, and scope coverage.\n- **verify_pack**: One-command verification of admissibility packs  auto-discovers sealed run, signature, transparency log, and authority ledger.\n- **seal_and_prove --auto-authority**: Single command now handles authority binding end-to-end.\n- **L7 Authority-Bound**: New admissibility level in ADMISSIBILITY_LEVELS.md.\n- **RFC 3161 interface spec**: Three-tier timestamping strategy (baseline  TSA  public anchor).\n- **Log head generator**: `LOG_HEAD.json` for external anchoring of transparency log state.\n- **Public demo pack**: Committed golden pack with intentionally-public demo key (89-check self-verification).\n- **22 new tests** (1274 total), CI gate updated with authority + verify_pack steps.\n\n## Stats\n\n- 32 files changed, ~2900 lines added\n- 9 new files, 9 modified files, 14 new artifacts\n- 1274 tests passing (22 new)\n\n## Test plan\n\n- [x] `python -m pytest tests/ -x -q`  1274 passed\n- [x] `ruff check`  all clean\n- [x] Demo pack self-verification  89 checks PASS\n- [x] Smoke tests for authority_ledger_append, authority_ledger_verify\n- [ ] CI admissibility gate green on this PR\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":32,"createdAt":"2026-02-21T20:34:41Z","deletions":23,"labels":[],"mergedAt":"2026-02-21T20:40:23Z","number":185,"title":"feat: Authority Ledger + Verify Pack (v2.0.3)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/185"},{"additions":3373,"body":"## Summary\n\nComplete court-grade admissibility hardening for sealed governance artifacts:\n\n- **Merkle commitments**  four-root commitment tree (inputs, prompts, schemas, policies) embedded in sealed runs with auto-verification on replay\n- **Transparency log**  append-only NDJSON log with hash-chained entries for tamper-evident audit trail\n- **Multi-signature witness**  threshold-based multisig envelopes with role-tagged signatures (operator, reviewer, witness, auditor)\n- **Hardware-backed key hooks**  external signer protocol for YubiKey/HSM/KMS integration via `--external-signer-cmd`\n- **Determinism audit**  9-check audit tool verifying hash_scope, clock, IDs, canonical JSON, and merkle commitments\n- **`seal_and_prove` orchestrator**  single-command pipeline: seal  sign  witness  log  audit  replay  pack\n- **6 admissibility levels** (L0-L6) documented from Audit Clean through Hardware-Backed Keys\n\n### Files Changed\n\n| Category | New | Modified |\n|----------|-----|----------|\n| `src/tools/reconstruct/` | 6 | 3 |\n| `schemas/reconstruct/` | 4 | 2 |\n| `docs/reconstruct/` | 5 | 1 |\n| `tests/` | 4 (28 tests) | 0 |\n| `.github/workflows/` | 1 | 1 |\n| `artifacts/` | 2 | 0 |\n| **Total** | **22 new** | **7 modified** |\n\n## Test plan\n\n- [x] 1252 tests pass locally (1224 existing + 28 new)\n- [ ] Determinism Gate CI passes\n- [ ] Signature Gate CI passes\n- [ ] Admissibility Gate CI passes (new workflow)\n- [ ] `seal_and_prove` smoke test with `--pack-dir` produces complete pack\n- [ ] Determinism audit `--strict` passes on sealed output\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":29,"createdAt":"2026-02-21T18:20:14Z","deletions":48,"labels":[],"mergedAt":"2026-02-21T18:24:55Z","number":184,"title":"feat: Court-Grade Admissibility v1.3","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/184"},{"additions":1103,"body":"## Summary\n\n- Adds cryptographic signature blocks for sealed runs and manifests (`signature_block_v1.json`)\n- Two-tier algorithm strategy: ed25519 (preferred, public-key) with hmac-sha256 fallback (stdlib)\n- `sign_artifact.py`: signs any sealed artifact, produces adjacent `.sig.json`\n- `verify_signature.py`: recomputes hashes and verifies cryptographic signature\n- `seal_bundle.py` gains `--sign` / `--sign-algo` / `--sign-key-id` / `--sign-key` flags\n- `replay_sealed_run.py` gains `--verify-signature` / `--sig` / `--key` / `--public-key` flags\n- Key management docs: storage (env vars, keychain, GitHub secrets), rotation guidance, key ID format\n- Admissibility pack: what a third party needs to verify a sealed artifact\n- `.gitignore` updated for `*.key`, `*.pem`, `.env`\n\n## Test plan\n\n- [x] 8 signature tests pass locally (sign, verify, tamper detection, wrong key, integrated seal+sign, replay+verify, manifest signing)\n- [x] 24 existing tests still pass (7 reconstruct + 17 deterministic)\n- [x] Ruff lint clean\n- [ ] CI signature gate green\n- [ ] CI determinism gate green\n- [ ] CI reconstruct replay green\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":10,"createdAt":"2026-02-21T16:51:04Z","deletions":1,"labels":[],"mergedAt":"2026-02-21T16:57:38Z","number":183,"title":"Signature support v1.2: sign/verify sealed artifacts + replay signature enforcement","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/183"},{"additions":1493,"body":"## Summary\n\n- Canonical serialization + stable hashing across all sealed artifacts (`canonical_json.py`)\n- Deterministic IDs derived from commit hash  no RNG in sealed artifacts (`deterministic_ids.py`)\n- Fixed clock mode (`--clock`) binds time-of-commit without non-deterministic \"now\" (`time_controls.py`)\n- Deterministic CSV ordering by primary key (`deterministic_io.py`)\n- Explicit hash-scope manifest declares what is sealed vs excluded (`hash_scope_v1.json`)\n- Deterministic telemetry events with content-derived IDs (`emit_event.py`, `telemetry_event_v1.json`)\n- Seal bundle upgraded: `--clock`, `--deterministic`, `commit_hash`, `hash_scope` embedded in every sealed run\n- Replay tool recomputes commit hash from embedded scope and validates admissibility (exit codes 0/1/2/3/4)\n- CI determinism gate seals twice with same clock, asserts identical commit hashes\n- Golden test vectors + 17 new deterministic tests + 7 updated reconstruct tests\n- Determinism Doctrine doc: what's in scope, what's excluded, why clock is required, no repair after the fact\n\n## Test plan\n\n- [x] All 24 tests pass locally (7 reconstruct + 17 deterministic)\n- [x] Smoke test: seal twice with same `--clock`  identical commit hash\n- [x] Replay PASS on deterministic sealed runs (43/43 checks)\n- [x] Ruff lint clean\n- [ ] CI determinism gate green\n- [ ] CI reconstruct replay green\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":20,"createdAt":"2026-02-21T16:43:11Z","deletions":114,"labels":[],"mergedAt":"2026-02-21T16:44:54Z","number":182,"title":"Determinism controls v1.1: canonical JSON, deterministic IDs, fixed clock sealing, hash-scope manifest, byte-for-byte replay","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/182"},{"additions":1433,"body":"## Summary\n- Adds authority envelope schema binding actor, scope, policy/prompt/schema hashes, refusal state, and enforcement state to every sealed run\n- Adds refusal codes enum (`NO_AUTHORITY`, `SCOPE_VIOLATION`, `POLICY_EXPIRED`, `INSUFFICIENT_EVIDENCE`, `UNSAFE_ACTION`, `MISSING_PROVENANCE`)\n- Adds seal bundle builder (`seal_bundle.py`) that hashes all inputs (policy, prompts, schemas, CSVs) and produces admissible sealed runs with manifests\n- Adds replay tool (`replay_sealed_run.py`) for adversarial reconstruction without live system access\n- Adds governance policy baseline + version file for hashable policy binding\n- Adds CI workflow: seal  replay  unit tests\n- Integrates reconstructability requirements into Prompt OS sealed export spec\n\n## Path adaptations\nAll paths use the consolidated structure:\n- Scripts: `src/tools/reconstruct/` (not `scripts/`)\n- Sample data: `artifacts/sample_data/prompt_os_v2/` (not `sample_data/`)\n\n## New files\n- `schemas/reconstruct/authority_envelope_v1.json`\n- `schemas/reconstruct/sealed_run_v1.json`\n- `schemas/reconstruct/refusal_codes_v1.json`\n- `src/tools/reconstruct/seal_bundle.py`\n- `src/tools/reconstruct/replay_sealed_run.py`\n- `docs/governance/POLICY_BASELINE.md`\n- `docs/governance/POLICY_VERSION.txt`\n- `docs/reconstruct/ADVERSARIAL_REPLAY_GUIDE.md`\n- `tests/test_reconstruct_replay.py`\n- `.github/workflows/reconstruct_replay.yml`\n\n## Test plan\n- [x] `python -m unittest tests.test_reconstruct_replay -v`  7/7 pass locally\n- [x] `ruff check` clean on all new Python files\n- [ ] CI: seal + replay validation workflow\n- [ ] CI: lint, unit tests, CodeQL\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":11,"createdAt":"2026-02-21T16:17:47Z","deletions":0,"labels":[],"mergedAt":"2026-02-21T16:19:27Z","number":181,"title":"Mechanical Reconstructability v1: authority envelope, refusal/enforcement emission, replay without live access","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/181"},{"additions":1048,"body":"## Summary\n- Adds a 10-minute \"Money Demo v2\" with before/after delta framing for executive live demos\n- Adds one-command driftpatch hero loop (`drift_to_patch_demo.py`) that detects drift conditions, creates patches, emits telemetry, and exports sealed run JSON\n- Adds Snowflake-ready export bundle generator (`export_for_snowflake.py`) with manifest + demo guide\n- Updates docs indexes and CI smoke tests (hero loop + unit tests)\n\n## Path adaptations\nAll paths use the consolidated structure from PR #179:\n- Scripts: `src/tools/prompt_os/` (not `scripts/`)\n- Sample data: `artifacts/sample_data/prompt_os_v2/` (not `sample_data/`)\n\n## New files\n- `docs/prompt_os/MONEY_DEMO_V2_10MIN.md`\n- `src/tools/prompt_os/drift_to_patch_demo.py`\n- `tests/test_prompt_os_hero_loop.py`\n- `src/tools/prompt_os/export_for_snowflake.py`\n- `docs/prompt_os/SNOWFLAKE_DEMO.md`\n- `src/tools/prompt_os/README.md`\n\n## Test plan\n- [x] `python -m unittest tests.test_prompt_os_hero_loop -v`  4/4 pass locally\n- [ ] CI: schema validation + hero loop smoke test + unit tests\n- [ ] CI: drift guard check\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":8,"createdAt":"2026-02-21T16:00:35Z","deletions":0,"labels":[],"mergedAt":"2026-02-21T16:06:58Z","number":180,"title":"Prompt OS: Money Demo v2 + one-command driftpatch hero loop + Snowflake export bundle","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/180"},{"additions":32,"body":"## Summary\n- Moves `sample_data/prompt_os_v2/`  `artifacts/sample_data/prompt_os_v2/` (pairs with Excel workbook)\n- Moves `scripts/prompt_os/`  `src/tools/prompt_os/` (consolidates with existing validator)\n- Eliminates two root-level folders that only contained Prompt OS content\n- Updates all references in CI workflow, Python scripts, shell script, and docs\n\n## Files changed\n- 7 CSVs moved, 3 scripts moved\n- `.github/workflows/prompt_os_validate.yml`  path triggers + run commands\n- `src/tools/validate_prompt_os.py`  default CSV dir path\n- `src/tools/prompt_os/*.py`  docstrings + argparse defaults\n- `src/tools/prompt_os/validate_prompt_os.sh`  REPO_ROOT depth + CSV path\n- `docs/prompt_os/README.md` + `SEALED_RUN_EXPORT_SPEC.md`  script paths\n- `README.md`  folder tree\n\n## Test plan\n- [ ] CI green (Prompt OS validate workflow triggers on new paths)\n- [ ] Drift Guard finds all required files at new locations\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":15,"createdAt":"2026-02-21T15:42:06Z","deletions":34,"labels":[],"mergedAt":"2026-02-21T15:43:22Z","number":179,"title":"chore: consolidate sample_data/ and scripts/ into existing folders","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/179"},{"additions":36,"body":"## Summary\n- Moves `HERO_DEMO.md`, `STABILITY.md`, `START_HERE.md` from repo root into `docs/`\n- Reduces root to the canonical 10-folder structure (`src/`, `tests/`, `docs/`, `dashboard/`, `schemas/`, `artifacts/`, `prompts/`, `sample_data/`, `scripts/`, `.github/`)\n- Rebases ~32 internal links from root-relative to docs/-relative\n- Fixes ~15 pre-existing broken links in `docs/` files that already referenced these as siblings\n- Removes stale `.dockerignore` entries (files now under `docs/` which is already excluded)\n\n## Files changed\n- `README.md`  3 link paths updated\n- `.dockerignore`  removed 2 lines (`HERO_DEMO.md`, `START_HERE.md`)\n- `docs/99-docs-map.md`  3 link paths updated\n- `docs/START_HERE.md`  21 link paths rebased\n- `docs/HERO_DEMO.md`  8 link paths rebased\n- `docs/STABILITY.md`  3 link paths rebased\n\n## Test plan\n- [ ] CI green (no Python/Docker changes  lint, tests, builds unaffected)\n- [ ] Spot-check links on GitHub PR file preview\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":6,"createdAt":"2026-02-21T15:31:28Z","deletions":38,"labels":[],"mergedAt":"2026-02-21T15:33:05Z","number":178,"title":"chore: move root markdown files into docs/","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/178"},{"additions":33,"body":"## Summary\n- Moves 6 variant Dockerfiles (`Dockerfile.{coherence,exhaust,mcp,otel,rdf,tools}`) into `docker/`\n- Main `Dockerfile` stays at root per convention\n- Reduces root clutter from 30  24 items\n\n## Changes (9 files, 26 lines)\n- `docker-compose.yml`  5 `dockerfile:` paths updated\n- 6 `docker-*.yml` workflows  paths triggers + `file:` directives updated\n- `docker-publish.yml`  2 paths triggers updated\n- `docs/mcp-server.md`  build command updated\n\n## Test plan\n- [ ] CI green (lint, unit tests, validation gates)\n- [ ] Docker workflow path triggers resolve correctly\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":16,"createdAt":"2026-02-21T15:17:37Z","deletions":32,"labels":[],"mergedAt":"2026-02-21T15:24:05Z","number":177,"title":"Move variant Dockerfiles to docker/ subdirectory","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/177"},{"additions":94,"body":"## Summary\n\nEliminates directory sprawl by consolidating 5 extra top-level directories into the canonical 10-folder structure.\n\n- **`specs/`**  `schemas/core/`  JSON schemas join the schemas/ directory\n- **`templates/`**  `artifacts/templates/`  workbook + Power Automate templates join artifacts/\n- **`examples/`**  `docs/examples/`  example lattices and demo stacks join docs/\n- **`fixtures/`**  `tests/fixtures/`  connector and dataset fixtures merge with existing test fixtures\n- **`mdpt/`**  `src/mdpt/`  Python package joins the src/ directory\n\n### Canonical 10-folder structure (tracked)\n\n```\n.github/    artifacts/    dashboard/    docs/    prompts/\nsample_data/    schemas/    scripts/    src/    tests/\n```\n\n### What was updated\n- ~30 code references (Path constants, CI paths, docstrings)\n- `.github/workflows/ci.yml` (BOOT validator, MDPT gate paths)\n- `README.md` directory tree + links\n- `START_HERE.md` links\n- `docs/fixtures.md` paths\n- `pyproject.toml` already discovers `mdpt*` from `src/`\n- `data/` was already gitignored with no tracked files\n\n## Test plan\n\n- [x] 44 key tests pass locally (schema, mdpt index, mdpt package)\n- [x] Ruff lint passes on all changed Python\n- [ ] Full CI suite passes\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":180,"createdAt":"2026-02-21T15:01:46Z","deletions":92,"labels":[],"mergedAt":"2026-02-21T15:10:10Z","number":176,"title":"Consolidate to 10-folder structure","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/176"},{"additions":867,"body":"## Summary\n\n- **A)** Expands sample data to demo-ready volume  25 rows per table (12 weekly for dashboard_trends), all schema-compliant\n- **B)** Adds `scripts/prompt_os/validate_prompt_os.py`  CSV  schema parity validator checking columns, enums, types, and ranges with row-level error reporting\n- **C)** Adds sealed run export spec (`docs/prompt_os/SEALED_RUN_EXPORT_SPEC.md`) + MVP exporter (`scripts/prompt_os/export_sealed_run.py`) for CSV  JSON sealed snapshots\n- **D)** Adds `docs/prompt_os/DATA_VALIDATION_MAP.md` documenting all enum dropdowns + updates workbook with data validation dropdowns (12 dropdowns across 5 tabs)\n- **E)** Adds `.github/workflows/prompt_os_validate.yml`  CI workflow with schema validation job + drift guard job (checks required files exist)\n\n## QA Checklist\n\n- [x] 25-record CSVs exist for all tables\n- [x] `validate_prompt_os.py` passes locally (7/7 PASS)\n- [x] CI workflow file created\n- [x] Enums in docs match schema exactly\n- [x] Exporter writes JSON to `artifacts/sealed_runs/`\n- [x] Ruff lint passes on all new Python\n\n## Test plan\n\n- [ ] CI `prompt_os_validate` workflow runs and passes on this PR\n- [ ] Existing CI (lint, unit tests, validation gates) unaffected\n- [ ] `python scripts/prompt_os/export_sealed_run.py --run-id RUN-001` produces valid JSON\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":16,"createdAt":"2026-02-21T14:42:03Z","deletions":30,"labels":[],"mergedAt":"2026-02-21T14:47:32Z","number":175,"title":"Prompt OS: demo-grade sample data, schema validator, sealed-run export spec, enum validation, CI drift guard","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/175"},{"additions":473,"body":"## Summary\n\n- Adds `src/tools/prompt_health_telemetry.py` with 5 subcommands:\n  - `record`  log prompt usage events (success, rating, model)\n  - `check-drift`  compare LLM output structure against expected sections\n  - `analyze`  compute per-prompt health metrics (success rate, avg rating, drift flag)\n  - `update-workbook`  sync telemetry data to PromptLibraryTable (UsageCount, SuccessRate, DriftFlag)\n  - `report`  full telemetry dump with health analysis\n- Drift detection: section coverage 90% = None, 7089% = Minor, <70% = Major\n- Telemetry stored in `data/prompt_telemetry/` as CSV (auto-created on first use)\n- Adds `docs/prompt_os/TELEMETRY.md` documentation\n\nCloses #167\n\n## Test plan\n\n- [ ] `python -m tools.prompt_health_telemetry record --prompt-id PRM-001 --success --rating 4` records event\n- [ ] `python -m tools.prompt_health_telemetry analyze` shows per-prompt metrics\n- [ ] `python -m tools.prompt_health_telemetry check-drift --prompt-id PRM-001 --output-text \"...\"` detects missing sections\n- [ ] `python -m tools.prompt_health_telemetry update-workbook` updates PromptLibraryTable\n- [ ] No hardcoded tenant or org-specific data\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-21T14:23:54Z","deletions":0,"labels":[],"mergedAt":"2026-02-21T14:28:43Z","number":174,"title":"Prompt health telemetry: usage tracking + drift detection (#167)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/174"},{"additions":570,"body":"## Summary\n\n- Adds 4 Power Automate flow template JSONs in `templates/power_automate/`:\n  1. Email/Teams  `AtomicClaimsTable` (keyword filter, source classification, auto-append)\n  2. Meeting notes  `DecisionLogTable` (manual trigger, 30-day review cycle, owner notification)\n  3. Weekly expiry + drift flagging  `PatchLogTable` (scheduled Mon 08:00, duplicate prevention)\n  4. Export sealed snapshot  JSON + PDF archive (SHA-256 seal hash, SharePoint storage)\n- README with import instructions, placeholder reference, and configuration notes\n- No tenant-specific values  all placeholders documented\n\nCloses #160\n\n## Test plan\n\n- [ ] All 4 JSON files are valid JSON\n- [ ] Table names in flows match workbook named tables exactly\n- [ ] README import instructions are complete\n- [ ] No tenant IDs, secrets, or org-specific values\n- [ ] Field mappings align with POWER_AUTOMATE_MAPPINGS.md\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":5,"createdAt":"2026-02-21T14:22:11Z","deletions":0,"labels":[],"mergedAt":"2026-02-21T14:28:38Z","number":173,"title":"Power Automate flow templates (#160)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/173"},{"additions":0,"body":"## Summary\n\n- Adds 3 charts to `DASHBOARD_TRENDS` tab in `Coherence_Prompt_OS_v2.xlsx`:\n  - Line chart: ActiveDecisions + AvgConfidence over time\n  - Bar chart: OpenPatches + REDPatches by week (RED series colored red)\n  - Area chart: AvgPromptHealth trend\n- Charts reference `DashboardTrendsTable` columns and auto-update with new rows\n\nCloses #163\n\n## Test plan\n\n- [ ] Workbook opens in Excel without errors\n- [ ] DASHBOARD_TRENDS tab shows 3 charts\n- [ ] Charts display data from the 3 sample trend rows\n- [ ] Adding a new trend row updates all charts\n- [ ] Named tables still intact after chart additions\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-21T14:20:10Z","deletions":0,"labels":[],"mergedAt":"2026-02-21T14:28:33Z","number":172,"title":"Dashboard charts for trends (#163)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/172"},{"additions":343,"body":"## Summary\n\n- **CSV/Schema Validator** (`src/tools/validate_prompt_os.py`)  validates all 7 sample CSVs against `prompt_os_schema_v2.json` with type, enum, range, and required-field checks. Exits non-zero on failure for CI integration.\n- **Sealed Snapshot Exporter** (`src/tools/export_sealed_snapshot.py`)  reads all named tables from the workbook via openpyxl, exports as JSON, computes SHA-256 seal hash, writes sealed snapshot with metadata.\n\nBoth tools tested and passing against current sample data and workbook.\n\nCloses #161, Closes #162\n\n## Test plan\n\n- [ ] `python -m tools.validate_prompt_os`  all 7 CSVs pass\n- [ ] `python -m tools.export_sealed_snapshot`  snapshot with 7 tables + seal hash\n- [ ] Validator exits non-zero on intentionally bad CSV data\n- [ ] Exporter output matches sealed run JSON structure from POWER_AUTOMATE_MAPPINGS.md\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-21T14:19:32Z","deletions":0,"labels":[],"mergedAt":"2026-02-21T14:28:29Z","number":171,"title":"Python tools: CSV validator + sealed snapshot exporter (#161, #162)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/171"},{"additions":288,"body":"## Summary\n\n- Adds 3 JSON-output variants for automation pipelines (#165):\n  - `01_unified_executive_analysis_json.md`  structured decision JSON\n  - `02_reality_assessment_json.md`  perception correction JSON\n  - `03_multi_dim_prompting_for_teams_a1_json.md`  workbook triage JSON\n- Adds Decision Compression prompt (#166):\n  - Detects rushed decisions via 5 compression factors\n  - Scores compression risk (Low/Medium/High)\n  - Provides decompression steps with 2448h cooling period\n  - Maps to DECISION_LOG CompressionRisk field\n- Updates PROMPTS.md and prompts/README.md with all new entries\n\nCloses #165, Closes #166\n\n## Test plan\n\n- [ ] All 4 new prompt files render correctly on GitHub\n- [ ] JSON schemas in prompt text are valid JSON\n- [ ] PROMPTS.md links resolve to correct files\n- [ ] prompts/README.md index includes all new entries\n- [ ] No proprietary info\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":6,"createdAt":"2026-02-21T14:18:00Z","deletions":14,"labels":[],"mergedAt":"2026-02-21T14:28:25Z","number":170,"title":"Prompt variants v2: JSON outputs + Decision Compression (#165, #166)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/170"},{"additions":56,"body":"## Summary\n\n- Renames `GOVERNANCE_POLICY_CARD.md`  `GOVERNANCE.md` per issue spec\n- Adds seal policy: when to seal, seal contents, integrity rules\n- Adds retention policy: 12-month minimum for snapshots, append-only ledger, archive naming\n- Updates Related Docs link in prompt_os README\n\nCloses #164\n\n## Test plan\n\n- [ ] `docs/prompt_os/GOVERNANCE.md` exists with all sections\n- [ ] Ownership matrix covers all 8 tabs\n- [ ] Seal policy defines required vs recommended triggers\n- [ ] Retention table covers all artifact types\n- [ ] Linked from `docs/prompt_os/README.md`\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-21T14:15:36Z","deletions":3,"labels":[],"mergedAt":"2026-02-21T14:28:21Z","number":169,"title":"Governance policy: seal policy + retention rules (#164)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/169"},{"additions":348,"body":"## Summary\n\n- Unifies workbook A1 control prompt into a single canonical source (`prompts/prompt_os/START_SESSION_A1.md`); converts `prompts/canonical/03_*` into a compatibility pointer\n- Improves repo discoverability: root README links to quickstart/prompts/diagram; prompt_os README adds \"Start Here (60 seconds)\" onboarding\n- Adds 1-page executive brief for adoption conversations (what/why/KPIs/pilot/done-state)\n- Adds 2-week pilot runbook with day-1 setup, daily/weekly checklists, success metrics, and stop conditions\n- Adds minimal governance policy card: ownership matrix, review cadence, sealversionpatch rule\n- Adds `prompts/README.md` index for human navigation across all prompt assets\n\n## Test plan\n\n- [ ] `prompts/canonical/03_*` is a pointer only  no duplicate prompt content\n- [ ] `docs/prompt_os/PROMPTS.md` links to `START_SESSION_A1.md` for workbook A1\n- [ ] All markdown links resolve (21 links verified)\n- [ ] Table names consistent across all docs (7 canonical names verified)\n- [ ] Mermaid diagram matches all 10 tab names\n- [ ] No proprietary info in any file\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":8,"createdAt":"2026-02-21T14:11:20Z","deletions":51,"labels":[],"mergedAt":"2026-02-21T14:13:11Z","number":168,"title":"Prompt OS polish: canonical A1, exec brief, pilot runbook, governance card","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/168"},{"additions":211,"body":"## Summary\n\n- Adds three canonical prompts as versioned repo assets in `prompts/canonical/`\n- `01_unified_executive_analysis.md`  structured decision output with blast radius, reversibility, failure modes, options comparison\n- `02_reality_assessment.md`  perception correction with drift check (ego, scarcity, urgency, pattern projection)\n- `03_multi_dim_prompting_for_teams_a1.md`  workbook A1 control prompt for triage sessions\n- Documents intended usage and workbook tab mapping in `docs/prompt_os/PROMPTS.md`\n- Sets foundation for automation + prompt governance\n\n## Test plan\n\n- [ ] All three prompt files exist and render correctly on GitHub\n- [ ] PROMPTS.md links resolve to correct files\n- [ ] No proprietary info in any prompt\n- [ ] Root README updated with Prompts section\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":5,"createdAt":"2026-02-21T13:58:21Z","deletions":0,"labels":[],"mergedAt":"2026-02-21T14:03:30Z","number":159,"title":"Canonical prompts v1  Executive / Reality / Team Workbook A1","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/159"},{"additions":1398,"body":"## Summary\n\n- Adds `Coherence_Prompt_OS_v2.xlsx`  Excel-first cognition container with 10 tabs, named tables, and computed scoring formulas\n- Adds Assumptions half-life + expiry risk (RED/YELLOW/GREEN) with automatic date-based decay\n- Adds driftpatch log linking expired assumptions and degraded prompts to corrective actions\n- Adds LLM output capture tab for sealed runs (top actions, risks, seal hash)\n- Adds dashboard v2 (live KPI summary) + trends snapshots (weekly history)\n- Adds full documentation: tabs/schema reference, scoring formulas, Power Automate mappings\n- Adds mermaid architecture diagram (Perception  Decision  Memory  Drift  Patch)\n- Adds JSON schema with types, enums, required columns, and example records for all 7 named tables\n- Adds sample CSV exports for all tables (generic data only)\n- Adds START_SESSION_A1 prompt for LLM workbook triage sessions\n\n## Test plan\n\n- [ ] Workbook opens in Excel and named tables exist (DecisionLogTable, AtomicClaimsTable, etc.)\n- [ ] Formulas compute correctly: PriorityScore, CredibilityScore, PromptHealth, ExpiryRisk\n- [ ] Docs match tab names exactly\n- [ ] Mermaid diagram renders on GitHub\n- [ ] No proprietary info in any file\n- [ ] Sample CSVs have correct headers matching schema\n- [ ] JSON schema validates against sample CSV data\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":17,"createdAt":"2026-02-21T13:56:52Z","deletions":0,"labels":[],"mergedAt":"2026-02-21T14:00:19Z","number":158,"title":"Excel Prompt OS v2  assumptions half-life, driftpatch, dashboard v2","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/158"},{"additions":131,"body":"## Summary\n- **Hard prune** `docs/mermaid/` from 47 diagram files down to 4 canonical diagrams\n- **Archive** 43 non-canonical diagrams to `docs/archive/mermaid/` (preserved, not deleted)\n- **Guardrail** `src/tools/mermaid_audit.py` + CI gate to prevent re-sprawl\n\n## Canonical Set\n\n| # | Diagram | Purpose |\n|---|---------|---------|\n| 01 | System Architecture | System poster  where RAL sits in the stack |\n| 05 | Drift to Patch | 8 drift types  severity  fingerprint  7 patches |\n| 06 | Coherence Ops Pipeline | DLR/RS/DS/MG data flow + scoring |\n| 10 | Integration Map | Connectors, surfaces, runtime integrations |\n\n## Before / After\n\n| Metric | Before | After |\n|--------|--------|-------|\n| `docs/mermaid/*.md` | 47 | 4 + README |\n| `docs/archive/mermaid/` | 0 | 43 |\n| Embedded mermaid blocks | 25 | 25 (all local/contextual) |\n| Standalone `.mmd` | 9 | 9 (example-specific) |\n| CI guardrail | none | `mermaid_audit.py` in validation-gates |\n\n## Test plan\n- [x] `python src/tools/mermaid_audit.py`  PASS\n- [x] `ruff check`  clean\n- [x] Full test suite  1168 passed\n- [x] Wiki Mermaid-Diagrams page updated\n- [x] No broken links (only 1 repo ref to `docs/mermaid/` dir, still valid)\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":46,"createdAt":"2026-02-20T16:22:09Z","deletions":63,"labels":[],"mergedAt":"2026-02-20T16:25:23Z","number":156,"title":"Build 62: Mermaid hard prune  4 canonical, 43 archived","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/156"},{"additions":868,"body":"## Summary\n\n- Adds `LlamaCppConnector`  targets any OpenAI-compatible server (`/v1/chat/completions`, `/v1/models`)\n- Refactors `LLMExtractor._call_api()` into a backend router: `DEEPSIGMA_LLM_BACKEND=local` dispatches to local, default remains `anthropic`\n- Updates `exhaust_refiner.py` guard to allow local backend without `ANTHROPIC_API_KEY`\n- Adds `Source.local` to exhaust models, `[local]` extras to pyproject.toml\n- Full exhaust adapter (`LocalLLMExhaustAdapter`) emitting prompt/response/metric events\n- Dockerfile.exhaust + docker-compose.yml updated with optional local backend config\n\n## Test plan\n\n- [x] 14 new tests in `test_local_llm_adapter.py` (connector, exhaust, extractor dispatch, Source enum)\n- [x] 5 existing `test_exhaust_llm_extractor.py` tests pass (zero regression)\n- [x] Full suite: 1168 passed, 0 failed\n- [x] `ruff check` clean\n- [ ] CI green on push\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":12,"createdAt":"2026-02-20T15:53:52Z","deletions":5,"labels":[],"mergedAt":"2026-02-20T16:03:25Z","number":155,"title":"feat: Build 61  Local Inference Adapter (llama.cpp)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/155"},{"additions":215,"body":"## Summary\nFull folder reorganization in 4 phases (4 commits):\n\n**Phase 1  Consolidate docs** (42  26 dirs)\n- Move 16 root directories under `docs/` (canonical, category, cookbook, llm_data_model, mermaid, metrics, ontology, policy_packs, rdf, release, roadmap, runtime, schemas, sim, wiki)\n- Move 7 root `.md` files under `docs/` (ABOUT, CONFIG_REFERENCE, GLOSSARY, NAV, OPS_RUNBOOK, TEST_STRATEGY, TROUBLESHOOTING)\n- Move `datasets/` to `fixtures/datasets/`\n\n**Phase 2  Merge small packages** (26  24 dirs)\n- `primitives/compression.py`  `engine/compression.py`\n- `connectors/contract.py`  `adapters/contract.py`\n- Update 16 import references\n\n**Phase 3  src/ layout** (24  13 dirs)\n- Move 12 Python packages into `src/` (core, credibility_engine, deepsigma, engine, adapters, services, mesh, governance, tenancy, verifiers, tools, demos)\n- Update `pyproject.toml` with `where = [\"src\", \".\"]`\n- Fix all `Path(__file__).parents[N]` computations (+1 level)\n- Update 6 Dockerfiles, 7 CI workflow path triggers, test file paths\n\n**Phase 4  Cleanup** (13  10 dirs)\n- Add `data/` to `.gitignore`, remove from tracking (23 files)\n- Remove redundant `workflows/DeepSigma.yml`\n\n## Final structure\n```\nsrc/           12 Python packages (all source code)\ntests/         1050+ tests\ndocs/          All documentation consolidated\ndashboard/     React + Python API (hybrid)\nmdpt/          MDPT tools + Power App (hybrid)\nspecs/         JSON schemas\nexamples/      Working examples\ntemplates/     Excel workbook templates\nfixtures/      Test fixtures + datasets\n.github/       CI/CD workflows\n```\n\n## Test plan\n- [x] Full test suite: 1131 passed, 3 skipped, 0 failures\n- [x] LLM data model validation passes\n- [x] `deepsigma doctor --json` works\n- [ ] CI green on all 11 jobs\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":447,"createdAt":"2026-02-20T14:52:05Z","deletions":652,"labels":[],"mergedAt":"2026-02-20T15:22:16Z","number":154,"title":"refactor: full folder reorganization (42  10 dirs)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/154"},{"additions":162,"body":"## Summary\n\n- **RDF/SPARQL dependency pinning**  pin `rdflib>=7.0,<8` + `pyparsing>=3.1` to prevent pyparsing 3.0.x incompatibility; add `openclaw` extra; add `services*` to package includes; CI installs rdf extra on py3.12 Linux\n- **Feature-gate SPARQL service**  fix module-level crash when rdflib not installed (`Namespace(...)` at import time); conditional init + `None` fallback\n- **MDPT doc consolidation**  mark old 5-screen Power Apps Screen Map as superseded; add Documentation Map table to `mdpt/README.md`\n- **ConnectorV1 contract standardization**  add `list_records`/`get_record` stubs to `AskSageConnector`; add `TestConnectorV1Methods` enforcement tests across all 5 adapters\n- **Release packaging sanity**  sdist builds clean, `services` package included in distribution\n\n## Test plan\n- [x] 1050 tests pass locally (`pytest tests/ -m \"not benchmark\"`)\n- [x] `python -m build --sdist` succeeds\n- [x] `services/sparql_service.py` imports cleanly without rdflib installed\n- [x] All 5 connector adapters pass method-presence tests\n- [ ] CI green across matrix\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":9,"createdAt":"2026-02-20T14:11:20Z","deletions":12,"labels":[],"mergedAt":"2026-02-20T14:18:07Z","number":153,"title":"fix: backlog cleanup before focus mode","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/153"},{"additions":1200,"body":"## Summary\n- **LatticeGraph** serializes `Claim`, `DriftEvent`, `CorrelationCluster` Python dataclasses to RDF triples using the `ds:` Coherence Ops ontology namespace\n- **SPARQLService** wraps rdflib's SPARQL 1.1 engine with 7 standard queries: low confidence claims, evidence chains, drift-by-region, all claims/drift, cluster risk, graph stats\n- Turtle and N-Triples export for offline analysis and interop with Jena Fuseki\n- Trust Scorecard integration via `rdf_metrics()`  triple counts, query latency stats\n- Performance validated: all queries <1s at 10k-node scale\n\n## Acceptance Criteria (from #109)\n- [x] RDF serialization of lattice (Claim, Evidence, Source, DriftSignal as RDF classes)\n- [x] SPARQL endpoint (rdflib in-process)\n- [x] Standard queries: confidence < threshold, evidence chains for claim X, drift by region\n- [x] Turtle (.ttl) export for offline analysis\n- [x] Integration with Trust Scorecard pipeline\n- [x] Performance: SPARQL queries < 1s for 10k-node lattice\n- [x] Documentation with example queries (module docstring)\n\n## Test plan\n- 42 tests across 7 test classes\n- `TestLatticeGraph` (12): RDF triple serialization, type assertions, evidence linking\n- `TestSPARQLService` (14): all standard queries, custom query, tracking\n- `TestExport` (5): Turtle roundtrip, N-Triples, content assertions\n- `TestScorecardIntegration` (3): metrics structure and values\n- `TestPerformance` (3): 10k-node query SLO, serialization SLO\n- `TestEdgeCases` (5): empty graph, null confidence, empty clusters\n\nCloses #109\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-20T13:41:55Z","deletions":0,"labels":[],"mergedAt":"2026-02-20T13:46:09Z","number":132,"title":"Add RDF/SPARQL service for semantic lattice queries","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/132"},{"additions":1032,"body":"## Summary\n- Add `WASMRuntime` sandbox with wasmtime backend for untrusted policy execution\n- Configurable memory limits (default 64 MB), fuel metering (~5s CPU), wall-clock timeout\n- Filesystem and network access denied by default\n- Import whitelist with 7 approved host functions\n- Graceful termination on limit breach (returns `ExecutionResult`, no process crash)\n- WASM binary validation (magic number, size, imports) before execution\n- Fuzzing harness for random bytes and malicious function names\n- Security audit documentation (`SECURITY_AUDIT.md`)\n\n## Test plan\n- [x] 43 tests pass (config, runtime, validation, execution, access control, whitelist, fuzzing)\n- [x] Full suite: 1110 passed, no regressions\n- [x] Lint clean\n\nCloses #108\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-20T13:32:54Z","deletions":0,"labels":[],"mergedAt":"2026-02-20T13:35:00Z","number":131,"title":"feat: harden OpenClaw WASM runtime (#108)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/131"},{"additions":769,"body":"## Summary\n- Add SharePoint list schema JSON (`sharepoint_list_schema.json`) with 3 list definitions (PromptCapabilities, PromptRuns, DriftPatches)\n- Add Power Automate flow template (`flow_scheduled_index_regen.json`) for weekly index regeneration\n- Add deployment guide (`mdpt/docs/power_app_deployment.md`) with step-by-step instructions\n- Add `.zip` package builder (`mdpt/tools/package_power_app.py`) bundling all artifacts\n\n## Test plan\n- [x] 12 tests pass (package builder, schema validation, flow template)\n- [x] Package generates cleanly with all 14 files + manifest\n- [x] Full suite: 1067 passed, no regressions\n- [x] Lint clean\n\nCloses #97\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":5,"createdAt":"2026-02-20T13:24:07Z","deletions":0,"labels":[],"mergedAt":"2026-02-20T13:28:38Z","number":130,"title":"feat: ship MDPT Power App deployment package (#97)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/130"},{"additions":592,"body":"## Summary\n- Add `list_records()` and `get_record()` for ConnectorV1 contract compliance\n- Add configurable column mapping (`column_map` constructor param) for flexible evidence field extraction\n- Support table, view, and custom SQL query source modes\n- Fix `_mapped_value` to gracefully handle mock-created instances (fixture tests)\n\n## Test plan\n- [x] 32 Snowflake tests pass (auth, cortex, warehouse, contract, mapping, exhaust)\n- [x] 3 fixture tests restored (previously broken by missing `_column_map`)\n- [x] Full suite: 1055 passed, no regressions\n- [x] Lint clean\n\nCloses #94\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-20T13:16:10Z","deletions":123,"labels":[],"mergedAt":"2026-02-20T13:20:29Z","number":129,"title":"feat: Snowflake connector contract compliance (#94)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/129"},{"additions":538,"body":"## Summary\n- Add `list_records()` and `get_record()` methods for ConnectorV1 contract compliance\n- Add rate-limit handling with exponential backoff for HTTP 429 / 503 (honours `Retry-After` header)\n- Add integration tests with `skip-if-no-creds` marker for live Azure AD testing\n- Fix all E501 line-length violations\n\n## Test plan\n- [x] 36 unit tests pass (helpers, canonical, contract, retry, throttle)\n- [x] 2 integration tests skip gracefully without credentials\n- [x] Full suite: 1045 passed, no regressions\n- [x] Lint clean\n\nCloses #93\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-20T13:08:01Z","deletions":129,"labels":[],"mergedAt":"2026-02-20T13:11:41Z","number":128,"title":"feat: production-harden SharePoint connector (#93)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/128"},{"additions":1407,"body":"## Summary\n- Adds `tools/generate_healthcare_cds_workbook.py`  Healthcare CDS generator (Meridian Health Partners: clinical, staffing, formulary, billing governance)\n- Adds `tools/generate_finserv_cds_workbook.py`  FinServ CDS generator (Apex Capital Partners: VaR, AML, Basel III, SOX governance)\n- Both produce BOOT-compliant workbooks with 7 canonical named tables (tblTimeline, tblDeliverables, tblDLR, tblClaims, tblAssumptions, tblPatchLog, tblCanonGuardrails), 25 rows each\n- Generated workbooks in `templates/creative_director_suite/`\n- 6 automated tests verifying BOOT protocol, table presence, and row counts\n\nCloses #98\n\n## Test plan\n- [x] `python tools/validate_workbook_boot.py templates/.../Healthcare_CoherenceOps.xlsx`  PASS\n- [x] `python tools/validate_workbook_boot.py templates/.../FinServ_CoherenceOps.xlsx`  PASS\n- [x] `pytest tests/test_workbook_boot.py -v`  6/6 pass\n- [x] `pytest tests/ -v -m \"not benchmark\"`  1035 pass, no regressions\n- [x] `flake8`  lint clean\n- [ ] CI pipeline green\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":5,"createdAt":"2026-02-20T02:18:25Z","deletions":0,"labels":[],"mergedAt":"2026-02-20T02:24:02Z","number":127,"title":"feat: Healthcare and FinServ CDS workbook templates (#98)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/127"},{"additions":976,"body":"## Summary\n- Adds `mesh/sync_plane.py` with `SyncPlane` coordinator, `SyncNode` per-region tracking, and `TimeBeacon` independent time references\n- Implements 6 drift signal types: `SEQUENCE_VIOLATION`, `LATE_ARRIVAL`, `CLOCK_SKEW`, `BEACON_DIVERGENCE`, `REPLAY_DETECTED`, `SIGNAL_LOSS`\n- Extends `EvidenceEnvelope` with `event_time` and `sequence_number` fields (backward-compatible defaults)\n- 26 tests covering setup, monotonic sequences, watermarks, beacons, replay detection, region authority, and integration scenarios\n\nCloses #102\n\n## Test plan\n- [x] `pytest tests/test_sync_plane.py -v`  26/26 pass\n- [x] `pytest tests/ -v -m \"not benchmark\"`  1029 pass, no regressions\n- [x] `flake8`  lint clean\n- [ ] CI pipeline green (all 12 jobs)\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-20T02:02:56Z","deletions":0,"labels":[],"mergedAt":"2026-02-20T02:09:08Z","number":126,"title":"feat: multi-region sync plane prototype (#102)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/126"},{"additions":438,"body":"## Summary\n- Benchmark harness (`MeshBenchmarkHarness`) with configurable node count, sparse peering (k=10), and realistic role distribution (60% edge, 20% validator, 15% aggregator, 5% seal)\n- 12 tests across 4 categories: throughput (pytest-benchmark CI gate), latency (p50/p95/p99), memory (tracemalloc), bottleneck isolation (serialization, filesystem I/O, crypto)\n- CI gate: 100-node full cycle must complete in < 60s (actual: ~1.4s)\n- Updated `docs/performance.md` with mesh topology section: throughput/latency/memory tables, bottleneck analysis, mesh SLOs\n\n## Test plan\n- [x] 12 benchmark tests all green (33s total)\n- [x] Full suite: 1003 passed, 0 failures\n- [x] Lint clean\n\nCloses #99\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-20T01:49:47Z","deletions":0,"labels":[],"mergedAt":"2026-02-20T01:53:35Z","number":125,"title":"feat: mesh topology benchmarks at 100/250/500 nodes (#99)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/125"},{"additions":1096,"body":"## Summary\n- Adds `Transport` protocol with `LocalTransport` (filesystem, backward compatible) and `HTTPTransport` (httpx, distributed deployment) implementations\n- Standalone mesh node HTTP server (`mesh/server.py`) with health checks and graceful shutdown\n- Static peer discovery registry (`mesh/discovery.py`) from config dict or YAML\n- MessagePack content negotiation with JSON fallback; retry with exponential backoff on transient failures\n- `MeshNode` now accepts a pluggable `transport` parameter (defaults to `LocalTransport`)\n\n## Test plan\n- [x] 35 new tests across 9 test classes covering protocol, local/HTTP transport, serialization, node integration, server endpoints, discovery, and full HTTP integration\n- [x] Full suite: 1003 passed, 0 failures\n- [x] Lint clean (ruff)\n\nCloses #105\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":7,"createdAt":"2026-02-20T01:40:09Z","deletions":26,"labels":[],"mergedAt":"2026-02-20T01:41:42Z","number":124,"title":"feat: pluggable HTTP mesh transport layer (#105)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/124"},{"additions":849,"body":"## Summary\n- Adds `credibility_engine/tiering.py` with `EvidenceTierManager` that classifies evidence into hot/warm/cold tiers based on age and TTL\n- Hot+warm evidence feeds Credibility Index scoring; cold is preserved for audit only\n- Extends `CredibilityStore` with warm/cold file helpers using compaction naming (`*-warm.jsonl`, `*-cold.jsonl`)\n- Wires tier manager into `CredibilityEngine` as opt-in via `enable_tiering()`\n- Adds tier summary and sweep API endpoints\n\n## Test plan\n- [x] 34 new tests in `test_evidence_tiering.py`  all pass\n- [x] Full suite: 968 passed, 3 skipped, 0 failures\n- [ ] CI green on all jobs\n\nCloses #101\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":6,"createdAt":"2026-02-20T01:12:47Z","deletions":9,"labels":[],"mergedAt":"2026-02-20T01:25:33Z","number":123,"title":"feat: add hot/warm/cold evidence tiering (#101)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/123"},{"additions":1049,"body":"## Summary\n- Implements `ConnectorV1` for ingesting LangGraph execution traces as Coherence Ops evidence\n- Supports three trace formats: LangSmith Run (flat list), LangSmith Run (nested tree), and `astream_events` v2  with auto-detection\n- Maps `run_type` to canonical records: `llm`  Claim (0.75), `tool`  Event (0.90), `retriever`  Document (0.80), `chain`  Event (0.85)\n- Reconstructs chain-of-thought links from `langgraph_triggers` metadata as `derived_from` edges\n- No runtime dependency on langchain/langgraph  only parses trace JSON\n- 28 unit tests + 5 golden fixture tests + cross-connector integration\n\n## Test plan\n- [x] 28 tests in `test_langgraph_connector.py` (source name, run format, events format, nested tree, envelopes, edge cases)\n- [x] 5 golden envelope fixture tests in `test_connector_fixtures.py`\n- [x] Cross-connector tests updated to include `langgraph_small`\n- [x] Source name attribute test added to `test_connector_contract_v1.py`\n- [x] Full suite: 934 passed, 0 failures\n\nCloses #95\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":9,"createdAt":"2026-02-20T01:00:48Z","deletions":1,"labels":[],"mergedAt":"2026-02-20T01:03:43Z","number":122,"title":"feat: add LangGraph connector for LLM chain evidence (#95)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/122"},{"additions":953,"body":"## Summary\n- New `engine/webhooks.py` module: `WebhookManager` with HMAC-SHA256 signing, retry + exponential backoff, Slack Block Kit formatting, JSONL persistence, delivery logging, audit integration\n- 5 event types: `drift_detected`, `quorum_break`, `credibility_threshold`, `patch_applied`, `seal_created`\n- 4 FastAPI endpoints: register, list, delete, test webhook\n- 5 convenience `notify_*()` functions for fire-and-forget integration hooks\n- 22 new tests (900 total pass, 0 regressions)\n\nCloses #107\n\n## Test plan\n- [x] 22 webhook tests pass locally (`tests/test_webhooks.py`)\n- [x] Full suite: 900 passed, 3 skipped, 0 failed\n- [ ] CI jobs all green\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":4,"createdAt":"2026-02-20T00:46:52Z","deletions":0,"labels":[],"mergedAt":"2026-02-20T00:50:24Z","number":121,"title":"feat: add webhook notification system for drift events","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/121"},{"additions":821,"body":"## Summary\n- Add 5 `coherence.*` tools: `query_credibility_index`, `list_drift_signals`, `get_episode`, `apply_patch`, `seal_decision`\n- API key authentication (optional, via `MCP_API_KEYS` env var) with per-session tracking\n- Per-client sliding window rate limiting (configurable via `MCP_RATE_LIMIT`, default 60 req/min)\n- 24 new integration tests covering auth, rate limiting, all coherence tools, and catalog validation (75 total MCP tests pass)\n- Full documentation at `docs/mcp-server.md`\n- Server + catalog version bumped to 1.0.0\n\nCloses #106\n\n## Test plan\n- [x] 75 MCP tests pass locally (`test_mcp_production.py`, `test_mcp_iris.py`, `test_mcp_resources.py`, `test_mcp_resilience.py`)\n- [ ] CI jobs all green\n- [ ] Loopback smoke test: `echo '{\"jsonrpc\":\"2.0\",\"method\":\"tools/list\",\"id\":1}' | python adapters/mcp/mcp_server_scaffold.py`\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":6,"createdAt":"2026-02-20T00:32:23Z","deletions":14,"labels":[],"mergedAt":"2026-02-20T00:35:17Z","number":120,"title":"feat: ship production MCP server with auth, rate limiting, and coherence tools","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/120"},{"additions":570,"body":"## Summary\n- Add streaming JSONL helpers (`_iter_jsonl`, `_count_jsonl`) for bounded-memory reads at scale\n- Optimize `detect_drift()` to stream canon file directly into lookup maps (eliminates intermediate list)\n- Apply streaming to health endpoint, drift listing, and drift-only episode filtering\n- Add 20 performance benchmarks validating pipeline at 10k, 50k, and 100k evidence nodes\n- Document performance characteristics, SLOs, and production recommendations\n\n## Test plan\n- [x] All 20 new performance tests pass locally (1.13s)\n- [x] All 49 existing exhaust tests pass (no regressions)\n- [ ] CI passes on Ubuntu and Windows matrix\n\nCloses #96\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":4,"createdAt":"2026-02-20T00:20:18Z","deletions":42,"labels":[],"mergedAt":"2026-02-20T00:22:04Z","number":119,"title":"feat: harden exhaust pipeline for production throughput (#96)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/119"},{"additions":551,"body":"## Summary\n- New CLI command: `deepsigma compact --input <dir> [--retention <days>] [--dry-run] [--json]`\n- Deduplicates records by type-specific ID fields (event_id, drift_id, etc.)\n- Strips redundant heartbeat events (keeps 1 per hour)\n- Tiers records into hot/warm/cold by timestamp age\n- Writes `{name}.jsonl` (hot), `{name}-warm.jsonl`, `{name}-cold.jsonl`\n- Recursive directory traversal, skips already-tiered files\n- 22 unit tests covering all compaction logic + CLI integration\n\n## Test plan\n- [ ] All CI jobs pass\n- [ ] `test_jsonl_compaction.py`  22 tests\n\nCloses #100\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-20T00:10:33Z","deletions":0,"labels":[],"mergedAt":"2026-02-20T00:11:52Z","number":118,"title":"feat: JSONL compaction with hot/warm/cold tiering","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/118"},{"additions":1168,"body":"## Summary\n- Add `StorageBackend` abstraction with SQLite, JSONL, and PostgreSQL implementations\n- Add `SQLiteMGBackend` and `PostgreSQLMGBackend` to Memory Graph persistence layer\n- `create_backend(url)` factory with `DEEPSIGMA_STORAGE_URL` env var fallback\n- SQLite uses stdlib `sqlite3` (zero deps); PostgreSQL uses `psycopg` (optional)\n- Evidence append-only guarantees enforced (events/drifts use `INSERT OR IGNORE`)\n- 48 new tests covering all backends, pagination, upserts, schema creation\n\n## Test plan\n- [ ] All CI jobs pass\n- [ ] `test_storage_backend.py`  28 tests (SQLite + JSONL + factory + schema)\n- [ ] `test_mg_persistence.py`  20 tests (JSONL + SQLite + InMemory MG backends)\n\nCloses #104\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":6,"createdAt":"2026-02-20T00:03:13Z","deletions":3,"labels":[],"mergedAt":"2026-02-20T00:06:12Z","number":117,"title":"feat: add PostgreSQL/SQLite persistence backend","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/117"},{"additions":85,"body":"## Summary\n- Split monolithic `test` job into 4 parallel jobs: **unit-tests**, **integration-tests**, **validation-gates**, **benchmarks**\n- Add `pip` caching (`actions/setup-python` built-in) to all Python jobs\n- Add `npm` caching (`actions/setup-node` built-in) to dashboard build\n- Unit tests use `--ignore` flags for future-proof discovery (no manual file lists to maintain)\n- `fail-fast: false` preserved across all matrix jobs\n- `publish` gated on unit-tests + integration-tests + validation-gates + lint + dashboard-build (benchmarks optional)\n\n## Test plan\n- [ ] All 6 CI jobs pass (unit-tests, integration-tests, validation-gates, benchmarks, lint, dashboard-build)\n- [ ] Pip cache hits on second run\n- [ ] npm cache hits on second run\n- [ ] Total wall-clock time < 5 min for unit+lint\n\nCloses #103\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-19T23:50:20Z","deletions":32,"labels":[],"mergedAt":"2026-02-19T23:55:59Z","number":116,"title":"ci: parallelize test jobs + dependency caching","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/116"},{"additions":5165,"body":"## Summary\n\n- **Game Studio:** no regressions; example remains E2E (validator 12/12, workbook 8 tabs, drift_patch_cycle clean)\n- **Healthcare:** now full AE vertical pack (RUNBOOK, IRIS queries, 4 patches, validator, workbook generator, CLI hook)\n- Both examples are runnable and demo-ready from repo root\n- Includes Build 57 PR script (`CLAUDE_PR_BUILD57_VERTICAL_PACKS.md`)\n\n## Verification (all passed)\n\n| Command | Result |\n|---------|--------|\n| Game Studio validator | 12/12 passed, 0 failed |\n| Healthcare validator | 12/12 passed, 0 failed |\n| Game Studio drift_patch_cycle | 4 signals, 4 patches, CI 8341recovery |\n| Healthcare drift_patch_cycle | 4 signals, 4 patches, CI 8748recovery |\n| Game Studio workbook | 8 tabs, 187 rows |\n| Healthcare workbook | 9 tabs, 210 rows |\n\n## Test plan\n\n- [x] `python examples/05-healthcare-lattice/tools/validate_example_json.py`  12 passed\n- [x] `python examples/05-healthcare-lattice/tools/generate_healthcare_workbook.py --out /tmp/test.xlsx`  9 tabs, 210 rows\n- [x] `python -m core.examples.drift_patch_cycle --example healthcare`  4/4/4\n- [x] `python examples/04-game-studio-lattice/tools/validate_example_json.py`  12 passed\n- [x] `python examples/04-game-studio-lattice/tools/generate_gamestudio_workbook.py --out /tmp/test.xlsx`  8 tabs, 187 rows\n- [x] `python -m core.examples.drift_patch_cycle --example game-studio`  4/4/4\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":19,"createdAt":"2026-02-19T23:11:01Z","deletions":1,"labels":[{"id":"LA_kwDOROCxlM8AAAACYsamqg","name":"vertical-pack","description":"Vertical pack standard upgrade","color":"1D76DB"},{"id":"LA_kwDOROCxlM8AAAACYsxang","name":"examples","description":"Example lattices and demos","color":"0E8A16"},{"id":"LA_kwDOROCxlM8AAAACYsxb3w","name":"healthcare","description":"Healthcare lattice vertical","color":"D93F0B"},{"id":"LA_kwDOROCxlM8AAAACYsxb_Q","name":"docs","description":"Documentation","color":"0075CA"},{"id":"LA_kwDOROCxlM8AAAACYszi3Q","name":"workbooks","description":"Excel workbook generators","color":"FBCA04"}],"mergedAt":"2026-02-19T23:15:28Z","number":115,"title":"Build 57: Add Healthcare vertical pack + confirm Game Studio pack (validators, workbooks, drift_patch_cycle hooks)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/115"},{"additions":183,"body":"## Summary\n- Adds `TrustScorecard` types, `generateMockTrustScorecard()` mock generator, and `fetchRealTrustScorecard()` API helper to `mockData.ts`\n- Adds `trustScorecard` slice to Zustand store with async fetcher that tries the real API first, then falls back to mock data\n- Refactors `TrustScorecardPanel` to use global store instead of local `useState`  adds 30-second periodic refresh and a manual refresh button\n- Wires overview tab with a new Trust Scorecard KPI row showing baseline/patched scores, pipeline step status, and SLO summary\n\n## Test plan\n- [x] `npm run build` passes (TypeScript + Vite)\n- [x] `python -m pytest tests/ -q`  735 passed, 3 skipped\n- [x] `ruff check .`  all checks passed\n- [ ] Manual: verify overview tab shows scorecard KPI cards\n- [ ] Manual: verify Trust Scorecard tab loads with mock fallback when API offline\n- [ ] Manual: verify 30s auto-refresh cycle on Trust Scorecard tab\n\nCloses #92\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":4,"createdAt":"2026-02-19T22:26:31Z","deletions":64,"labels":[],"mergedAt":"2026-02-19T22:28:50Z","number":114,"title":"Wire dashboard to live Trust Scorecard data","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/114"},{"additions":1193,"body":"## Summary\n- New `examples/05-healthcare-lattice/`  ~300 node lattice for a fictional multi-hospital health system (Meridian Health Partners)\n- 3 facilities: Meridian General (450 beds), Meridian Community (180 beds), Meridian Behavioral (60 beds)\n- 4 decision domains: Clinical Governance (CLN), Regulatory Compliance (REG), Operational Continuity (OPS), Financial Integrity (FIN)\n- 4 episodes: formulary conflict, staffing cascade, billing code drift, equipment maintenance gap\n- 4 drift signals with cross-facility correlation groups\n- 2 patch artifacts with sequenced remediation\n- 3 Mermaid diagrams\n- Full scenario plan with CI impact tables and cumulative timeline\n- `--example healthcare` flag added to `drift_patch_cycle.py`\n- Fiction guardrails prominently stated\n\n## Demonstrates domain portability\nSame Coherence Ops primitives (Episode, DriftSignal, Patch, Seal) applied to healthcare operations  proving the framework is not domain-specific.\n\n## Test plan\n- [x] 10/10 JSON files valid\n- [x] `--example healthcare` demo runs cleanly\n- [x] ruff clean\n- [x] Existing tests pass (no regressions)\n\nCloses #90\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":18,"createdAt":"2026-02-19T22:19:06Z","deletions":1,"labels":[],"mergedAt":"2026-02-19T22:28:32Z","number":113,"title":"Add Healthcare Lattice vertical example","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/113"},{"additions":306,"body":"## Summary\n- New `adapters/otel/spans.py`  canonical registry of all span names, attribute keys, and metric names\n- All attribute keys migrated to `deepsigma.*` namespace (e.g. `episode.id`  `deepsigma.episode.id`)\n- `exporter.py` refactored to use constants  zero hardcoded string literals remain\n- AST-based CI gate (`test_otel_span_registry.py`) that parses `exporter.py` and **fails** if any `start_as_current_span()`, `set_attribute()`, or metric creation call uses a string literal instead of a registered constant\n\n## Registry contents\n| Category | Count | Convention |\n|----------|-------|-----------|\n| Span names | 3 root + 1 dynamic prefix | Short labels (`decision_episode`, `phase.{name}`) |\n| Attribute keys | 12 static + 1 dynamic prefix | `deepsigma.<resource>.<field>` |\n| Metric names | 4 | `sigma.<resource>.<metric>` |\n| Event names | 1 | `degrade_triggered` |\n\n## Breaking change\nAttribute key namespace changed from bare (`episode.id`) to namespaced (`deepsigma.episode.id`). Any existing dashboards or alerts querying the old keys will need updating. This is intentional  freezing the contract now before more consumers depend on it.\n\n## Test plan\n- [x] 12 new registry enforcement tests pass\n- [x] 13 existing exporter tests pass (no regressions)\n- [x] ruff clean\n- [ ] CI matrix passes\n\nCloses #89\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-19T22:12:23Z","deletions":22,"labels":[],"mergedAt":"2026-02-19T22:28:09Z","number":112,"title":"Stabilize OTel span naming and attribute conventions","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/112"},{"additions":480,"body":"## Summary\n- New `adapters/mcp/resilience.py`  stdlib-only retry decorator and circuit breaker\n- `retry()`: exponential backoff with jitter, retries on transient errors (429, 502, 503, timeout, connection reset, rate limit)\n- `CircuitBreaker`: per-connector state machine (CLOSED  OPEN  HALF_OPEN), threshold + cooldown, thread-safe\n- All 6 connector families wrapped: SharePoint, Dataverse, AskSage, Cortex, Snowflake warehouse, Golden Path\n- `CircuitOpen` exceptions surface as JSON-RPC error code -32003 (service unavailable)\n- No new dependencies  stdlib only\n\n## Test plan\n- [x] 28 new tests in `test_mcp_resilience.py` (retry, breaker states, context manager, stats)\n- [x] 23 existing MCP tests pass unchanged (`test_mcp_iris.py`, `test_mcp_resources.py`)\n- [ ] CI matrix passes (Ubuntu + Windows)\n- [x] ruff clean\n\nCloses #88\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-19T22:08:50Z","deletions":17,"labels":[],"mergedAt":"2026-02-19T22:27:48Z","number":111,"title":"Harden MCP adapter with retry + circuit-breaker","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/111"},{"additions":23,"body":"## Summary\n- Adds Python 3.13 to the Ubuntu test matrix (was 3.10-3.12, now 3.10-3.13)\n- Adds Windows runner for Python 3.12 + 3.13\n- Sets `fail-fast: false` so all matrix combinations report independently\n- Gates shell/path-dependent steps (Golden Path, BOOT validation, MDPT, Trust Scorecard, Excel demo) to Linux only  Windows runs unit, integration, load, connector, Money Demo, and CLI smoke tests\n- Adds `Programming Language :: Python :: 3.13` classifier to pyproject.toml\n\n## Matrix (6 jobs)\n| OS | Python |\n|----|--------|\n| Ubuntu | 3.10, 3.11, 3.12, 3.13 |\n| Windows | 3.12, 3.13 |\n\n## Test plan\n- [ ] All 6 matrix jobs pass in CI\n- [ ] Windows jobs complete unit + integration + load + connector + CLI smoke\n- [ ] Ubuntu 3.13 runs the full step suite\n- [ ] `pip install -e \".[dev,excel]\"` succeeds on all combinations\n\nCloses #91\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":4,"createdAt":"2026-02-19T22:03:58Z","deletions":8,"labels":[],"mergedAt":"2026-02-19T22:27:31Z","number":110,"title":"Expand CI matrix: Windows + Python 3.13","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/110"},{"additions":1376,"body":"## Summary\n\n- Restructures `examples/04-game-studio-lattice/` into proper subdirectories (episodes/, drift_signals/, patches/, diagrams/, expected_outputs/, tools/)\n- Adds **60-second Quickstart** with 6 copy-paste commands to README\n- Adds **3 Mermaid diagrams**: contradiction loop (6 domains), shared infra blast radius (50 nodes/4 domains), drift-to-patch sequence\n- Adds **4 patch artifacts** (Patch-GS-001..004) completing the DriftPatch E2E cycle with decision options, step-by-step sequences, owners, rollback plans, and closure conditions\n- Adds **IRIS query pack** (`iris_queries.md`) with 5 deterministic queries and expected output stubs\n- Adds **JSON validation harness** (`validate_example_json.py`)  stdlib only, checks 12 files across 3 artifact types\n- Adds **Excel-first GameOps Pack workbook generator** (`generate_gamestudio_workbook.py`)  8 tabs, 175 rows, cross-referenced to ep-gs/DS-GS/Patch-GS IDs, includes LLM PROMPTS tab\n- Wires `--example game-studio` into `drift_patch_cycle.py` for on-rails demo\n- Adds **one-screen Demo Script** optimized for studio exec meetings (~5 min talk track)\n- Updates RUNBOOK with all new paths, tools, and verification checklist\n\n## Verification\n\n```\n$ python ./examples/04-game-studio-lattice/tools/validate_example_json.py\n12 files checked  12 passed, 0 failed\n\n$ python -m core.examples.drift_patch_cycle --example game-studio\n4 drift signals detected, 4 patch plans generated\n\n$ python -m pytest tests/ -q\n735 passed, 3 skipped\n\n$ ruff check core/examples/ examples/04-game-studio-lattice/tools/\nAll checks passed\n```\n\n## Test plan\n\n- [x] JSON validator passes all 12 artifact files\n- [x] `--example game-studio` prints full E2E transcript\n- [x] Workbook generates with 8 tabs (requires openpyxl)\n- [x] Existing test suite: 735 passed, 0 failures\n- [x] Ruff lint: clean\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":27,"createdAt":"2026-02-19T21:36:15Z","deletions":44,"labels":[],"mergedAt":"2026-02-19T21:37:05Z","number":86,"title":"Add Game Studio Lattice example (Quickstart + Diagrams + IRIS pack + DriftPatch + Workbook)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/86"},{"additions":84,"body":"## Summary\n\n- **STABILITY.md**: Rewrote from v0.3.2 alpha contract to v1.0.0 stable core contract. Covers credibility engine, governance, mesh, API endpoints, CLI. Experimental surfaces (adapters, dashboard, internal classes) clearly marked. Post-1.0 semver policy.\n- **pyproject.toml classifier**: `Development Status :: 3 - Alpha`  `Development Status :: 4 - Beta`\n- **pyproject.toml description**: Replaced \"Reality Await Layer (RAL) control plane for agentic AI\"  \"Institutional Decision Infrastructure for coherence, credibility, and drift governance\"\n\n## Test plan\n\n- [x] No code changes  documentation and metadata only\n- [x] Lint clean\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-19T20:26:28Z","deletions":64,"labels":[],"mergedAt":"2026-02-19T20:27:57Z","number":85,"title":"fix: v1.0.0 consistency cleanup","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/85"},{"additions":2802,"body":"## Summary\n\n- Added `mesh/` module: distributed multi-node credibility infrastructure with 4 roles (edge, validator, aggregator, seal authority)\n- Signed evidence envelopes (Ed25519 or HMAC-SHA256 demo fallback) with append-only log replication via HTTP push/pull\n- Federated quorum: policy-driven consensus requiring multi-region, multi-group agreement. Partition  UNKNOWN. Correlated failure  DEGRADED\n- 4-phase scenario controller (healthy  partition  correlated failure  recovery) demonstrating claim state transitions\n- Cross-node verification for envelope signatures and seal chain continuity\n- Mesh CLI (`python -m mesh.cli`) for init, run, scenario, and verify\n- v0.9.0 governance + credibility APIs preserved unchanged\n\n## Verification\n\n- 735 tests pass (0 failures, 3 skipped)\n- Ruff lint clean\n- Full scenario run: healthy (100/Stable/VERIFIED)  partition (47-70/UNKNOWN)  correlated failure (48-52/DEGRADED)  recovery (96-100/Stable/VERIFIED)\n- Envelope signatures: 63 checked, 63 passed, 0 failed\n- Seal chain: 84 seals, 0 breaks, 0 missing fields\n\n## How to Run\n\n```bash\npython -m mesh.cli init --tenant tenant-alpha\npython -m mesh.cli scenario --tenant tenant-alpha --mode day3\npython -m mesh.cli verify --tenant tenant-alpha\n```\n\n## Test plan\n\n- [x] Existing tests pass (735 passed)\n- [x] Ruff lint clean\n- [x] Mesh scenario demonstrates all 4 phases\n- [x] Envelope signatures verify\n- [x] Seal chain intact\n- [x] v0.9.0 APIs unmodified\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":17,"createdAt":"2026-02-19T20:16:04Z","deletions":2,"labels":[],"mergedAt":"2026-02-19T20:19:13Z","number":84,"title":"feat(v1.0.0): Distributed Credibility Mesh","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/84"},{"additions":1417,"body":"## Summary\n\n- **Per-tenant policy engine** with TTL/quorum/correlation/silence/SLO/quota thresholds, SHA-256 policy hashes, and policy evaluation against live engine state\n- **Seal chaining**  every seal links to the previous seal via `prev_seal_hash`, plus `policy_hash` and `snapshot_hash` for tamper-evident continuity\n- **Immutable audit trail**  append-only audit log for PACKET_GENERATE, PACKET_SEAL, SNAPSHOT_WRITE, POLICY_UPDATE (denied attempts always audited)\n- **Drift recurrence weighting**  fingerprint registry with 24h/7d counts and severity multipliers (>10 = 1.5x, >25 = 2.0x, >50 = 3.0x)\n- **Quotas + SLO telemetry**  per-tenant rate limits (HTTP 429 on exceed), packet latency tracking\n- **API additions**  `GET/POST /api/{tenant_id}/policy`, `GET /api/{tenant_id}/audit/recent`\n- **Dashboard**  policy hash + seal chain metadata in packet preview\n- v0.8.0 API compatibility preserved, 735 tests passing, ruff clean\n\n## Test plan\n\n- [x] 735 existing tests pass (no regressions)\n- [x] ruff lint clean\n- [x] Policy load/save/evaluate/hash verified for all 3 tenants\n- [x] Seal chaining verified: 3 consecutive seals with chain integrity\n- [x] Audit trail captures SUCCESS and DENIED outcomes\n- [x] Drift recurrence weighting produces correct multipliers (1.0x/1.5x)\n- [x] Quota enforcement returns DENIED after limit reached\n- [x] v0.8.0 snapshot methods return expected structure with new `policy_hash` field\n- [ ] Dashboard packet preview shows prev_seal_hash, policy_hash, snapshot_hash\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":19,"createdAt":"2026-02-19T19:44:33Z","deletions":15,"labels":[],"mergedAt":"2026-02-19T19:46:29Z","number":82,"title":"feat(v0.9.0): governance hardening layer","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/82"},{"additions":1692,"body":"## Summary\n\n- Added `tenancy/` module  tenant registry, paths, header-based RBAC\n- Added `tenant_id` propagation across all credibility artifacts (claims, drift, snapshots, packets, seals)\n- Added tenant-scoped persistence: `data/credibility/{tenant_id}/`\n- Added canonical API routes: `GET/POST /api/{tenant_id}/credibility/*` (7 endpoints)\n- Preserved alias routes: `/api/credibility/*`  DEFAULT tenant (6 endpoints)\n- Added `GET /api/tenants`  14 total routes\n- Dashboard supports tenant + role selection in API mode\n- Seeded 3 demo tenants with calibrated CI profiles:\n  - **Alpha**: CI=95 Stable\n  - **Bravo**: CI=86 Minor Drift (CG-002 REVIEW at 0.82)\n  - **Charlie**: CI=68 Elevated (CG-002 CRITICAL at 0.93, 1 UNKNOWN claim)\n- Store uses write-mode for current-state files, append-mode for event streams\n- Seal requires `coherence_steward` role (403 for all others)\n- Version bumped to 0.8.0\n- 735 tests pass, ruff clean\n\n## Note\n\nPR #80 was merged into `feature/credibility-engine-runtime-v0.7.0` instead of `main`. This PR applies the same v0.8.0 changes correctly onto `main`.\n\n## Test plan\n\n- [ ] `GET /api/tenants` returns 3 tenants\n- [ ] Switching tenants changes data (no cross-tenant bleed)\n- [ ] Alias routes `/api/credibility/*` serve DEFAULT tenant\n- [ ] `POST /api/{tenant_id}/credibility/packet/generate` works for all roles\n- [ ] `POST /api/{tenant_id}/credibility/packet/seal` returns 403 unless `coherence_steward`\n- [ ] Mock mode still works\n- [ ] `python -m pytest tests/ -q`  735 pass\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":40,"createdAt":"2026-02-19T19:18:14Z","deletions":178,"labels":[],"mergedAt":"2026-02-19T19:19:08Z","number":81,"title":"feat(v0.8.0): multi-tenant credibility engine MVP","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/81"},{"additions":1635,"body":"## Summary\n\n- Added `tenancy/` module with tenant registry, path management, and header-based RBAC\n- Propagated `tenant_id` across all credibility artifacts (claims, drift, snapshots, correlation, sync, packets)\n- Tenant-scoped persistence under `data/credibility/{tenant_id}/`\n- Canonical tenant-scoped API routes: `/api/{tenant_id}/credibility/*`\n- Backward-compatible alias routes: `/api/credibility/*` (serves default tenant)\n- Dashboard supports tenant + role selection in API mode\n- Seeded 3 demo tenants with distinct credibility profiles:\n  - **tenant-alpha**: Stable (CI ~97), low drift, correlation OK\n  - **tenant-bravo**: Entropy (CI ~87), 1 DEGRADED claim, CG-002 REVIEW\n  - **tenant-charlie**: Correlation pressure (CI ~68), 1 UNKNOWN claim, CG-002 CRITICAL\n- Seal requires `coherence_steward` role (HTTP 403 for other roles)\n\n## Verification\n\n- 735 tests pass, 0 regressions\n- Ruff lint clean\n- 14 API routes registered (1 registry + 7 tenant-scoped + 6 alias)\n- Cross-tenant isolation confirmed\n- RBAC enforcement confirmed (seal blocked for exec/dri/truth_owner)\n- Seed data populated for all 3 tenants\n\n## How to Run\n\n```bash\nuvicorn dashboard.api_server:app --reload\n```\n\nDashboard: open `dashboard/credibility-engine-demo/index.html`, set `DATA_MODE = \"API\"` in `app.js`\n\n## Test Seal Authorization\n\n```bash\n# Should succeed (coherence_steward)\ncurl -X POST http://localhost:8000/api/tenant-alpha/credibility/packet/seal \\\n  -H \"X-Role: coherence_steward\" -H \"X-User: demo\"\n\n# Should return 403 (exec)\ncurl -X POST http://localhost:8000/api/tenant-alpha/credibility/packet/seal \\\n  -H \"X-Role: exec\" -H \"X-User: demo\"\n```\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":40,"createdAt":"2026-02-19T18:47:17Z","deletions":161,"labels":[],"mergedAt":"2026-02-19T18:48:09Z","number":80,"title":"feat(v0.8.0): multi-tenant credibility engine MVP","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/80"},{"additions":1655,"body":"## Summary\n\n- Added `credibility_engine/` runtime module  real stateful engine with JSONL persistence, Credibility Index calculation, and sealed packet generation\n- Added 6 FastAPI endpoints under `/api/credibility/*` integrated into the existing dashboard API server\n- Dashboard now supports `DATA_MODE = \"API\"` toggle for live API-driven visualization\n- Simulation runner supports `--mode engine` to drive the runtime engine instead of writing static JSON\n- Version bumped to 0.7.0 across pyproject.toml, core, and CHANGELOG\n\n## Files\n\n### New (9)\n- `credibility_engine/__init__.py`  Module exports\n- `credibility_engine/models.py`  Claim, DriftEvent, CorrelationCluster, SyncRegion, Snapshot\n- `credibility_engine/store.py`  JSONL persistence (append-only, thread-safe)\n- `credibility_engine/index.py`  Credibility Index calculation (5 penalties, 5 bands)\n- `credibility_engine/engine.py`  CredibilityEngine class (state management + dashboard snapshots)\n- `credibility_engine/packet.py`  Credibility Packet generator (DLR/RS/DS/MG + seal)\n- `credibility_engine/api.py`  FastAPI router (6 endpoints)\n- `credibility_engine/README.md`  Stage 3 documentation\n- `data/credibility/.gitkeep`  Persistence directory\n\n### Modified (8)\n- `dashboard/api_server.py`  Integrated credibility router\n- `dashboard/credibility-engine-demo/app.js`  API mode toggle\n- `sim/credibility-engine/runner.py`  `--mode engine` driver\n- `pyproject.toml`  Version 0.7.0 + package discovery\n- `core/__init__.py`  Version 0.7.0\n- `README.md`  Stage 3 section + API endpoint table\n- `NAV.md`  Runtime engine link\n- `CHANGELOG.md`  v0.7.0 entry\n\n## Test plan\n\n- [x] All 735 existing tests pass (0 regressions)\n- [x] Ruff lint clean\n- [x] Module imports verified\n- [x] Engine smoke test: initialize  drift  recalculate  snapshot  persist\n- [x] All 6 API routes registered in server\n- [x] Dashboard MOCK mode unchanged\n- [x] Simulation still runs in json mode\n- [x] Guardrails preserved (abstract institutional modeling only)\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":17,"createdAt":"2026-02-19T18:23:50Z","deletions":21,"labels":[],"mergedAt":"2026-02-19T18:24:57Z","number":79,"title":"feat(v0.7.0): Real Credibility Engine Runtime + API Layer","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/79"},{"additions":2384,"body":"## Summary\n\n- Added simulation harness under `sim/credibility-engine/` with tick-based engine (2-second intervals, 15 sim-min/tick)\n- Implemented 4 scenarios: Day0 (stable, CI 9497), Day1 (entropy, CI 8590), Day2 (coordinated darkness, CI 6575), Day3 (external mismatch + recovery, CI 4560)\n- Dashboard auto-refreshes every 2 seconds for live visualization\n- Generates dynamic credibility packets with DLR/RS/DS/MG narratives and sealed hash chain\n- Supports hot-swap scenario switching via `scenario.json`\n\n## Files\n\n**New (6):** `sim/credibility-engine/`  runner.py, engine.py, models.py, scenarios.py, packet.py, README.md\n\n**Modified (4):** `app.js` (auto-refresh), `README.md` (Stage 2 section), `NAV.md` (sim links), `CHANGELOG.md` (Stage 2 entry)\n\n## Run instructions\n\n```bash\n# Terminal 1: Start simulation\npython sim/credibility-engine/runner.py --scenario day0\n\n# Terminal 2: Serve dashboard\npython -m http.server 8000\n# Visit http://localhost:8000/dashboard/credibility-engine-demo/\n```\n\n## Test plan\n\n- [x] Day0 produces CI 9497 (Stable)\n- [x] Day1 shows correlation REVIEW, CI drops to 8590\n- [x] Day2 produces UNKNOWN claim, CI drops to 6575\n- [x] Day3 produces CRITICAL correlation + replay flags, CI 4560, then recovers\n- [x] All JSON schemas match dashboard expectations\n- [x] 735 tests pass, lint clean\n- [x] No domain modeling present\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":10,"createdAt":"2026-02-19T17:58:02Z","deletions":1,"labels":[],"mergedAt":"2026-02-19T18:02:30Z","number":78,"title":"feat(v0.6.4): add stage 2 simulated credibility engine","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/78"},{"additions":1822,"body":"## Summary\n- Static 7-panel dashboard for Credibility Engine institutional state visualization\n- Vanilla HTML/CSS/JS  no frameworks, professional cockpit theme\n- Mock JSON calibrated to 36,000-node production lattice (consistent with v0.6.4 scale docs)\n\n## Panels\n1. **Credibility Index**  composite 0100 score, trend, 6-component breakdown, interpretation bands\n2. **Tier 0 Claims**  5 claims with status, quorum K/N, margin, TTL, correlation groups, out-of-band\n3. **Drift Activity (24h)**  183 events, severity breakdown, 5 institutional categories, top fingerprints\n4. **Correlation Risk**  6 clusters with coefficients, color-coded thresholds (green/yellow/red)\n5. **TTL Expiration Timeline**  4-hour forecast with tier breakdown, clustering warning, Tier 0 alerts\n6. **Sync Plane Integrity**  3 regions with skew, watermark lag, beacon health, federation status\n7. **Credibility Packet**  generate sealed DLR + RS + DS + MG assessment summary\n\n## Files (11 new, 2 modified)\n- `dashboard/credibility-engine-demo/`  11 files (README, HTML, CSS, JS, 7 JSON)\n- `README.md`  added demo link in Progressive Escalation\n- `CHANGELOG.md`  added demo cockpit entry\n\n## Test plan\n- [x] 735 tests pass, 3 skipped\n- [x] Ruff lint clean\n- [x] All 7 JSON files validate\n- [x] Guardrails maintained (abstract, non-domain)\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":13,"createdAt":"2026-02-19T17:29:45Z","deletions":1,"labels":[],"mergedAt":"2026-02-19T17:31:23Z","number":77,"title":"feat(v0.6.4): Credibility Engine Demo Cockpit","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/77"},{"additions":2066,"body":"## Summary\n- Adds 12 supporting files across 3 lattice examples (scenarios, runbooks, schemas, architecture, economics, diagrams)\n- Adds \"Why Scale Changes Everything\" section to README\n\nFollow-up to PR #75  these files were committed after the merge.\n\n## Test plan\n- [x] 735 tests pass, 3 skipped\n- [x] Ruff lint clean\n- [x] Vocabulary consistency verified\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":13,"createdAt":"2026-02-19T17:20:08Z","deletions":0,"labels":[],"mergedAt":"2026-02-19T17:20:13Z","number":76,"title":"Build 43  Example supporting files + Why Scale Changes Everything","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/76"},{"additions":1454,"body":"## Summary\n\nCompletes v0.6.4 by formalizing Coherence Ops at institutional scale alongside the existing MDPT Beta Kit.\n\n- **Credibility Index**  composite 0100 score from 6 components (tier-weighted integrity, drift penalty, correlation risk, quorum margin, TTL expiration, confirmation bonus). 5 interpretation bands. Operational thresholds and fail-first indicators for 30k40k node lattices.\n- **Core System Design**  evidence node model (11 fields), append-only event model (6 event types), TTL discipline (Tier 03), K-of-N quorum with correlation groups.\n- **Sync Plane**  event time vs ingest time, monotonic sequences, independent beacons, watermarks, replay detection. Minimum: 3 regions, 35 nodes/region, no region >40% authority.\n- **Drift-Patch-Seal loop**  5 institutional drift categories (timing entropy, correlation drift, confidence volatility, TTL compression, external mismatch) mapping to 8 runtime types.\n- **Deployment patterns**  MVP ($1.5M$3M, 68 engineers)  Production ($6M$10M, 30k40k nodes, 3+ regions). Economics: ~$170$280/node/year.\n- **Progressive lattice examples**  Mini (12 nodes), Enterprise (~500), Scale (30k40k). Abstract, non-domain.\n- **Mermaid diagrams**  38 (Lattice Architecture), 39 (Institutional Drift Loop).\n- README elevated with Progressive Escalation section and Credibility Engine section.\n\n## Test plan\n\n- [x] 735 tests pass, 3 skipped, 0 failures\n- [x] `ruff check .` passes clean\n- [x] All 11 new files created and linked\n- [x] README renders with correct markdown tables and links\n- [x] CHANGELOG updated with Credibility Engine additions\n- [x] NAV updated with 11 new resource links\n- [x] Mermaid catalogue updated (diagrams 3739)\n- [ ] Mermaid diagrams render on GitHub\n- [ ] Internal links resolve correctly\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":15,"createdAt":"2026-02-19T16:42:39Z","deletions":3,"labels":[],"mergedAt":"2026-02-19T16:43:29Z","number":75,"title":"v0.6.4  Credibility Engine & Scaled Truth Infrastructure","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/75"},{"additions":2138,"body":"## Summary\n\n- **MDPT Index Generator**  `mdpt/tools/generate_prompt_index.py` converts PromptCapabilities SharePoint CSV exports into schema-validated `prompt_index.json` + `prompt_index_summary.md` with Totals, Expiring Soon, Top Drift, and Top Used rollups\n- **Product CLI**  unified `deepsigma` entrypoint with 5 subcommands: `doctor`, `demo excel`, `validate boot`, `mdpt index`, `golden-path` (preserved)\n- **Power App Starter Kit**  8-screen builder guide + 6 copy-paste PowerFx snippet files for canvas app construction in under 1 hour\n\n## Details\n\n### Commit 1: MDPT Index Generator\n- `mdpt/tools/generate_prompt_index.py`  CSV  filtered/validated/normalized JSON + summary MD\n- `mdpt/templates/prompt_index_schema.json`  Draft-07 schema with nested `links`, `telemetry`, `counts`\n- `tests/fixtures/promptcapabilities_export.csv`  8-row fixture (6 Approved, 2 non-Approved)\n- 22 tests in `tests/test_mdpt_index_generator.py`\n- CI gate: generator run + schema validation\n\n### Commit 2: Product CLI\n- `deepsigma/cli/` package with `main.py` + 5 command modules (doctor, demo_excel, validate_boot, mdpt_index, golden_path)\n- `deepsigma` console script redirected from `tools.golden_path_cli`  `deepsigma.cli.main` (golden-path preserved as subcommand)\n- 7 smoke tests in `tests/test_cli_smoke.py`\n- `docs/CLI.md` reference doc\n\n### Commit 3: Power App Starter Kit + Release\n- `mdpt/powerapps/STARTER_KIT.md`  8-screen builder guide (Catalog  CapabilityDetail  UseCapability  RunHistory  Evaluation  DriftReport  Approvals  Admin)\n- 6 `.pfx` PowerFx snippet files with labeled formulas, no tenant URLs, no secrets\n- `mermaid/37-mdpt-beta-kit.md`  canonical lifecycle diagram (Index  Catalog  Use  Log  Drift  Patch), reused in README.md and mdpt/README.md\n- Version bump 0.6.3  0.6.4 across pyproject.toml, core/__init__.py, CHANGELOG, NAV, README\n\n## Test plan\n\n- [x] 735 tests pass, 3 skipped, 0 failures\n- [x] `deepsigma doctor`  12/12 checks PASS (HEALTHY)\n- [x] `deepsigma demo excel`  produces 5 artifacts, before 76.9  after 84.9\n- [x] `deepsigma validate boot <xlsx>`  PASS on CDS template\n- [x] `deepsigma mdpt index --csv <csv>`  6 capabilities indexed, schema-valid JSON\n- [ ] CI pipeline runs green on this branch\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":34,"createdAt":"2026-02-19T16:03:46Z","deletions":4,"labels":[],"mergedAt":"2026-02-19T16:11:15Z","number":74,"title":"v0.6.4  MDPT Beta Kit (Index Generator + Product CLI + Power App Starter Kit)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/74"},{"additions":1787,"body":"## Summary\n\n- **BOOT Contract Gate**  `tools/validate_workbook_boot.py` enforces 5 required metadata keys in BOOT!A1 + 7 named tables; wired into CI as a blocking gate\n- **Excel-first Money Demo**  deterministic one-command pipeline (`python -m demos.excel_first`) producing workbook  run record  drift signal  patch stub  coherence delta (no LLM, no network)\n- **MDPT Power App Pack**  6 implementation-ready docs: 3 SharePoint list build sheets (PromptCapabilities, PromptRuns, DriftPatches), Power Automate flow recipes (4 flows), Power Apps screen map (5 screens), and governance mapping\n\n## Details\n\n### Commit 1: BOOT Contract Validator\n- New `tools/validate_workbook_boot.py`  CLI validator (exit 0/1) checking BOOT sheet, metadata keys, named tables\n- Updated `BOOT_TEXT` in generator with `BOOT! METADATA` prefix block (version, ttl_hours_default, risk_lane_default, schema_ref, owner)\n- 4 test fixture workbooks + 10 tests in `tests/test_workbook_boot_validator.py`\n- CI updated: `pip install -e \".[dev,excel]\"` + BOOT validation step\n\n### Commit 2: Excel-first Money Demo\n- `demos/excel_first/` module with argparse CLI and deterministic 6-step pipeline\n- Outputs: `workbook.xlsx`, `run_record.json`, `drift_signal.json`, `patch_stub.json`, `coherence_delta.txt`\n- 17 tests in `tests/test_excel_first_money_demo.py`\n- `excel-demo` console entry point in pyproject.toml\n\n### Commit 3: MDPT Build Sheets + Version Bump\n- 3 SharePoint list build sheets with full column schemas, Mermaid ER/state diagrams, default views, SLA targets\n- Power Automate flow recipes: drift alert, patch approval, weekly digest, workbook refresh validator\n- Power Apps screen map: Home dashboard, Prompt Gallery, Run Detail, Drift Board, Patch Queue\n- Governance doc: Coherence Ops mapping, 3-tier permissions, audit trail, compliance, escalation path\n- Version bump 0.6.2  0.6.3 across pyproject.toml, __init__.py, CHANGELOG.md\n\n## Test plan\n\n- [x] 674 tests pass, 26 skipped, 0 failures\n- [x] BOOT validator passes on regenerated template workbook\n- [x] Money Demo produces all 5 expected artifacts with correct structure\n- [x] `after_score > before_score` in coherence delta (DriftPatch proof)\n- [ ] CI pipeline runs green on this branch\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":28,"createdAt":"2026-02-19T15:12:50Z","deletions":5,"labels":[],"mergedAt":"2026-02-19T15:14:40Z","number":73,"title":"v0.6.3  Excel-first BOOT Contract Gate + Money Demo + MDPT Power App Pack","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/73"},{"additions":1382,"body":"## Summary\n- Introduces the **Coherence Ops Interoperability Stack**  a unified architecture for AG-UI, A2A, MCP, and Agora protocol integration\n- Defines the **Interop Gateway Spec v0.1** with protocol adapters, Agora-style negotiation engine, sealed contract lifecycle, runtime execution, drift detection, and security controls\n- Includes **ProtocolContract JSON Schema** (Draft-07) with full sealing/versioning/provenance, plus a realistic AgentBooking  AgentTravel example\n- Adds **drift trigger playbook** (10 trigger types with detection signals, severity, and response actions) and a **14-day MVP implementation plan**\n- Two new Mermaid diagrams: interop request flow sequence + Agora negotiation flowchart\n\n## New files (8)\n- `docs/interop/README.md`  One-stack overview\n- `docs/interop/COHERENCE_INTEROP_GATEWAY_SPEC_v0.1.md`  Full gateway spec\n- `docs/interop/DRIFT_TRIGGERS.md`  Drift detection table\n- `docs/interop/MVP_PLAN.md`  2-week implementation plan\n- `schemas/interop/protocol_contract.schema.json`  ProtocolContract schema\n- `templates/interop/ProtocolContract.example.json`  Example contract\n- `mermaid/30-interop-request-flow.md`  Sequence diagram\n- `mermaid/31-agora-negotiation-flow.md`  Negotiation flowchart\n\n## Modified (1)\n- `NAV.md`  Added Interoperability section + diagram entries\n\n## Test plan\n- [x] `ruff check .`  lint clean\n- [x] JSON schema + example parse valid\n- [x] `pytest tests/ -q`  678 passed, 3 skipped (1 pre-existing golden-file mismatch)\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":11,"createdAt":"2026-02-19T13:54:00Z","deletions":3,"labels":[],"mergedAt":"2026-02-19T13:59:37Z","number":72,"title":"Add Interop Gateway spec for v0.6.1","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/72"},{"additions":665,"body":"## Summary\n- **Normative spec** (`specs/trust_scorecard_v1.md`) defining metrics, SLO thresholds, and JSON output format\n- **Generator tool** (`tools/trust_scorecard.py`) reads Golden Path output  `trust_scorecard.json` with metrics + SLO checks\n- **Dashboard panel** (`TrustScorecardPanel.tsx`) with score cards, SLO badges, timing/quality metrics\n- **API endpoint** (`GET /api/trust_scorecard`) serving scorecard JSON\n- **CI integration**  connector contract tests + scorecard generation steps in `ci.yml`\n- **18 tests** covering metrics, SLOs, CLI, grades, coverage passthrough\n\nStacks on PR #70 (Fixture Library)  PR #69 (Connector Contract v1.0).\n\n## Test plan\n- [x] `pytest tests/test_trust_scorecard.py -v`  18/18 pass\n- [x] `pytest tests/ -q`  679 passed, 0 failures\n- [x] `ruff check`  lint clean\n- [ ] Verify Trust Scorecard tab renders in dashboard\n- [ ] CI green on push\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":9,"createdAt":"2026-02-18T20:24:16Z","deletions":6,"labels":[],"mergedAt":"2026-02-19T13:56:27Z","number":71,"title":"v0.6.0 PR #3  Trust Scorecard","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/71"},{"additions":883,"body":"## Summary\n- Introduces `ConnectorV1` protocol + `RecordEnvelope` dataclass as the standard interface all source connectors must satisfy\n- Adds `specs/connector_envelope.schema.json`  JSON schema for the canonical record envelope (provenance, hashes, ACL tags, raw data)\n- Adds `specs/connector_contract_v1.md`  normative spec covering interface, pagination, retry/backoff, rate limits, error model, auth handling\n- All 4 connectors (SharePoint, Dataverse, AskSage, Snowflake) gain `source_name` attribute + `to_envelopes()` method  **additive, zero behavior change** to existing code\n- 30 new tests validate schema compliance, hash stability, and envelope round-trips for all connectors\n\n## File Tree\n```\nNEW:\n  connectors/__init__.py\n  connectors/contract.py           Protocol + RecordEnvelope + validate/normalize/bridge\n  specs/connector_envelope.schema.json\n  specs/connector_contract_v1.md\n  tests/test_connector_contract_v1.py\n\nMODIFIED (additive):\n  adapters/sharepoint/connector.py       +source_name, +to_envelopes()\n  adapters/powerplatform/connector.py    +source_name, +to_envelopes()\n  adapters/asksage/connector.py          +source_name, +to_envelopes()\n  adapters/snowflake/warehouse.py        +source_name, +to_envelopes()\n  pyproject.toml                         +connectors* to package find\n  NAV.md                                 Connector Contract links\n  README.md                              \"Connectors are contract-driven\" note\n```\n\n## Test plan\n- [x] 30 new tests in `test_connector_contract_v1.py` pass\n- [x] 33 existing golden path tests still pass\n- [x] Lint clean (ruff)\n- [ ] CI matrix (Python 3.10/3.11/3.12) passes\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":12,"createdAt":"2026-02-18T20:13:34Z","deletions":2,"labels":[],"mergedAt":"2026-02-18T20:25:57Z","number":69,"title":"v0.6.0 Connector Contract v1.0  standardized interface + canonical envelope","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/69"},{"additions":219,"body":"## Summary\n\n- **Part A  CLI entrypoint**: New `deepsigma golden-path` command (`tools/golden_path_cli.py`) with `--clean`, `--verbose`, `--json` flags. Wired as `deepsigma` in pyproject.toml scripts. Step-by-step PASS/FAIL output, non-zero exit on failure.\n- **Part B  CI gate**: Golden Path fixture run added to `ci.yml`  runs `python -m demos.golden_path` + `pytest tests/test_golden_path.py` on every PR/push. Deterministic, <1s.\n- **Part C  Docker profile**: `golden-path` profile in docker-compose.yml. `Dockerfile.tools` and `Dockerfile.coherence` updated to COPY `demos/`. Run: `docker compose --profile golden-path run --rm golden-path`\n- **Part D  Docs**: Golden Path section in README.md, `deepsigma golden-path` in CLI quick reference, NAV.md updated with demos/golden_path entries.\n- **Part E  Polish**: `expected_summary.json` fixture snapshot + `test_matches_expected_summary` assertion (33 golden path tests total).\n\n## File tree\n\n```\nNEW:\n  tools/golden_path_cli.py                                     deepsigma CLI entrypoint\n  demos/golden_path/fixtures/sharepoint_small/expected_summary.json   golden snapshot\n\nMODIFIED:\n  .github/workflows/ci.yml         Golden Path fixture gate step\n  Dockerfile.coherence              COPY demos/, updated header\n  Dockerfile.tools                  COPY demos/, deepsigma command, updated header\n  docker-compose.yml                golden-path profile service\n  pyproject.toml                    deepsigma entrypoint\n  README.md                         Golden Path section + CLI reference\n  NAV.md                            Golden Path links\n  tests/test_golden_path.py         expected_summary snapshot test\n```\n\n## Verification\n\n| # | Check | Status |\n|---|-------|--------|\n| 1 | `deepsigma golden-path sharepoint --fixture ... --clean` | 7/7 PASS |\n| 2 | `deepsigma golden-path sharepoint --fixture ... --json` | Valid JSON |\n| 3 | `pytest tests/test_golden_path.py -v` | 33 passed |\n| 4 | `pytest tests/ -q` | 607 passed, 3 skipped |\n| 5 | `ruff check .` | Clean |\n\n## Test plan\n\n- [ ] CI passes (all jobs green)\n- [ ] `deepsigma golden-path sharepoint --fixture demos/golden_path/fixtures/sharepoint_small --clean` prints PASS for all 7 steps\n- [ ] Docker build: `docker compose --profile golden-path build`\n- [ ] Docker run: `docker compose --profile golden-path run --rm golden-path`\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":10,"createdAt":"2026-02-18T19:50:42Z","deletions":2,"labels":[],"mergedAt":"2026-02-18T19:54:42Z","number":68,"title":"v0.5.1 Golden Path  CLI, CI gate, Docker profile","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/68"},{"additions":4,"body":"## Summary\n- `stain/jena-fuseki:5.0.0` ships TDB1 tools at `/jena-fuseki/`, not TDB2 at `/jena/bin/`\n- Changed `Dockerfile.rdf` to use `/jena-fuseki/tdbloader` (TDB1 loader that actually exists)\n- Updated Fuseki dataset config from `tdb2:DatasetTDB2` to `tdb:DatasetTDB` to match\n- Fixes the `Docker  RDF/SPARQL` CI failure (`/jena/bin/tdb2.tdbloader: not found`, exit 127)\n\n## Test plan\n- [x] CI Docker build should pass on this PR\n- [ ] Verify SPARQL endpoint responds after container starts\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-18T16:09:36Z","deletions":5,"labels":[],"mergedAt":"2026-02-18T16:11:43Z","number":67,"title":"Fix Docker RDF: use correct tdbloader path","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/67"},{"additions":4,"body":"## Summary\n- Moved `import sys` to the top of `adapters/otel/sidecar.py` with other stdlib imports\n- Placed `logging.basicConfig()` after the `sys.path` manipulation block\n- Fixes the E402 (module-level import not at top of file) that is failing the lint job on main\n\n## Test plan\n- [x] `ruff check . --select E,F,W --ignore E501` passes clean locally\n- [x] All 287 tests pass\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-18T16:04:19Z","deletions":4,"labels":[],"mergedAt":"2026-02-18T16:06:03Z","number":66,"title":"Fix CI: ruff E402 in otel sidecar","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/66"},{"additions":71,"body":"## Summary\n\nAdds a validation CI workflow that runs on every change to `llm_data_model/`. Catches broken examples and malformed JSON before merge.\n\n## What it checks\n\n1. **`validate_examples.py`**  existing structural validator for all `03_examples/*.json` against canonical envelope rules\n2. **Schema JSON**  all `02_schema/jsonschema/*.json` files parse as valid JSON\n3. **Example JSON**  all `03_examples/*.json` files parse as valid JSON\n\n## Trigger\n\n- Push to `main` touching `llm_data_model/**`\n- Any PR touching `llm_data_model/**`\n- Manual dispatch\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-18T15:30:26Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T15:30:57Z","number":65,"title":"CI: LLM Data Model validation workflow","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/65"},{"additions":84,"body":"## Summary\n\nAdds a publish workflow for the `langchain-deepsigma` package (`packages/langchain-deepsigma/`). Uses OIDC trusted publishing  no long-lived API token required.\n\n## How to release\n\n```bash\ngit tag langchain-v0.2.0\ngit push origin langchain-v0.2.0\n#  triggers test (3.10/3.11/3.12)  build  publish to PyPI\n```\n\n**TestPyPI dry run:**\nRun the workflow manually from Actions UI with `test_pypi = true`.\n\n## Workflow\n\n1. **test**  `pytest tests/` on Python 3.10, 3.11, 3.12 from `packages/langchain-deepsigma/`\n2. **build-and-publish**  `python -m build`  `pypa/gh-action-pypi-publish` (OIDC)\n\n**Tag pattern:** `langchain-v*` (e.g. `langchain-v0.1.0`, `langchain-v0.2.0`)\n\n**Setup needed:** Add `langchain-deepsigma` as a trusted publisher in PyPI project settings pointing to this repo + `publish-langchain.yml` workflow.\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-18T15:29:36Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T15:30:54Z","number":64,"title":"CI: langchain-deepsigma PyPI publish workflow","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/64"},{"additions":138,"body":"## Summary\n\nAdds `Dockerfile.rdf`  an Apache Jena Fuseki container with all DeepSigma ontology TTL files pre-loaded into a TDB2 dataset at build time.\n\n## Usage\n\n```bash\ndocker run -p 3030:3030 ghcr.io/8ryanwh1t3/deepsigma-rdf\n```\n\n**Endpoints:**\n- SPARQL query: `http://localhost:3030/deepsigma/sparql`\n- SPARQL update: `http://localhost:3030/deepsigma/update`\n- Graph store: `http://localhost:3030/deepsigma/data`\n- Admin UI: `http://localhost:3030`\n\n**Example query:**\n```bash\ncurl -X POST http://localhost:3030/deepsigma/sparql \\\n  -H \"Content-Type: application/sparql-query\" \\\n  -H \"Accept: application/json\" \\\n  -d \"PREFIX co: <https://deepsigma.ai/coherence-ops#>\n      SELECT ?class WHERE { ?class a owl:Class } LIMIT 20\"\n```\n\n## TTL files loaded\n\n- `rdf/coherence-ops-ontology.ttl`  main ontology\n- `rdf/namespaces.ttl`  namespace declarations\n- `rdf/ontology/claim_primitive.ttl`  claim primitive ontology\n- `rdf/ontology/coherence_ops_core.ttl`  core types\n- `rdf/ontology/coherence_ops_extended.ttl`  extended vocabulary\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-18T15:28:40Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T15:30:50Z","number":63,"title":"RDF/SPARQL: Fuseki container pre-loaded with DeepSigma ontology","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/63"},{"additions":139,"body":"## Summary\n\nReplaces the `OverwatchClient` placeholder stub with a real HTTP client. Uses stdlib `urllib` only  no extra dependencies.\n\n## Usage\n\n```python\nfrom adapters.openclaw.overwatch_openclaw_adapter import OverwatchClient, SkillRun, run_skill_with_overwatch\n\n# Auto-reads OVERWATCH_BASE_URL from env (default: http://localhost:8000)\nclient = OverwatchClient()\n\n# Check connectivity\nclient.health()\n\n# Full skill lifecycle\nresult = run_skill_with_overwatch(\n    SkillRun(skill_name=\"AccountQuarantine\", payload={\"accountId\": \"acct-123\"}, actor_id=\"agent-1\"),\n    client,\n)\n#  {\"session_id\": \"...\", \"verification\": {...}, \"seal\": {...}, \"status\": \"sealed\"}\n```\n\n## API mapping\n\n| Method | Endpoint |\n|--------|---------|\n| `submit_task()` | `POST /api/episodes` |\n| `execute_tool()` | `POST /api/episodes/{id}/tool_calls` |\n| `dispatch_action()` | `POST /api/episodes/{id}/actions` |\n| `verify()` | `POST /api/episodes/{id}/verify` |\n| `seal()` | `POST /api/episodes/{id}/seal` |\n| `health()` | `GET /api/health` |\n\n## Configuration\n\n```bash\nexport OVERWATCH_BASE_URL=http://overwatch-dashboard:8000\nexport OVERWATCH_TIMEOUT=30\n```\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-18T15:27:29Z","deletions":25,"labels":[],"mergedAt":"2026-02-18T15:30:47Z","number":62,"title":"OpenClaw: implement OverwatchClient HTTP client","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/62"},{"additions":264,"body":"## Summary\n\n- Upgrades `adapters/otel/exporter.py` to support real OTLP export (gRPC and HTTP)\n- Adds `adapters/otel/sidecar.py`  a standalone poll-loop that watches a data directory and ships episodes/drift to any OTLP collector\n- Adds `Dockerfile.otel` and CI workflow for `ghcr.io/8ryanwh1t3/deepsigma-otel`\n\n## Usage\n\n```bash\n# Point at a local Grafana/Tempo/Jaeger collector\ndocker run \\\n  -e OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317 \\\n  -v ./data:/app/data \\\n  ghcr.io/8ryanwh1t3/deepsigma-otel\n\n# Console mode (no collector)\ndocker run -v ./data:/app/data ghcr.io/8ryanwh1t3/deepsigma-otel\n\n# Build with HTTP transport instead of gRPC\ndocker build -f Dockerfile.otel --build-arg INSTALL_OTLP=http .\n```\n\n**Sidecar pattern:** drop JSON episode/drift files in `./data/episodes/` or `./data/drift/`  sidecar polls every 5s, exports spans, moves files to `./data/exported/`.\n\n## Exporter selection\n\n| Condition | Exporter |\n|-----------|---------|\n| `OTEL_EXPORTER_OTLP_ENDPOINT` set, `:4317` | OTLP gRPC (BatchSpanProcessor) |\n| `OTEL_EXPORTER_OTLP_ENDPOINT` set, `:4318` or `/v1/traces` | OTLP HTTP (BatchSpanProcessor) |\n| No endpoint | Console (SimpleSpanProcessor) |\n| OTLP packages not installed | Console fallback with warning |\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":4,"createdAt":"2026-02-18T15:24:02Z","deletions":8,"labels":[],"mergedAt":"2026-02-18T15:30:44Z","number":61,"title":"OTel: add OTLP export + deepsigma-otel sidecar container","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/61"},{"additions":119,"body":"## Summary\n\nAdds `Dockerfile.mcp` and CI workflow for `ghcr.io/8ryanwh1t3/deepsigma-mcp`  a containerized MCP server that speaks JSON-RPC over stdin/stdout, matching the standard MCP subprocess pattern.\n\n## Usage\n\n**Claude Desktop** (`~/.claude/claude_desktop_config.json`):\n```json\n{\n  \"mcpServers\": {\n    \"deepsigma\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"--rm\", \"-i\",\n               \"-v\", \"/path/to/data:/app/data\",\n               \"ghcr.io/8ryanwh1t3/deepsigma-mcp\"]\n    }\n  }\n}\n```\n\n**Direct pipe:**\n```bash\necho '{\"jsonrpc\":\"2.0\",\"method\":\"tools/list\",\"id\":1}' | \\\n  docker run --rm -i ghcr.io/8ryanwh1t3/deepsigma-mcp\n```\n\n**Available MCP tools:** `submit_task`, `tool_execute`, `action_dispatch`, `verify_run`, `episode_seal`, `drift_emit`\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `Dockerfile.mcp` | `python:3.12-slim`, runs `mcp_server_scaffold.py` via stdin/stdout |\n| `.github/workflows/docker-mcp.yml` | Publishes `ghcr.io/8ryanwh1t3/deepsigma-mcp` on MCP adapter changes |\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-18T15:21:21Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T15:30:40Z","number":60,"title":"Container: deepsigma-mcp  JSON-RPC stdio MCP server","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/60"},{"additions":146,"body":"## Summary\n\nAdds `Dockerfile.tools` and CI workflow for `ghcr.io/8ryanwh1t3/deepsigma-tools`  a batch worker with all three supervisor CLI tools bundled.\n\n## Usage\n\n```bash\n# Run a supervised decision episode\ndocker run --rm -v ./data:/data -v ./policy_packs:/app/policy_packs:ro \\\n  ghcr.io/8ryanwh1t3/deepsigma-tools \\\n  overwatch --decisionType AccountQuarantine \\\n  --policy /app/policy_packs/packs/demo_policy_pack_v1.json --out /data\n\n# Validate examples against schemas\ndocker run --rm ghcr.io/8ryanwh1t3/deepsigma-tools overwatch-validate\n\n# Replay a sealed episode\ndocker run --rm -v ./data:/data \\\n  ghcr.io/8ryanwh1t3/deepsigma-tools \\\n  overwatch-replay --episode /data/ep_001.json\n\n# Via compose (profile: cli)\ndocker compose --profile cli run tools overwatch-validate\n```\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `Dockerfile.tools` | `python:3.12-slim`, all three CLI entry points, `/data` mount |\n| `.github/workflows/docker-tools.yml` | Publishes `ghcr.io/8ryanwh1t3/deepsigma-tools` |\n| `docker-compose.yml` | Added `tools` service under `profiles: [cli]` |\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-18T15:20:05Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T15:30:37Z","number":59,"title":"Container: deepsigma-tools  overwatch/validate/replay CLI worker image","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/59"},{"additions":70,"body":"## Summary\n\n- Rewrites `docker-compose.yml` to fix a progressive indentation bug and add two new services\n- Updates `docker-publish.yml` to include `Dockerfile.coherence` and `Dockerfile.exhaust` in path triggers\n\n## docker-compose.yml changes\n\n**Bug fixed:** Every line after the first service key was indented 2 spaces deeper than the one before  invalid in strict YAML parsers.\n\n**New services:**\n\n| Service | Image | Port | Notes |\n|---------|-------|------|-------|\n| `overwatch` | `deepsigma-dashboard:local` | 3000 | Unchanged |\n| `exhaust` | `deepsigma-exhaust:local` | 8001 | Starts with `docker compose up` |\n| `coherence` | `deepsigma-coherence:local` |  | `profiles: [cli]`  run-and-exit only |\n\n**coherence profile usage:**\n```bash\ndocker compose --profile cli run coherence score /data/episodes.json --json\ndocker compose --profile cli run coherence audit /data/\ndocker compose --profile cli run coherence iris query /data/ --type STATUS\n```\n\n## Test plan\n\n- [x] `docker compose config --quiet` validates YAML without errors\n- [x] `docker compose up overwatch`  dashboard unchanged on :3000\n- [x] `docker compose up exhaust`  exhaust service starts on :8001\n- [x] `docker compose --profile cli run coherence --help`  coherence CLI responds\n- [x] `docker-publish.yml` path triggers include new Dockerfiles\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-18T15:11:46Z","deletions":23,"labels":[],"mergedAt":"2026-02-18T15:12:03Z","number":58,"title":"docker-compose: fix indentation bug, add exhaust + coherence services","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/58"},{"additions":171,"body":"## Summary\n\nAdds a standalone FastAPI container for the Exhaust Inbox  runs independently of the dashboard with full LLM extraction support.\n\n## Usage\n\n```bash\n# Base image (rule-based extraction)\ndocker run -p 8001:8001 \\\n  -v ./data:/app/data \\\n  ghcr.io/8ryanwh1t3/deepsigma-exhaust\n\n# With LLM extraction (runtime opt-in)\ndocker run -p 8001:8001 \\\n  -e EXHAUST_USE_LLM=1 \\\n  -e ANTHROPIC_API_KEY=sk-ant-... \\\n  -v ./data:/app/data \\\n  ghcr.io/8ryanwh1t3/deepsigma-exhaust\n\n# Build with Anthropic baked in\ndocker build -f Dockerfile.exhaust --build-arg INSTALL_LLM=1 -t deepsigma-exhaust:llm .\n```\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `dashboard/server/exhaust_main.py` | Thin FastAPI app mounting existing `exhaust_api` router at `/api/exhaust` |\n| `Dockerfile.exhaust` | `python:3.12-slim`  port 8001, `ARG INSTALL_LLM`, stdlib healthcheck |\n| `.github/workflows/docker-exhaust.yml` | Publishes `ghcr.io/8ryanwh1t3/deepsigma-exhaust` on exhaust file changes |\n\n## Test plan\n\n- [x] `docker build -f Dockerfile.exhaust -t deepsigma-exhaust:test .`\n- [x] `curl http://localhost:8001/healthz`  `{\"status\":\"ok\",\"service\":\"exhaust\"}`\n- [x] `curl http://localhost:8001/api/exhaust/health`  exhaust router responds\n- [x] `docker build --build-arg INSTALL_LLM=1`  anthropic present in image\n- [x] No changes to `exhaust_api.py` or `dashboard/server/api.py`\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-18T15:10:33Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T15:12:00Z","number":57,"title":"Container: deepsigma-exhaust  standalone Exhaust Inbox API service","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/57"},{"additions":114,"body":"## Summary\n\nAdds `Dockerfile.coherence` and a matching CI workflow to publish `ghcr.io/8ryanwh1t3/deepsigma-coherence`  a minimal run-and-exit CLI worker for batch governance operations.\n\n## Usage\n\n```bash\n# Score episodes\ndocker run --rm -v ./data:/data \\\n  ghcr.io/8ryanwh1t3/deepsigma-coherence \\\n  score /data/episodes.json --json\n\n# Full audit\ndocker run --rm -v ./data:/data \\\n  ghcr.io/8ryanwh1t3/deepsigma-coherence \\\n  audit /data/\n\n# IRIS query\ndocker run --rm -v ./data:/data \\\n  ghcr.io/8ryanwh1t3/deepsigma-coherence \\\n  iris query /data/ --type STATUS --json\n```\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `Dockerfile.coherence` | `python:3.12-slim`  no nginx/supervisord; `ENTRYPOINT [\"coherence\"]` |\n| `.github/workflows/docker-coherence.yml` | Publishes to GHCR on push to `core/**`, `engine/**`, `Dockerfile.coherence` |\n\n## Test plan\n\n- [x] `docker build -f Dockerfile.coherence -t deepsigma-coherence:test .`\n- [x] `docker run --rm deepsigma-coherence:test --help`  prints coherence CLI help\n- [x] CI workflow YAML is valid\n- [x] Image name, tag strategy, and cache config match existing `docker-publish.yml`\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-18T15:09:12Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T15:11:56Z","number":56,"title":"Container: deepsigma-coherence  CLI worker image for batch governance","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/56"},{"additions":37,"body":"## Summary\n\n- Adds `.github/workflows/wiki-sync.yml`\n- Triggers on any push to `main` that touches `wiki/**`\n- Clones `<repo>.wiki.git`, copies all `wiki/*.md` files, commits + pushes only when there's a diff\n- Uses `GITHUB_TOKEN`  no additional secrets or PATs needed\n\n## How it works\n\n```\npush to main (wiki/** changed)\n   checkout main repo\n   clone wiki repo via GITHUB_TOKEN\n   cp wiki/*.md  wiki repo\n   git diff --cached: if changes exist  commit + push\n```\n\n## Test plan\n\n- [x] Workflow file is valid YAML\n- [x] `paths: wiki/**` filter prevents triggering on unrelated commits\n- [x] No-op if no diff (idempotent)\n- [ ] Verify first run pushes successfully after merge\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-18T15:00:36Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T15:00:50Z","number":55,"title":"CI: auto-sync wiki/ to GitHub wiki on merge","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/55"},{"additions":109,"body":"## Summary\n\n- `Home.md` rewritten from an 18-line stub to a full sectioned reference page\n- `_Sidebar.md` gains an Exhaust Inbox section (it was missing entirely)\n\n## Home.md sections\n\n| Section | Pages covered |\n|---------|--------------|\n| Start Here | Quickstart, Concepts, Architecture, FAQ |\n| Core Runtime | Contracts, DTE Schema, Action Contract Schema, Degrade Ladder, Verifiers, Sealing, Runtime Flow, Policy Packs |\n| Drift & Governance | DriftPatch, Drift Schema, Coherence Ops, IRIS, Claims, Canon, Retcon, LLM Data Model |\n| Exhaust Inbox | Exhaust-Inbox with adapter/API/LLM extraction summary |\n| Schemas | All 8 schema pages |\n| Integrations | MCP, LangChain, Palantir, Power Platform, OpenTelemetry |\n| Operations | Operations, SLOs, Replay, Security |\n| Reference | Glossary, Roadmap, Contributing |\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-18T14:54:26Z","deletions":12,"labels":[],"mergedAt":"2026-02-18T14:54:35Z","number":54,"title":"Wiki: expand Home.md to full navigation hub, add Exhaust Inbox to sidebar","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/54"},{"additions":405,"body":"## Summary\n\n- 4 new diagram files covering the full Exhaust Inbox architecture shipped in Build 29 (PRs #4446)\n- 13 total diagrams: pipeline, connector map, API surface, and LLM extraction internals\n\n## Files\n\n| File | Diagrams | Coverage |\n|------|----------|----------|\n| `29-exhaust-inbox-pipeline.md` | 3 | Adapter  refine  coherence ops; bucket routing; episode state machine |\n| `29-exhaust-connector-map.md` | 3 | LangChain / Anthropic / Azure normalisation paths; latency_ms + model enrichment |\n| `29-exhaust-api-surface.md` | 3 | All 10 REST endpoints; refinecommit sequence; HTTP status codes |\n| `29-llm-extraction-flow.md` | 4 | LLMExtractor internals; API call sequence; confidence clamping; system prompt |\n\n## Test plan\n\n- [x] All `.md` files contain valid mermaid fences\n- [x] Diagram types used: `graph TB/LR/TD`, `flowchart TD/LR`, `stateDiagram-v2`, `sequenceDiagram`\n- [x] Cross-referenced in `wiki/Exhaust-Inbox.md` (added in PR #48)\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":4,"createdAt":"2026-02-18T14:50:03Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T14:50:12Z","number":53,"title":"Mermaid: Exhaust Inbox Build 29 coverage (4 files, 13 diagrams)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/53"},{"additions":640,"body":"## Summary\n\n- 52 tests across 10 test classes covering the fully-wired IRIS engine (shipped in #50)\n- All resolvers verified end-to-end with mocked MG, DLR, RS, DS artifacts\n- Confidence weight accumulation, threshold boundaries, and 1.0 cap tested explicitly\n- Provenance chain artifact links and roles verified per query type\n- SLA warning path exercised via `_elapsed` patch; config validation for negative values\n- CLI integration tests covering `--json` flag, missing `--target` guard, and argparse exit codes\n\n## Test plan\n\n- [x] `TestResolveWhy` (6)  MG + DLR + RS wiring, confidence, provenance\n- [x] `TestResolveWhatChanged` (6)  DLR outcome distribution, MG patches, DS drift summary\n- [x] `TestResolveWhatDrifted` (5)  DS primary, MG resolution ratio, empty DS\n- [x] `TestResolveRecall` (4)  full episode walk, DLR + RS augmentation\n- [x] `TestResolveStatus` (5)  CoherenceScorer integration, DS headline, MG stats\n- [x] `TestConfidenceScoring` (6)  per-artifact weights, cap at 1.0, PARTIAL/RESOLVED thresholds\n- [x] `TestProvenanceChain` (5)  artifact link roles, DS link in WHAT_DRIFTED\n- [x] `TestConfigAndSLA` (6)  config validation, SLA warning via `_elapsed` patch\n- [x] `TestResponseFormat` (5)  query_id format, serialisation, elapsed_ms, confidence clamp\n- [x] `TestCLI` (4)  status query, WHY target guard, `--json` flag, argparse exit code 2\n\nRun: `pytest tests/test_iris.py -v`  52 passed\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-18T14:46:54Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T14:47:02Z","number":52,"title":"IRIS test suite: 52 tests covering all resolvers, confidence, provenance, SLA, and CLI","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/52"},{"additions":419,"body":"## Summary\n\n- **CLI syntax error fixed**  `core/cli.py` line 215: missing `)` closing `IRISQuery(` prevented the CLI from running at all; also wires `dlr_entries`, `rs`, and `ds` to the engine\n- **`rs` and `ds` wired to engine**  `IRISEngine.__init__` now accepts `rs: ReflectionSession` and `ds: DriftSignalCollector`; both were built in `_build_pipeline()` but never passed to the engine\n- **Confidence scoring implemented**  additive model capped at 1.0; each artifact contributes per-query-type weights; maps to `RESOLVED` (0.5) / `PARTIAL` (>0 <0.5) / `NOT_FOUND` (0.0); `IRISResponse` now carries `confidence` field\n- **WHY resolver**  adds DLR policy context (+0.35: decision_type, outcome_code, degrade_step, policy_stamp) and RS reflection context (+0.15); full provenance chain with MG/DLR/RS links\n- **WHAT_CHANGED resolver**  adds DLR outcome distribution + degraded episodes + policy stamp gap analysis (+0.45) and DS drift summary (+0.20); was MG-patches-only before\n- **WHAT_DRIFTED resolver**  replaces MG-only stub with DS `summarise()` as primary (+0.60: severity breakdown, fingerprint buckets, recurring patterns) and MG resolution ratio (+0.40)\n- **RECALL resolver**  replaces `mg.query(\"stats\")` with full episode graph walk (why + drift + patches + claims +0.50); adds DLR +0.30, RS +0.20\n- **STATUS resolver**  replaces manual health heuristic with `CoherenceScorer.score()` +0.70; adds DS drift headline +0.15, MG stats +0.15\n\n## Test plan\n\n- [ ] `python -m py_compile core/iris.py core/cli.py`  passes\n- [ ] `python -m core.cli iris query --type STATUS ./specs/sample_episode_events.jsonl`  runs without syntax error\n- [ ] WHY with valid episode_id returns `dlr_entry` in data and confidence > 0\n- [ ] WHAT_DRIFTED returns `by_severity`, `top_buckets`, `resolution_ratio`\n- [ ] STATUS returns `overall_score`, `grade`, `dimensions[]`\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":2,"createdAt":"2026-02-18T14:35:26Z","deletions":81,"labels":[],"mergedAt":"2026-02-18T14:45:35Z","number":50,"title":"IRIS: wire all 4 artifacts, fix resolvers, fix CLI syntax","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/50"},{"additions":375,"body":"## Summary\n\n**Formatting fixes (3 files)**\n- `IRIS.md`  ~120 lines of broken `- - - -` indentation chains repaired in Response Format, Provenance Chain, Design Principles, and Glossary Terms sections; all content preserved at correct depth\n- `Canon.md`  Related Pages section: `- - [Page]` nested bullets  flat `- [Page]` list\n- `Retcon.md`  Graph Integrity: duplicate numbering (`2. 2.`, `3. 3.` etc.)  clean `1.5.` list; Related Pages: same nested-bullet fix\n\n**Stub expansions (3 files)**\n- `Verifiers.md` (151  ~1.2KB)  defines what a verifier is, documents `pass`/`fail`/`inconclusive` outcomes, explains both included scaffolds (`read_after_write`, `invariant_check`) in detail, adds custom verifier implementation guide with code example\n- `Degrade-Ladder.md` (358  ~1.3KB)  documents all 6 rungs with behaviour and when-to-use guidance, trigger table per stage, configuration JSON example, episode stamping behaviour\n- `Contracts.md` (411  ~1.5KB)  expands all 4 contract types with key fields and schema links, adds ASCII interaction diagram, fixes Schemas.md link\n\n## Test plan\n\n- [ ] IRIS.md renders cleanly with no indentation artifacts in Response Format / Design Principles / Glossary Terms\n- [ ] Canon.md Related Pages: 5 flat bullet links render correctly\n- [ ] Retcon.md Graph Integrity: numbered list 15, no duplicates; Related Pages: 5 flat bullets\n- [ ] Verifiers.md: code example renders correctly\n- [ ] Degrade-Ladder.md: JSON example renders correctly\n- [ ] Contracts.md: ASCII diagram and all 4 sections render correctly\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":6,"createdAt":"2026-02-18T14:24:08Z","deletions":163,"labels":[],"mergedAt":"2026-02-18T14:27:06Z","number":49,"title":"Wiki: fix markdown corruption + expand 3 stub pages","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/49"},{"additions":51,"body":"## Summary\n\n- **LLM Extraction section** (new)  `EXHAUST_USE_LLM=1`, `ANTHROPIC_API_KEY`, fallback behaviour, grade expectation, install command, links to engine file and cookbook\n- **Adapter section labels fixed**  was A (LangChain)  B (Anthropic)  E (Azure) with no explanation of the gap; now A / B / C in sequence\n- **LangChain section**  notes the new `latency_ms` + `model` metric event added in Build 29\n- **API Reference**  corrected and expanded: `POST /episodes/{id}/item`  `PATCH /episodes/{id}/items/{item_id}`, replaced nonexistent `/schema` with `GET /mg`, added `GET /health` as first row; now shows all 10 real endpoints\n- **Diagrams section** (new)  cross-references the 4 new `mermaid/29-*` files added in Build 29\n- **Coherence Scoring table**  added Weight column with the 5 actual dimension weights (25/25/20/15/15%)\n\n## Test plan\n\n- [ ] LLM Extraction section: install command and env vars are accurate\n- [ ] Adapter labels A/B/C render correctly with no gap\n- [ ] API Reference: all 10 rows match actual `exhaust_api.py` endpoints\n- [ ] Diagram links resolve to `mermaid/29-exhaust-inbox-pipeline.md`, etc.\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":1,"createdAt":"2026-02-18T14:19:56Z","deletions":20,"labels":[],"mergedAt":"2026-02-18T14:27:01Z","number":48,"title":"Wiki: update Exhaust-Inbox.md for Build 29","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/48"},{"additions":318,"body":"## Summary\n\n- Creates `Action-Contract-Schema.md`  blast radius tiers, authorization modes, rollback plan types, all fields from `specs/action_contract.schema.json`\n- Creates `DTE-Schema.md`  stage budgets, freshness, limits, degrade ladder rungs, verification, safe action constraints from `specs/dte.schema.json`\n- Creates `Drift-Schema.md`  all 8 drift types (+ 2 Exhaust Inbox types), severity levels, 7 patch types, fingerprint dedup model from `specs/drift.schema.json`\n- All three pages were linked in `_Sidebar.md` under the Schemas section but did not exist  navigating to them produced a 404\n\n## Test plan\n\n- [ ] Click each sidebar link: Action Contract Schema, DTE Schema, Drift Schema  all resolve\n- [ ] Verify field tables match `specs/action_contract.schema.json`, `specs/dte.schema.json`, `specs/drift.schema.json`\n- [ ] Verify cross-links to related pages (Contracts, DTE-Schema, Action-Contract-Schema, Episode-Schema, etc.) resolve\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-18T14:16:29Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T14:26:58Z","number":47,"title":"Wiki: add 3 missing schema pages (Action-Contract, DTE, Drift)","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/47"},{"additions":867,"body":"## Summary\n\n- **New `adapters/anthropic_exhaust.py`**: Batch adapter for Anthropic Messages API log files. Mirrors the `azure_openai_exhaust.py` structure  reads JSONL, normalises to `EpisodeEvent` dicts (prompt / completion / tool / metric), groups by `session_id + time_window`, POSTs one event at a time. CLI: `--file`, `--endpoint`, `--project`, `--team`, `--window`, `--dry-run`. Tested via `--dry-run` with a sample log entry (3 events  1 episode).\n- **`adapters/langchain_exhaust.py` improvements**: Two targeted additions, no breaking changes  (1) `on_llm_start` records `time.monotonic()` and extracts model name from `serialized`; (2) `on_llm_end` computes `latency_ms`, emits a `metric` event with `{\"latency_ms\": ..., \"model\": ...}` payload.\n- **`Source.anthropic` added to Source enum**: Enables the new adapter's events to pass `EpisodeEvent` validation.\n- **`cookbook/exhaust/`**: 5 new files  README quick-chooser, `basic_ingest/` (curl walkthrough + `run.sh` for full automated cycle), `llm_extraction/` (docs + `demo.py` runnable script that shows LLM extraction when `ANTHROPIC_API_KEY` is set, rule-based fallback otherwise).\n- **NAV.md + wiki/Exhaust-Inbox.md**: updated with Anthropic connector row and cookbook entries.\n\n## Test plan\n\n- [x] `python -m adapters.anthropic_exhaust --file /tmp/test.jsonl --dry-run`  `3 events, 1 episode` (verified)\n- [x] `python cookbook/exhaust/llm_extraction/demo.py`  rule-based path exits cleanly, Grade C, correct bucket counts (verified)\n- [x] LangChain changes: no existing tests broken; new `_run_start`/`_run_model` dicts don't affect callbacks that don't use them\n\n## Merge order\n\nMerges independently from PR #44 and PR #45. When all three PRs merge, `EXHAUST_USE_LLM=1` activates the full pipeline: Anthropic logs  adapter  ingest  assemble  LLM refine  commit.\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":10,"createdAt":"2026-02-18T02:44:21Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T02:53:26Z","number":46,"title":"Exhaust connectors  Anthropic adapter, LangChain latency/model, cookbook","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/46"},{"additions":403,"body":"## Summary\n\n- **New `engine/exhaust_llm_extractor.py`**: `LLMExtractor` class wraps the Anthropic Messages API (`claude-haiku-4-5-20251001` default) to extract TRUTH/REASONING/MEMORY buckets from episode transcripts. Falls back to empty buckets on any failure  API error, missing key, bad JSON  so the rule-based extractor takes over transparently.\n- **`refine_episode()` gets `use_llm: bool = False`**: additive, non-breaking. When `True` and `ANTHROPIC_API_KEY` is set, calls `LLMExtractor`; otherwise (or on any exception) runs the existing rule-based pipeline unchanged.\n- **`EXHAUST_USE_LLM` env var**: read per-request in the `/refine` endpoint. Default `\"0\"`  zero behavior change for existing deployments.\n- **`pyproject.toml`**: adds `exhaust-llm = [\"anthropic>=0.40.0\"]` optional dep. CI passes without it installed.\n- **Quickstart docs updated** with install + enable instructions and a note on fallback behavior.\n\n## Architecture\n\n```\nPOST /episodes/{id}/refine\n   EXHAUST_USE_LLM=1 + ANTHROPIC_API_KEY set?\n      YES  LLMExtractor.extract(episode)\n               _build_prompt()   (truncated at 6000 chars)\n               _call_api()       (Anthropic Messages API)\n               _parse_response() (JSON  TruthItem / ReasoningItem / MemoryItem)\n               merge episode node from rule-based extract_memory()\n            on any failure  fall through to rule-based\n      NO   existing extract_truth() / extract_reasoning() / extract_memory()\n   detect_drift() + score_coherence()  (always run, same as before)\n```\n\n## Test plan\n\n- [x] `pytest tests/test_exhaust_llm_extractor.py -v`  5/5 passed (all mocked, no API key)\n- [x] `EXHAUST_USE_LLM=0` (default)  no behavior change verified by existing test suites\n- [x] Happy path, API error fallback, bad JSON fallback, prompt truncation at 6000 chars, confidence clamping 0.01.0\n\n## Install & use\n\n```bash\npip install -e \".[exhaust-llm]\"\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\nexport EXHAUST_USE_LLM=\"1\"\n# POST /api/exhaust/episodes/{id}/refine   uses LLM extraction\n```\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":6,"createdAt":"2026-02-18T02:35:28Z","deletions":5,"labels":[],"mergedAt":"2026-02-18T02:51:24Z","number":45,"title":"Exhaust LLM Extraction  Anthropic-backed extraction with rule-based fallback","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/45"},{"additions":685,"body":"## Summary\n\n- **Schema alignment**: Fixed `specs/exhaust.schema.json`  event_type enum now matches Python `EventType` model exactly (removed `response`/`tool_call`/`tool_result` legacy values); `DriftType` updated (`low_coverage`  `low_claim_coverage`, added `stale_reference`); added `\"edited\"` to all item status enums\n- **Stale reference drift**: Implemented `DriftType.stale_reference` detection in `detect_drift()`  scans memory item context fields for `\"In episode <id>\"` patterns and signals when the referenced episode is absent from the canon memory graph\n- **Division-by-zero guard**: `score_coherence()` `evidence_quality` now uses `sum(...) / len(truth) if truth else 0.0` instead of dividing by `max(len, 1)` (consistent with surrounding pattern)\n- **Sample data fix**: `specs/sample_episode_events.jsonl` payloads converted from strings to proper JSON objects; source values corrected to valid enum values (`azure_openai`  `azure`, `cli_import`  `manual`)\n- **Test suite**: 28 new tests across two files  15 unit tests for all 5 refiner functions, 13 integration tests for 7 API endpoints via FastAPI TestClient\n\n## Test plan\n\n- [x] `pytest tests/test_exhaust_refiner.py tests/test_exhaust_api.py -v`  28/28 passed\n- [x] No changes to runtime behavior when `stale_reference` canon is empty (guarded by `if known_episode_ids:`)\n- [x] Division-by-zero guard verified via `test_score_coherence_empty`\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":6,"createdAt":"2026-02-18T02:30:34Z","deletions":31,"labels":[],"mergedAt":"2026-02-18T03:04:50Z","number":44,"title":"Exhaust Foundation  schema fixes, stale_reference drift, test suite","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/44"},{"additions":861,"body":"## Summary\n\nConverts thin integration stubs into runnable, verifiable examples for all three adapters.\n\n- **cookbook/README.md**  quick-chooser table, common prerequisites, verification concept\n- **cookbook/mcp/hello_deepsigma/**  complete MCP loopback: 7-message JSON-RPC sequence, stdlib-only `run_loopback.py`, expected output, failure modes. Clearly documents scaffold vs. full MCP status.\n- **cookbook/openclaw/supervised_run/**  `policy_pack_min.yaml` with LoanApproval + TradeExecution contracts; `run.sh` exercises all three outcomes (PASS, BLOCKED, POSTCONDITION FAILED); shows how to wrap results in a sealed DecisionEpisode\n- **cookbook/otel/trace_drift_patch/**  step-by-step span export for episodes and drift events; console-only path requires no backend; `env.example` covers Jaeger/Tempo/Honeycomb remote export\n\n## Acceptance\n\n- [ ] `python cookbook/mcp/hello_deepsigma/run_loopback.py` prints `=== PASS ===`\n- [ ] `bash cookbook/openclaw/supervised_run/run.sh` prints `=== PASS: All three scenarios behaved as expected ===`\n- [ ] OTel README steps work with `pip install -e \".[otel]\"` + console output visible\n- [ ] All cookbook docs linked from NAV.md Cookbook section\n- [ ] `docs/integrations/mcp.md` links to MCP cookbook\n- [ ] No new runtime dependencies added\n- [ ] CI remains green\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":11,"createdAt":"2026-02-18T00:07:17Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T00:14:23Z","number":43,"title":"Cookbook  runnable MCP/OpenClaw/OTel examples with verification","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/43"},{"additions":1387,"body":"## Summary\n\nConverts DeepSigma from \"excellent alpha\" to \"deployable alpha\" by adding operator-grade documentation and test infrastructure.\n\n- **OPS_RUNBOOK.md**  single-command Money Demo path, diagnostic commands, three incident playbooks including 60s WHY retrieval SLO triage\n- **TROUBLESHOOTING.md**  top 20 issues (environment, deps, schema, CLI, CI) with symptom  cause  fix  verify\n- **CONFIG_REFERENCE.md**  all CLI args, policy pack YAML schema, environment variables, \"safe minimal config\"\n- **STABILITY.md**  stable/unstable interface contract, versioning policy, v1.0 criteria checklist\n- **TEST_STRATEGY.md**  test tier breakdown (unit/integration/contract), SLO enforcement, coverage command, CI mapping, next milestones\n- **pyproject.toml**  adds `pytest-cov` to `[dev]` optional dependencies\n- **README.md**  new Operations section linking to all five docs + coverage snippet\n- **NAV.md**  new Ops Pack section\n\n## SLO Enforced\n\nWHY retrieval  60 seconds is documented in `OPS_RUNBOOK.md 5.1` (triage playbook) and declared as a measurable SLO in `TEST_STRATEGY.md 3`.\n\n## Test plan\n\n- [ ] `pytest tests/ -v` passes (no behavior changes)\n- [ ] `pip install -e \".[dev]\"` installs `pytest-cov` successfully\n- [ ] `pytest --cov=core --cov-report=term-missing` runs and reports coverage\n- [ ] All five new docs render correctly on GitHub\n- [ ] README Operations section and NAV Ops Pack section link correctly\n- [ ] CI remains green (no runtime changes)\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":8,"createdAt":"2026-02-18T00:02:42Z","deletions":0,"labels":[],"mergedAt":"2026-02-18T00:13:19Z","number":42,"title":"v0.3.2 Ops Pack  runbooks, troubleshooting, config ref, stability, test strategy, coverage","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/42"},{"additions":817,"body":"## Summary\n\n- **`dashboard/api_server.py`**  new FastAPI server (port 8000) that loads real `DecisionEpisodes` and `DriftEvents` from `examples/`, runs the full `DLR  RS  DS  MG  CoherenceScorer` pipeline, and exposes:\n  - `GET /api/episodes`  real episodes in dashboard format\n  - `GET /api/drifts`  real drift events\n  - `GET /api/agents`  per-agent metric aggregates\n  - `GET /api/coherence`  full coherence score report (grade + dimensions)\n  - `POST /api/iris`  live IRIS query resolution\n- **`dashboard/src/mockData.ts`**  added `fetchRealEpisodes()`, `fetchRealDrifts()`, `fetchRealAgents()`, `fetchRealIRIS()` helpers that hit the API with a 2s timeout and return `null` if offline\n- **`dashboard/src/App.tsx`**  `loadData` is now async; tries the API first, falls back to 100 generated mock episodes; shows a ` live` / ` mock` badge in the header\n\n## Test plan\n\n- [ ] `pip install fastapi uvicorn && python dashboard/api_server.py`  server starts on port 8000\n- [ ] `GET http://localhost:8000/api/health` returns `{\"status\":\"ok\",\"episode_count\":7,\"drift_count\":8}`\n- [ ] `cd dashboard && npm run dev`  dashboard shows ` live` badge and real episode data\n- [ ] Stop the API server  dashboard falls back to mock data and shows ` mock`\n- [ ] `POST /api/iris` with `{\"query_type\":\"STATUS\"}` returns a valid IRIS response\n\n Generated with [Claude Code](https://claude.com/claude-code)","changedFiles":3,"createdAt":"2026-02-17T22:15:02Z","deletions":534,"labels":[],"mergedAt":"2026-02-17T23:40:24Z","number":41,"title":"feat(dashboard): real-data API bridge + live/mock toggle","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/41"},{"additions":238,"body":"## Summary\r\n\r\nCredibility and discoverability fixes based on external feedback.\r\nNo feature changes, no scoring logic changes, no new frameworks.\r\n\r\n### Changes\r\n\r\n- **LICENSE cleanup**: Replaced Apache-2.0 placeholder with full MIT text\r\n-   to match `pyproject.toml` (`license = {text = \"MIT\"}` + classifier\r\n-   `License :: OSI Approved :: MIT License`). pyproject.toml was already correct.\r\n- **README badges**: Added CI status, License (MIT), and Python 3.10+ badges\r\n-   to the top of README.md. No PyPI badge (not published). Minimal, no clutter.\r\n- **Coherence Scoring Model doc** (`canonical/coherence_scoring_model.md`):\r\n-   Documents the four scoring dimensions, weights, grade thresholds, penalty\r\n-   formulas, and a fully verified worked example using the Money Demo numbers\r\n-   (90.00 A -> 85.75 B -> 90.00 A). All numbers cross-checked against\r\n-   `scoring.py`, `ds.py`, `rs.py`, `dlr.py`, and `sample_episodes.json`.\r\n-   Explicitly states code is source of truth.\r\n- **Link polish**: Audited README.md, START_HERE.md, HERO_DEMO.md, NAV.md\r\n-   for absolute `blob/main` links. All four already use relative paths --\r\n-   no changes needed.\r\n- **Repo visibility guidance** (`docs/repo_visibility.md`): Recommended\r\n-   6 missing GitHub topics (cross-referenced against the 20 existing ones)\r\n-   and a 30-second discoverability checklist.\r\n### Files Changed\r\n\r\n| File | Action |\r\n|------|--------|\r\n| `LICENSE` | Replaced (Apache-2.0 placeholder -> full MIT text) |\r\n| `README.md` | Modified (added 3 badges above title) |\r\n| `canonical/coherence_scoring_model.md` | **Created** |\r\n| `docs/repo_visibility.md` | **Created** |\r\n\r\n### Verification\r\n\r\n- [x] `pyproject.toml` license field, classifier, and LICENSE file all say MIT\r\n- [ ] - [x] Badges render correctly and link to relevant pages\r\n- [ ] - [x] Scoring doc numbers verified against source: 90.00 -> 85.75 -> 90.00\r\n- [ ] - [x] A reader can explain why a score changes without reading code\r\n- [ ] - [x] No remaining `blob/main` links in the four entry docs\r\n- [ ] - [x] Repo visibility doc is clear, actionable, short -- accounts for existing topics","changedFiles":4,"createdAt":"2026-02-16T23:11:29Z","deletions":5,"labels":[],"mergedAt":"2026-02-16T23:13:02Z","number":40,"title":"Repo Credibility Pass: License + Badges + Score Transparency + Clean Links","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/40"},{"additions":246,"body":"## What does this PR do?\r\n\r\n<!-- Brief description of the change -->\r\n\r\n## Type of Change\r\n\r\n- [ ] Bug fix (non-breaking change that fixes an issue)\r\n- [ ] New feature (non-breaking change that adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation update\r\n- [ ] Refactor / chore (no functional change)\r\n\r\n## Modules Affected\r\n\r\n- [ ] engine/\r\n- [ ] core/\r\n- [ ] verifiers/\r\n- [ ] tools/\r\n- [ ] specs/\r\n- [ ] policy_packs/\r\n- [ ] adapters/\r\n- [ ] rdf/\r\n- [ ] tests/\r\n- [ ] docs / wiki / mermaid\r\n\r\n## Checklist\r\n\r\n- [ ] My code follows the project style (ruff clean)\r\n- [ ] I have added/updated tests for this change\r\n- [ ] All new and existing tests pass (`python -m pytest tests/ -v`)\r\n- [ ] I have updated documentation if needed\r\n- [ ] Schema changes include updated examples\r\n- [ ] No secrets, tokens, or credentials in this PR\r\n\r\n## Related Issues\r\n\r\n<!-- Closes #123, Fixes #456 -->\r\n","changedFiles":5,"createdAt":"2026-02-15T00:41:16Z","deletions":1434,"labels":[],"mergedAt":"2026-02-15T01:10:29Z","number":29,"title":"Create compression_engine.py","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/29"},{"additions":1174,"body":"## What does this PR do?\r\n\r\nImplements **Phase 1 (PRIME Layer)** of the Gap Closure Roadmap  the governance threshold gate that converts LLM probability gradients into decision-grade actions using Truth-Reasoning-Memory invariants.\r\n\r\nPRIME sits between context assembly and action execution in the Coherence Ops pipeline, evaluating three invariant facets and emitting APPROVE / DEFER / ESCALATE verdicts with full decision lineage.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change that adds functionality)\r\n- [x] Documentation update\r\n\r\n## Files Added (5)\r\n\r\n| File | Purpose |\r\n|------|---------|\r\n| `core/prime.py` | Core PRIME Threshold Gate implementation (286 lines) |\r\n| `specs/prime_gate.schema.json` | JSON Schema for PRIME gate inputs/outputs |\r\n| `tests/test_prime.py` | Unit tests  verdicts, scoring, edge cases |\r\n| `mermaid/27-prime-threshold-gate.md` | Visual architecture diagrams |\r\n| `docs/18-prime.md` | Full documentation with config reference & examples |\r\n\r\n## Modules Affected\r\n\r\n- [x] core/\r\n- [x] specs/\r\n- [x] tests/\r\n- [x] docs / wiki / mermaid\r\n\r\n## Architecture\r\n\r\n```\r\nLLM Output  Context Assembly  PRIME Gate  Action Execution\r\n                                    \r\n                          Truth (claim-evidence-source)\r\n                          Reasoning (facts vs interpretation)\r\n                          Memory (seal-version-patch)\r\n                                    \r\n                          APPROVE / DEFER / ESCALATE\r\n                          + full decision lineage\r\n```\r\n\r\n## Roadmap Reference\r\n\r\nCloses P1 tasks from the Gap Closure Roadmap:\r\n-  Create core/prime.py (CRITICAL)\r\n-  Add specs/prime_gate.schema.json (CRITICAL)\r\n-  Add tests/test_prime.py (HIGH)\r\n-  Create mermaid/27-prime-threshold-gate.md (MEDIUM)\r\n-  Add docs/18-prime.md (HIGH)\r\n\r\nRemaining P1 task: Wire PRIME into run_supervised pipeline (separate PR)\r\n\r\n## Checklist\r\n\r\n- [x] My code follows the project style (ruff clean)\r\n- [x] I have added/updated tests for this change\r\n- [x] I have updated documentation if needed\r\n- [x] Schema changes include updated examples\r\n- [x] No secrets, tokens, or credentials in this PR","changedFiles":6,"createdAt":"2026-02-14T22:35:39Z","deletions":1,"labels":[],"mergedAt":"2026-02-15T01:28:23Z","number":28,"title":"feat(P1): PRIME Threshold Gate  core implementation, schema, tests, docs","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/28"},{"additions":229,"body":"## What does this PR do?\r\n\r\nPhase 0 of the Gap Closure Roadmap  Brand Unification & Foundation.\r\n\r\nAdds two canonical reference documents that bridge LinkedIn content vocabulary to repository code:\r\n\r\n- **GLOSSARY.md**  120-line canonical glossary covering all concepts: brand identity, core framework (Truth-Reasoning-Memory), four pillars (DLR/RS/DS/MG), runtime architecture (AL6/DTE), measurement (CTI/DAT/DDR/ITCO), operational modes (FranOPS/IntelOps/ReflectionOps), integrations, and narrative metaphors.\r\n- **docs/01-language-map.md**  Rosetta stone mapping every LinkedIn post concept to its repo artifact with implementation status.\r\n\r\n## Type of Change\r\n- [x] Documentation update\r\n\r\n## Modules Affected\r\n- [x] docs / wiki / mermaid\r\n\r\n## Checklist\r\n- [x] My code follows the project style (ruff clean)\r\n- [x] I have updated documentation if needed\r\n- [x] No secrets, tokens, or credentials in this PR\r\n\r\n## Related Issues\r\nCloses gap: \" OVERWATCH branding gap\", \"Institutional Memory narrative\", \"Signal Over Noise\", \"Ferrari/Chassis metaphor\", \"Iceberg Model\", \"MU-TH-UR analogy\"","changedFiles":2,"createdAt":"2026-02-14T19:50:23Z","deletions":0,"labels":[],"mergedAt":"2026-02-14T19:54:23Z","number":27,"title":"docs(phase0): add GLOSSARY.md and LinkedIn-to-Code language map","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/27"},{"additions":2,"body":"Bumps [actions/setup-python](https://github.com/actions/setup-python) from 5 to 6.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/setup-python/releases\">actions/setup-python's releases</a>.</em></p>\n<blockquote>\n<h2>v6.0.0</h2>\n<h2>What's Changed</h2>\n<h3>Breaking Changes</h3>\n<ul>\n<li>Upgrade to node 24 by <a href=\"https://github.com/salmanmkc\"><code>@salmanmkc</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1164\">actions/setup-python#1164</a></li>\n</ul>\n<p>Make sure your runner is on version v2.327.1 or later to ensure compatibility with this release. <a href=\"https://github.com/actions/runner/releases/tag/v2.327.1\">See Release Notes</a></p>\n<h3>Enhancements:</h3>\n<ul>\n<li>Add support for <code>pip-version</code>  by <a href=\"https://github.com/priyagupta108\"><code>@priyagupta108</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1129\">actions/setup-python#1129</a></li>\n<li>Enhance reading from .python-version by <a href=\"https://github.com/krystof-k\"><code>@krystof-k</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/787\">actions/setup-python#787</a></li>\n<li>Add version parsing from Pipfile by <a href=\"https://github.com/aradkdj\"><code>@aradkdj</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1067\">actions/setup-python#1067</a></li>\n</ul>\n<h3>Bug fixes:</h3>\n<ul>\n<li>Clarify pythonLocation behaviour for PyPy and GraalPy in environment variables by <a href=\"https://github.com/aparnajyothi-y\"><code>@aparnajyothi-y</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1183\">actions/setup-python#1183</a></li>\n<li>Change missing cache directory error to warning  by <a href=\"https://github.com/aparnajyothi-y\"><code>@aparnajyothi-y</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1182\">actions/setup-python#1182</a></li>\n<li>Add Architecture-Specific PATH Management for Python with --user Flag on Windows by <a href=\"https://github.com/aparnajyothi-y\"><code>@aparnajyothi-y</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1122\">actions/setup-python#1122</a></li>\n<li>Include python version in PyPy python-version output by <a href=\"https://github.com/cdce8p\"><code>@cdce8p</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1110\">actions/setup-python#1110</a></li>\n<li>Update docs: clarification on pip authentication with setup-python by <a href=\"https://github.com/priya-kinthali\"><code>@priya-kinthali</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1156\">actions/setup-python#1156</a></li>\n</ul>\n<h3>Dependency updates:</h3>\n<ul>\n<li>Upgrade idna from 2.9 to 3.7 in /<strong>tests</strong>/data by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a>[bot] in <a href=\"https://redirect.github.com/actions/setup-python/pull/843\">actions/setup-python#843</a></li>\n<li>Upgrade form-data to fix critical vulnerabilities <a href=\"https://redirect.github.com/actions/setup-python/issues/182\">#182</a> &amp; <a href=\"https://redirect.github.com/actions/setup-python/issues/183\">#183</a> by <a href=\"https://github.com/aparnajyothi-y\"><code>@aparnajyothi-y</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1163\">actions/setup-python#1163</a></li>\n<li>Upgrade setuptools to 78.1.1 to fix path traversal vulnerability in PackageIndex.download by <a href=\"https://github.com/aparnajyothi-y\"><code>@aparnajyothi-y</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1165\">actions/setup-python#1165</a></li>\n<li>Upgrade actions/checkout from 4 to 5 by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a>[bot] in <a href=\"https://redirect.github.com/actions/setup-python/pull/1181\">actions/setup-python#1181</a></li>\n<li>Upgrade <code>@actions/tool-cache</code> from 2.0.1 to 2.0.2 by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a>[bot] in <a href=\"https://redirect.github.com/actions/setup-python/pull/1095\">actions/setup-python#1095</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/krystof-k\"><code>@krystof-k</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/setup-python/pull/787\">actions/setup-python#787</a></li>\n<li><a href=\"https://github.com/cdce8p\"><code>@cdce8p</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/setup-python/pull/1110\">actions/setup-python#1110</a></li>\n<li><a href=\"https://github.com/aradkdj\"><code>@aradkdj</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/setup-python/pull/1067\">actions/setup-python#1067</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/setup-python/compare/v5...v6.0.0\">https://github.com/actions/setup-python/compare/v5...v6.0.0</a></p>\n<h2>v5.6.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Workflow updates related to Ubuntu 20.04 by <a href=\"https://github.com/aparnajyothi-y\"><code>@aparnajyothi-y</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1065\">actions/setup-python#1065</a></li>\n<li>Fix for Candidate Not Iterable Error by <a href=\"https://github.com/aparnajyothi-y\"><code>@aparnajyothi-y</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1082\">actions/setup-python#1082</a></li>\n<li>Upgrade semver and <code>@types/semver</code> by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1091\">actions/setup-python#1091</a></li>\n<li>Upgrade prettier from 2.8.8 to 3.5.3 by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1046\">actions/setup-python#1046</a></li>\n<li>Upgrade ts-jest from 29.1.2 to 29.3.2 by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1081\">actions/setup-python#1081</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/setup-python/compare/v5...v5.6.0\">https://github.com/actions/setup-python/compare/v5...v5.6.0</a></p>\n<h2>v5.5.0</h2>\n<h2>What's Changed</h2>\n<h3>Enhancements:</h3>\n<ul>\n<li>Support free threaded Python versions like '3.13t' by <a href=\"https://github.com/colesbury\"><code>@colesbury</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/973\">actions/setup-python#973</a></li>\n<li>Enhance Workflows: Include ubuntu-arm runners, Add e2e Testing for free threaded and Upgrade <code>@action/cache</code> from 4.0.0 to 4.0.3 by <a href=\"https://github.com/priya-kinthali\"><code>@priya-kinthali</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1056\">actions/setup-python#1056</a></li>\n<li>Add support for .tool-versions file in setup-python by <a href=\"https://github.com/mahabaleshwars\"><code>@mahabaleshwars</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1043\">actions/setup-python#1043</a></li>\n</ul>\n<h3>Bug fixes:</h3>\n<ul>\n<li>Fix architecture for pypy on Linux ARM64 by <a href=\"https://github.com/mayeut\"><code>@mayeut</code></a> in <a href=\"https://redirect.github.com/actions/setup-python/pull/1011\">actions/setup-python#1011</a>\nThis update maps arm64 to aarch64 for Linux ARM64 PyPy installations.</li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/setup-python/commit/a309ff8b426b58ec0e2a45f0f869d46889d02405\"><code>a309ff8</code></a> Bump urllib3 from 2.6.0 to 2.6.3 in /<strong>tests</strong>/data (<a href=\"https://redirect.github.com/actions/setup-python/issues/1264\">#1264</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/bfe8cc55a7890e3d6672eda6460ef37bfcc70755\"><code>bfe8cc5</code></a> Upgrade <a href=\"https://github.com/actions\"><code>@actions</code></a> dependencies to Node 24 compatible versions (<a href=\"https://redirect.github.com/actions/setup-python/issues/1259\">#1259</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/4f41a90a1f38628c7ccc608d05fbafe701bc20ae\"><code>4f41a90</code></a> Bump urllib3 from 2.5.0 to 2.6.0 in /<strong>tests</strong>/data (<a href=\"https://redirect.github.com/actions/setup-python/issues/1253\">#1253</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/83679a892e2d95755f2dac6acb0bfd1e9ac5d548\"><code>83679a8</code></a> Bump <code>@types/node</code> from 24.1.0 to 24.9.1 and update macos-13 to macos-15-intel ...</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/bfc4944b43a5d84377eca3cf6ab5b7992ba61923\"><code>bfc4944</code></a> Bump prettier from 3.5.3 to 3.6.2 (<a href=\"https://redirect.github.com/actions/setup-python/issues/1234\">#1234</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/97aeb3efb8a852c559869050c7fb175b4efcc8cf\"><code>97aeb3e</code></a> Bump requests from 2.32.2 to 2.32.4 in /<strong>tests</strong>/data (<a href=\"https://redirect.github.com/actions/setup-python/issues/1130\">#1130</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/443da59188462e2402e2942686db5aa6723f4bed\"><code>443da59</code></a> Bump actions/publish-action from 0.3.0 to 0.4.0 &amp; Documentation update for pi...</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/cfd55ca82492758d853442341ad4d8010466803a\"><code>cfd55ca</code></a> graalpy: add graalpy early-access and windows builds (<a href=\"https://redirect.github.com/actions/setup-python/issues/880\">#880</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/bba65e51ff35d50c6dbaaacd8a4681db13aa7cb4\"><code>bba65e5</code></a> Bump typescript from 5.4.2 to 5.9.3 and update docs/advanced-usage.md (<a href=\"https://redirect.github.com/actions/setup-python/issues/1094\">#1094</a>)</li>\n<li><a href=\"https://github.com/actions/setup-python/commit/18566f86b301499665bd3eb1a2247e0849c64fa5\"><code>18566f8</code></a> Improve wording and &quot;fix example&quot; (remove 3.13) on testing against pre-releas...</li>\n<li>Additional commits viewable in <a href=\"https://github.com/actions/setup-python/compare/v5...v6\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=5&new-version=6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>","changedFiles":1,"createdAt":"2026-02-13T14:36:23Z","deletions":2,"labels":[],"mergedAt":"2026-02-13T15:39:48Z","number":26,"title":"chore(ci): bump actions/setup-python from 5 to 6","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/26"},{"additions":2,"body":"Bumps [actions/checkout](https://github.com/actions/checkout) from 4 to 6.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/releases\">actions/checkout's releases</a>.</em></p>\n<blockquote>\n<h2>v6.0.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Update README to include Node.js 24 support details and requirements by <a href=\"https://github.com/salmanmkc\"><code>@salmanmkc</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2248\">actions/checkout#2248</a></li>\n<li>Persist creds to a separate file by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2286\">actions/checkout#2286</a></li>\n<li>v6-beta by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2298\">actions/checkout#2298</a></li>\n<li>update readme/changelog for v6 by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2311\">actions/checkout#2311</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v5.0.0...v6.0.0\">https://github.com/actions/checkout/compare/v5.0.0...v6.0.0</a></p>\n<h2>v6-beta</h2>\n<h2>What's Changed</h2>\n<p>Updated persist-credentials to store the credentials under <code>$RUNNER_TEMP</code> instead of directly in the local git config.</p>\n<p>This requires a minimum Actions Runner version of <a href=\"https://github.com/actions/runner/releases/tag/v2.329.0\">v2.329.0</a> to access the persisted credentials for <a href=\"https://docs.github.com/en/actions/tutorials/use-containerized-services/create-a-docker-container-action\">Docker container action</a> scenarios.</p>\n<h2>v5.0.1</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Port v6 cleanup to v5 by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2301\">actions/checkout#2301</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v5...v5.0.1\">https://github.com/actions/checkout/compare/v5...v5.0.1</a></p>\n<h2>v5.0.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Update actions checkout to use node 24 by <a href=\"https://github.com/salmanmkc\"><code>@salmanmkc</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2226\">actions/checkout#2226</a></li>\n<li>Prepare v5.0.0 release by <a href=\"https://github.com/salmanmkc\"><code>@salmanmkc</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2238\">actions/checkout#2238</a></li>\n</ul>\n<h2> Minimum Compatible Runner Version</h2>\n<p><strong>v2.327.1</strong><br />\n<a href=\"https://github.com/actions/runner/releases/tag/v2.327.1\">Release Notes</a></p>\n<p>Make sure your runner is updated to this version or newer to use this release.</p>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v4...v5.0.0\">https://github.com/actions/checkout/compare/v4...v5.0.0</a></p>\n<h2>v4.3.1</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Port v6 cleanup to v4 by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2305\">actions/checkout#2305</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v4...v4.3.1\">https://github.com/actions/checkout/compare/v4...v4.3.1</a></p>\n<h2>v4.3.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>docs: update README.md by <a href=\"https://github.com/motss\"><code>@motss</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1971\">actions/checkout#1971</a></li>\n<li>Add internal repos for checking out multiple repositories by <a href=\"https://github.com/mouismail\"><code>@mouismail</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1977\">actions/checkout#1977</a></li>\n<li>Documentation update - add recommended permissions to Readme by <a href=\"https://github.com/benwells\"><code>@benwells</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2043\">actions/checkout#2043</a></li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/blob/main/CHANGELOG.md\">actions/checkout's changelog</a>.</em></p>\n<blockquote>\n<h1>Changelog</h1>\n<h2>v6.0.2</h2>\n<ul>\n<li>Fix tag handling: preserve annotations and explicit fetch-tags by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2356\">actions/checkout#2356</a></li>\n</ul>\n<h2>v6.0.1</h2>\n<ul>\n<li>Add worktree support for persist-credentials includeIf by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2327\">actions/checkout#2327</a></li>\n</ul>\n<h2>v6.0.0</h2>\n<ul>\n<li>Persist creds to a separate file by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2286\">actions/checkout#2286</a></li>\n<li>Update README to include Node.js 24 support details and requirements by <a href=\"https://github.com/salmanmkc\"><code>@salmanmkc</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2248\">actions/checkout#2248</a></li>\n</ul>\n<h2>v5.0.1</h2>\n<ul>\n<li>Port v6 cleanup to v5 by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2301\">actions/checkout#2301</a></li>\n</ul>\n<h2>v5.0.0</h2>\n<ul>\n<li>Update actions checkout to use node 24 by <a href=\"https://github.com/salmanmkc\"><code>@salmanmkc</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2226\">actions/checkout#2226</a></li>\n</ul>\n<h2>v4.3.1</h2>\n<ul>\n<li>Port v6 cleanup to v4 by <a href=\"https://github.com/ericsciple\"><code>@ericsciple</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2305\">actions/checkout#2305</a></li>\n</ul>\n<h2>v4.3.0</h2>\n<ul>\n<li>docs: update README.md by <a href=\"https://github.com/motss\"><code>@motss</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1971\">actions/checkout#1971</a></li>\n<li>Add internal repos for checking out multiple repositories by <a href=\"https://github.com/mouismail\"><code>@mouismail</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1977\">actions/checkout#1977</a></li>\n<li>Documentation update - add recommended permissions to Readme by <a href=\"https://github.com/benwells\"><code>@benwells</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2043\">actions/checkout#2043</a></li>\n<li>Adjust positioning of user email note and permissions heading by <a href=\"https://github.com/joshmgross\"><code>@joshmgross</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2044\">actions/checkout#2044</a></li>\n<li>Update README.md by <a href=\"https://github.com/nebuk89\"><code>@nebuk89</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2194\">actions/checkout#2194</a></li>\n<li>Update CODEOWNERS for actions by <a href=\"https://github.com/TingluoHuang\"><code>@TingluoHuang</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2224\">actions/checkout#2224</a></li>\n<li>Update package dependencies by <a href=\"https://github.com/salmanmkc\"><code>@salmanmkc</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/2236\">actions/checkout#2236</a></li>\n</ul>\n<h2>v4.2.2</h2>\n<ul>\n<li><code>url-helper.ts</code> now leverages well-known environment variables by <a href=\"https://github.com/jww3\"><code>@jww3</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1941\">actions/checkout#1941</a></li>\n<li>Expand unit test coverage for <code>isGhes</code> by <a href=\"https://github.com/jww3\"><code>@jww3</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1946\">actions/checkout#1946</a></li>\n</ul>\n<h2>v4.2.1</h2>\n<ul>\n<li>Check out other refs/* by commit if provided, fall back to ref by <a href=\"https://github.com/orhantoy\"><code>@orhantoy</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1924\">actions/checkout#1924</a></li>\n</ul>\n<h2>v4.2.0</h2>\n<ul>\n<li>Add Ref and Commit outputs by <a href=\"https://github.com/lucacome\"><code>@lucacome</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1180\">actions/checkout#1180</a></li>\n<li>Dependency updates by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a>- <a href=\"https://redirect.github.com/actions/checkout/pull/1777\">actions/checkout#1777</a>, <a href=\"https://redirect.github.com/actions/checkout/pull/1872\">actions/checkout#1872</a></li>\n</ul>\n<h2>v4.1.7</h2>\n<ul>\n<li>Bump the minor-npm-dependencies group across 1 directory with 4 updates by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1739\">actions/checkout#1739</a></li>\n<li>Bump actions/checkout from 3 to 4 by <a href=\"https://github.com/dependabot\"><code>@dependabot</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1697\">actions/checkout#1697</a></li>\n<li>Check out other refs/* by commit by <a href=\"https://github.com/orhantoy\"><code>@orhantoy</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1774\">actions/checkout#1774</a></li>\n<li>Pin actions/checkout's own workflows to a known, good, stable version. by <a href=\"https://github.com/jww3\"><code>@jww3</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1776\">actions/checkout#1776</a></li>\n</ul>\n<h2>v4.1.6</h2>\n<ul>\n<li>Check platform to set archive extension appropriately by <a href=\"https://github.com/cory-miller\"><code>@cory-miller</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1732\">actions/checkout#1732</a></li>\n</ul>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/checkout/commit/de0fac2e4500dabe0009e67214ff5f5447ce83dd\"><code>de0fac2</code></a> Fix tag handling: preserve annotations and explicit fetch-tags (<a href=\"https://redirect.github.com/actions/checkout/issues/2356\">#2356</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/064fe7f3312418007dea2b49a19844a9ee378f49\"><code>064fe7f</code></a> Add orchestration_id to git user-agent when ACTIONS_ORCHESTRATION_ID is set (...</li>\n<li><a href=\"https://github.com/actions/checkout/commit/8e8c483db84b4bee98b60c0593521ed34d9990e8\"><code>8e8c483</code></a> Clarify v6 README (<a href=\"https://redirect.github.com/actions/checkout/issues/2328\">#2328</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/033fa0dc0b82693d8986f1016a0ec2c5e7d9cbb1\"><code>033fa0d</code></a> Add worktree support for persist-credentials includeIf (<a href=\"https://redirect.github.com/actions/checkout/issues/2327\">#2327</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/c2d88d3ecc89a9ef08eebf45d9637801dcee7eb5\"><code>c2d88d3</code></a> Update all references from v5 and v4 to v6 (<a href=\"https://redirect.github.com/actions/checkout/issues/2314\">#2314</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/1af3b93b6815bc44a9784bd300feb67ff0d1eeb3\"><code>1af3b93</code></a> update readme/changelog for v6 (<a href=\"https://redirect.github.com/actions/checkout/issues/2311\">#2311</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/71cf2267d89c5cb81562390fa70a37fa40b1305e\"><code>71cf226</code></a> v6-beta (<a href=\"https://redirect.github.com/actions/checkout/issues/2298\">#2298</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/069c6959146423d11cd0184e6accf28f9d45f06e\"><code>069c695</code></a> Persist creds to a separate file (<a href=\"https://redirect.github.com/actions/checkout/issues/2286\">#2286</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/ff7abcd0c3c05ccf6adc123a8cd1fd4fb30fb493\"><code>ff7abcd</code></a> Update README to include Node.js 24 support details and requirements (<a href=\"https://redirect.github.com/actions/checkout/issues/2248\">#2248</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/08c6903cd8c0fde910a37f88322edcfb5dd907a8\"><code>08c6903</code></a> Prepare v5.0.0 release (<a href=\"https://redirect.github.com/actions/checkout/issues/2238\">#2238</a>)</li>\n<li>Additional commits viewable in <a href=\"https://github.com/actions/checkout/compare/v4...v6\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=4&new-version=6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>","changedFiles":1,"createdAt":"2026-02-13T14:36:19Z","deletions":2,"labels":[],"mergedAt":"2026-02-13T15:41:15Z","number":25,"title":"chore(ci): bump actions/checkout from 4 to 6","url":"https://github.com/8ryanWh1t3/DeepSigma/pull/25"}]

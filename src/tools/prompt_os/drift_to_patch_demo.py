#!/usr/bin/env python3
"""One-command Drift → Patch hero loop.

Scans the decision log for drift conditions, creates a patch if triggered,
emits a telemetry event, and exports a sealed run JSON.

Usage:
    python src/tools/prompt_os/drift_to_patch_demo.py
    python src/tools/prompt_os/drift_to_patch_demo.py --run-id RUN-DEMO --user Boss
    python src/tools/prompt_os/drift_to_patch_demo.py --out-dir /tmp/sealed
"""
from __future__ import annotations

import argparse
import csv
import hashlib
import json
import random
import string
import sys
from datetime import datetime, timezone
from pathlib import Path


# ── Defaults ──────────────────────────────────────────────────────
DEFAULT_DATA_DIR = Path("artifacts/sample_data/prompt_os_v2")
DEFAULT_TELEMETRY_DIR = Path("artifacts/sample_data/prompt_os_telemetry")
DEFAULT_OUT_DIR = Path("artifacts/sealed_runs")

DECISION_LOG = "decision_log.csv"
PATCH_LOG = "patch_log.csv"
LLM_OUTPUT = "llm_output.csv"
TELEMETRY_FILE = "telemetry_events.csv"

TELEMETRY_COLUMNS = [
    "EventID", "Timestamp", "Event", "Severity",
    "DecisionID", "PatchID", "RunID", "User",
]

REQUIRED_DECISION_COLS = {
    "DecisionID", "Status", "BlastRadius_1to5", "Confidence_pct", "PriorityScore",
}


# ── ID generators ────────────────────────────────────────────────
def _rand_alnum(n: int = 4) -> str:
    return "".join(random.choices(string.ascii_uppercase + string.digits, k=n))


def gen_patch_id() -> str:
    return f"PX-{_rand_alnum(4)}"


def gen_run_id() -> str:
    return f"RUN-{_rand_alnum(4)}"


# ── CSV helpers ──────────────────────────────────────────────────
def read_csv(path: Path) -> list[dict]:
    with open(path, newline="") as f:
        return list(csv.DictReader(f))


def append_csv_row(path: Path, row: dict, fieldnames: list[str]) -> None:
    write_header = not path.exists() or path.stat().st_size == 0
    with open(path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if write_header:
            writer.writeheader()
        writer.writerow(row)


# ── Drift detection ─────────────────────────────────────────────
def detect_drift(rows: list[dict]) -> tuple[str, dict | None]:
    """Apply drift rules and return (severity, triggering_row | None).

    Rule 1 (RED):  BlastRadius_1to5 >= 4 AND Status == "Active" AND Confidence_pct < 70
    Rule 2 (YELLOW): PriorityScore >= 12 AND Status == "Active"
    """
    for row in rows:
        try:
            blast = int(row.get("BlastRadius_1to5", 0))
            conf = float(row.get("Confidence_pct", 100))
            status = row.get("Status", "").strip()
        except (ValueError, TypeError):
            continue
        if blast >= 4 and status == "Active" and conf < 70:
            return "RED", row

    for row in rows:
        try:
            priority = float(row.get("PriorityScore", 0))
            status = row.get("Status", "").strip()
        except (ValueError, TypeError):
            continue
        if priority >= 12 and status == "Active":
            return "YELLOW", row

    return "GREEN", None


# ── Patch row ────────────────────────────────────────────────────
def build_patch_row(
    patch_id: str,
    severity: str,
    decision_row: dict,
    user: str,
) -> dict:
    return {
        "PatchID": patch_id,
        "TriggerType": "Drift",
        "TriggerID": decision_row["DecisionID"],
        "Description": f"Auto-drift: {decision_row.get('Title', 'unknown')}",
        "Severity_GYR": severity,
        "Status": "Open",
        "Owner": user,
        "DateCreated": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
        "DateResolved": "",
        "Resolution": "",
        "Notes": "Generated by drift_to_patch_demo.py",
    }


PATCH_FIELDNAMES = [
    "PatchID", "TriggerType", "TriggerID", "Description", "Severity_GYR",
    "Status", "Owner", "DateCreated", "DateResolved", "Resolution", "Notes",
]


# ── Telemetry row ────────────────────────────────────────────────
def build_telemetry_row(
    severity: str,
    decision_id: str,
    patch_id: str,
    run_id: str,
    user: str,
) -> dict:
    return {
        "EventID": f"EVT-{_rand_alnum(6)}",
        "Timestamp": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
        "Event": "drift_flag",
        "Severity": severity,
        "DecisionID": decision_id,
        "PatchID": patch_id,
        "RunID": run_id,
        "User": user,
    }


# ── Sealed run ───────────────────────────────────────────────────
def build_sealed_run(
    run_id: str,
    severity: str,
    decision_row: dict | None,
    patch_id: str,
    user: str,
    llm_rows: list[dict],
) -> dict:
    now = datetime.now(timezone.utc)
    sealed = {
        "schema_version": "1.0",
        "meta": {
            "run_id": run_id,
            "session_date": now.strftime("%Y-%m-%d"),
            "operator": user,
            "model": "drift_to_patch_demo",
            "workbook_version": "v2",
            "export_timestamp": now.strftime("%Y-%m-%dT%H:%M:%SZ"),
        },
        "drift": {
            "detected": severity != "GREEN",
            "severity": severity,
            "decision_id": decision_row["DecisionID"] if decision_row else None,
            "decision_title": decision_row.get("Title") if decision_row else None,
            "patch_id": patch_id if severity != "GREEN" else None,
        },
        "kpis": {
            "total_llm_runs": len(llm_rows),
        },
        "hash": "",
    }
    canonical = json.dumps(sealed, sort_keys=True)
    sealed["hash"] = "sha256:" + hashlib.sha256(canonical.encode()).hexdigest()
    return sealed


# ── Main ─────────────────────────────────────────────────────────
def main() -> int:
    parser = argparse.ArgumentParser(
        description="One-command Drift → Patch hero loop"
    )
    parser.add_argument(
        "--run-id", default=None,
        help="Run ID (default: auto-generate RUN-XXXX)",
    )
    parser.add_argument(
        "--user", default="Boss",
        help="Operator name (default: Boss)",
    )
    parser.add_argument(
        "--data-dir", type=Path, default=DEFAULT_DATA_DIR,
        help="Directory containing prompt_os_v2 CSVs",
    )
    parser.add_argument(
        "--out-dir", type=Path, default=DEFAULT_OUT_DIR,
        help="Directory for sealed run JSON output",
    )
    args = parser.parse_args()

    run_id = args.run_id or gen_run_id()
    data_dir: Path = args.data_dir
    out_dir: Path = args.out_dir

    # ── Validate inputs ──────────────────────────────────────────
    decision_path = data_dir / DECISION_LOG
    patch_path = data_dir / PATCH_LOG
    llm_path = data_dir / LLM_OUTPUT

    for p in [decision_path, patch_path, llm_path]:
        if not p.exists():
            print(f"ERROR: Required file not found: {p}", file=sys.stderr)
            return 2

    decisions = read_csv(decision_path)
    if not decisions:
        print("ERROR: Decision log is empty", file=sys.stderr)
        return 2

    # Check required columns
    actual_cols = set(decisions[0].keys())
    missing = REQUIRED_DECISION_COLS - actual_cols
    if missing:
        print(f"ERROR: Missing columns in decision_log.csv: {missing}", file=sys.stderr)
        return 2

    llm_rows = read_csv(llm_path)

    # ── Detect drift ─────────────────────────────────────────────
    severity, trigger_row = detect_drift(decisions)
    patch_id = ""

    if severity != "GREEN" and trigger_row:
        patch_id = gen_patch_id()
        patch_row = build_patch_row(patch_id, severity, trigger_row, args.user)
        append_csv_row(patch_path, patch_row, PATCH_FIELDNAMES)

    # ── Emit telemetry ───────────────────────────────────────────
    telemetry_dir = DEFAULT_TELEMETRY_DIR
    telemetry_dir.mkdir(parents=True, exist_ok=True)
    telemetry_path = telemetry_dir / TELEMETRY_FILE

    decision_id = trigger_row["DecisionID"] if trigger_row else ""
    tel_row = build_telemetry_row(severity, decision_id, patch_id, run_id, args.user)
    append_csv_row(telemetry_path, tel_row, TELEMETRY_COLUMNS)

    # ── Export sealed run ────────────────────────────────────────
    sealed = build_sealed_run(run_id, severity, trigger_row, patch_id, args.user, llm_rows)

    out_dir.mkdir(parents=True, exist_ok=True)
    ts = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    out_path = out_dir / f"{run_id}_{ts}.json"
    with open(out_path, "w") as f:
        json.dump(sealed, f, indent=2)

    # ── Console summary ──────────────────────────────────────────
    print("=" * 50)
    print("  Drift → Patch Hero Loop")
    print("=" * 50)
    if severity != "GREEN" and trigger_row:
        print("  Drift detected:  YES")
        print(f"  Decision ID:     {trigger_row['DecisionID']}")
        print(f"  Decision:        {trigger_row.get('Title', '?')}")
        print(f"  Severity:        {severity}")
        print(f"  Patch ID:        {patch_id}")
    else:
        print("  Drift detected:  NO")
        print("  Severity:        GREEN")
    print(f"  Run ID:          {run_id}")
    print(f"  Sealed file:     {out_path}")
    print(f"  Telemetry:       {telemetry_path}")
    print("=" * 50)

    return 0


if __name__ == "__main__":
    sys.exit(main())
